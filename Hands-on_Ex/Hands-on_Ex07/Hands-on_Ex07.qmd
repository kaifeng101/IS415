---
title: "Hands-on Exercise 7"
subtitle: "Geographical Segmentation with Spatially Constrained Clustering Techniques"
author: "Kai Feng"
date: "Oct 11, 2024"
date-modified: "last-modified"
execute:
  eval: true
  echo: true
  freeze: true
---

# **1.0 Overview**

This exercise focuses on using geographically referenced multivariate data to delineate homogeneous regions. Two major analyses are used:

1.  Hierarchical cluster analysis

2.  Spatially constrained cluster analysis

The goal is to segment Shan State, Myanmar, into homogeneous regions based on multiple Information and Communication Technology (ICT) indicators: Radio, Television, Landline phone, Mobile phone, Computer, and Internet at home. This approach is commonly applied in geobusiness and spatial policy for defining market or planning areas.

<br/><br/>

# **2.0 Setup**

## 2.1 Installing R-Packages

Spatial data handling

-   **sf**, **rgdal** and **spdep**

Attribute data handling

-   **tidyverse**, especially **readr**, **ggplot2** and **dplyr**

Choropleth mapping

-   **tmap**

Multivariate data visualisation and analysis

-   **coorplot**, **ggpubr**, and **heatmaply**

Cluster analysis

-   **cluster** and **ClustGeo**

```{r}
pacman::p_load(spdep, tmap, sf, ClustGeo, 
               ggpubr, cluster, factoextra, NbClust,
               heatmaply, corrplot, psych, tidyverse, GGally)
```

<br/>

## 2.2 Data Acquisition

Two data sets will be used:

-   `Myanmar Township Boundary Data`: a GIS data set in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.

-   `Shan-ICT.csv`: an extract of [**The 2014 Myanmar Population and Housing Census Myanmar**](https://myanmar.unfpa.org/en/publications/2014-population-and-housing-census-myanmar-data-sheet) at the township level.

::: panel-tabset
# **Importing Geospatial Data**

```{r}
shan_sf <- st_read(dsn = "data/geospatial", 
                   layer = "myanmar_township_boundaries") %>%
  filter(ST %in% c("Shan (East)", "Shan (North)", "Shan (South)")) %>%
  select(c(2:7))

shan_sf

glimpse(shan_sf)
```

# Importing Aspatial Data

```{r}
ict <- read_csv ("data/aspatial/Shan-ICT.csv")

summary(ict)
```
:::

<br/>

## 2.3 Adding Penetration rate of each ICT

-   Measurement unit: Number of households.

-   Using raw values can introduce bias related to the total number of households.

Townships with a higher total number of households tend to show:

-   Higher numbers of households owning radios, TVs, etc.

-   Potentially inflated ownership rates that don’t reflect actual ownership proportions.

Hence:

```{r}
ict_derived <- ict %>%
  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %>%
  mutate(`TV_PR` = `Television`/`Total households`*1000) %>%
  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %>%
  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %>%
  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %>%
  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %>%
  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,
         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,
         `TT_HOUSEHOLDS`=`Total households`,
         `RADIO`=`Radio`, `TV`=`Television`, 
         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,
         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) 

summary(ict_derived)
```

<br/><br/>

# **3.0 Exploratory Data Analysis**

::: callout-note
**Histogram**

useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution)

**Box Plot**

useful to detect if there are outliers
:::

## Distribution of household with (eg. radio)

::: panel-tabset
## Histogram

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
```

## Box Plot

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO`)) +
  geom_boxplot(color="black", 
               fill="light blue")
```
:::

## Distribution of Penetration rate (eg. Radio)

::: panel-tabset
## Histogram

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
```

## Box Plot

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO_PR`)) +
  geom_boxplot(color="black", 
               fill="light blue")
```
:::

## Distribution of Penetration Rate across all channels

```{r}
radio <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

tv <- ggplot(data=ict_derived, 
             aes(x= `TV_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

llphone <- ggplot(data=ict_derived, 
             aes(x= `LLPHONE_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

mphone <- ggplot(data=ict_derived, 
             aes(x= `MPHONE_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

computer <- ggplot(data=ict_derived, 
             aes(x= `COMPUTER_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

internet <- ggplot(data=ict_derived, 
             aes(x= `INTERNET_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

ggarrange(radio, tv, llphone, mphone, computer, internet, 
          ncol = 3, 
          nrow = 2)
```

::: callout-note
use `ggarrange()` to group the histograms together
:::

## Penetration rate on map

::: panel-tabset
## Step 1: Join Geo & Aspatial data

```{r}
#| eval: false
shan_sf <- left_join(shan_sf, 
                     ict_derived, by=c("TS_PCODE"="TS_PCODE"))
  
write_rds(shan_sf, "data/rds/shan_sf.rds")
```

```{r}
shan_sf <- read_rds("data/rds/shan_sf.rds")
```

## Step 2: Prepare a choropleth map

Distribution of Radio penetration rate of Shan State at township lvl:

```{r}
qtm(shan_sf, "RADIO_PR")
```
:::

::: callout-note
The above map is bias to the underlying total number of households at the townships. It can be seen from the side by side map visualisation below **\[Townships with relatively larger number of households are also showing relatively higher number of radio ownership\]**
:::

```{r}
TT_HOUSEHOLDS.map <- tm_shape(shan_sf) + 
  tm_fill(col = "TT_HOUSEHOLDS",
          n = 5,
          style = "jenks", 
          title = "Total households") + 
  tm_borders(alpha = 0.5) 

RADIO.map <- tm_shape(shan_sf) + 
  tm_fill(col = "RADIO",
          n = 5,
          style = "jenks",
          title = "Number Radio ") + 
  tm_borders(alpha = 0.5) 

tmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,
             asp=NA, ncol=2)
```

## Distribution on penetration rate (eg. radio)

```{r}
tm_shape(shan_sf) +
    tm_polygons(c("TT_HOUSEHOLDS", "RADIO_PR"),
                style="jenks") +
    tm_facets(sync = TRUE, ncol = 2) +
  tm_legend(legend.position = c("right", "bottom"))+
  tm_layout(outer.margins=0, asp=0)
```

<br/><br/>

# **4.0 Correlation Analysis**

Use `corrplot.mixed()` to visualise & analyse the correlation of the input variables

```{r}
cluster_vars.cor = cor(ict_derived[,12:17])
corrplot.mixed(cluster_vars.cor,
         lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")
```

::: callout-note
COMPUTER_PR and INTERNET_PR are highly correlated

This suggest that only one of them should be used in the cluster analysis instead of both
:::

<br/><br/>

# **5.0 Hierarchy Cluster Analysis**

::: panel-tabset
## Step 1: Extracting clustering variables

```{r}
cluster_vars <- shan_sf %>%
  st_set_geometry(NULL) %>%
  select("TS.x", "RADIO_PR", "TV_PR", "LLPHONE_PR", "MPHONE_PR", "COMPUTER_PR")
head(cluster_vars,10)
```

::: callout-note
Following 4.0 analysis, we removed INTERNET_RP because it is highly correlated with variable COMPUTER_PR
:::

**Remove TS.x header:**

```{r}
# add a new column of towns without header
row.names(cluster_vars) <- cluster_vars$"TS.x"
head(cluster_vars,10)

# remove the old column of towns with "TS.x" header
shan_ict <- select(cluster_vars, c(2:6))
head(shan_ict, 10)
```

## Step 2: Data Standardisation

-   Cluster analysis typically involves multiple variables.

-   It's common for these variables to have different ranges of values.

-   To prevent bias in clustering results towards variables with larger values:

    -   Standardizing input variables is recommended before conducting cluster analysis.

## Step 3: Min-Max VS Z-score standardisation

::: callout-caution
Z-score standardisation method should only be used if we would assume all variables come from some normal distribution.
:::

**Min-Max Standardisation**

```{r}
shan_ict.std <- normalize(shan_ict)
summary(shan_ict.std)
```

::: callout-note
the values range of the Min-max standardised clustering variables are 0-1 now
:::

**Z-score Standardisation**

```{r}
shan_ict.z <- scale(shan_ict)
describe(shan_ict.z)
```

::: callout-note
mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.
:::
:::

### Visualising the standardised clustering variables (radio penetration rate)

::: panel-tabset
## Histogram

```{r}
r <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Raw values without standardisation")

shan_ict_s_df <- as.data.frame(shan_ict.std)
s <- ggplot(data=shan_ict_s_df, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Min-Max Standardisation")

shan_ict_z_df <- as.data.frame(shan_ict.z)
z <- ggplot(data=shan_ict_z_df, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Z-score Standardisation")

ggarrange(r, s, z,
          ncol = 3,
          nrow = 1)
```

## Area

```{r}
r <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_density(color="black",
               fill="light blue") +
  ggtitle("Raw values without standardisation")

shan_ict_s_df <- as.data.frame(shan_ict.std)
s <- ggplot(data=shan_ict_s_df, 
       aes(x=`RADIO_PR`)) +
  geom_density(color="black",
               fill="light blue") +
  ggtitle("Min-Max Standardisation")

shan_ict_z_df <- as.data.frame(shan_ict.z)
z <- ggplot(data=shan_ict_z_df, 
       aes(x=`RADIO_PR`)) +
  geom_density(color="black",
               fill="light blue") +
  ggtitle("Z-score Standardisation")

ggarrange(r, s, z,
          ncol = 3,
          nrow = 1)
```
:::

## Computing proximity matrix

`dist()` supports 6 distance proximity calculations:

**euclidean, maximum, manhattan, canberra, binary and minkowski**. The default is *euclidean* proximity matrix.

```{r}
proxmat <- dist(shan_ict, method = 'euclidean')

proxmat
```

## Computing hierarchical clustering

`hclust()` employed agglomeration method to compute the cluster

Eight clustering algorithms:

**ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC)**

```{r}
hclust_ward <- hclust(proxmat, method = 'ward.D')
plot(hclust_ward, cex = 0.6)
```

## Selecting the optimal clustering algorithm

-   Identifying stronger clustering structures is a challenge in hierarchical clustering.

-   The `agnes()` function from the `cluster` package can help.

-   Key features of `agnes()`:

    -   Similar to `hclust()`.

    -   Provides the agglomerative coefficient.

-   A coefficient close to 1 indicates a strong clustering structure.

```{r}
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

ac <- function(x) {
  agnes(shan_ict, method = x)$ac
}

map_dbl(m, ac)
```

::: callout-note
Ward’s method provides the strongest clustering structure among the four methods assessed.

Hence, in the subsequent analysis, only Ward’s method will be used.
:::

## Determining Optimal Clusters

Another technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.

There are [three](https://statweb.stanford.edu/~gwalther/gap) commonly used methods to determine the optimal clusters, they are:

-   [Elbow Method](https://en.wikipedia.org/wiki/Elbow_method_(clustering))

-   [Average Silhouette Method](https://www.sciencedirect.com/science/article/pii/0377042787901257?via%3Dihub)

-   [Gap Statistic Method](http://www.web.stanford.edu/~hastie/Papers/gap.pdf)

#### Gap Statistic Method

-   The gap statistic compares the total variation within clusters for different values of k to their expected values under a random distribution.

-   The optimal number of clusters is the value that maximizes the gap statistic (i.e., produces the largest gap).

-   A larger gap indicates that the clustering structure is significantly different from a random distribution of points.

```{r}
set.seed(12345)
gap_stat <- clusGap(shan_ict, 
                    FUN = hcut, 
                    nstart = 25, 
                    K.max = 10, 
                    B = 50)
# Print the result
print(gap_stat, method = "firstmax")

fviz_gap_stat(gap_stat)
```

::: callout-note
With reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.

**Note:** In addition to these commonly used approaches, the [NbClust](https://cran.r-project.org/web/packages/NbClust/) package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods.
:::

## Interpreting the dendrograms

-   In the dendrogram, each leaf represents an observation.

-   As we move up, similar observations are grouped into branches, which merge at higher levels.

-   The vertical axis shows the height of fusion, indicating (dis)similarity:

    -   Higher fusion height means less similarity.

-   Proximity can only be assessed based on the height at which branches containing the two observations merge, not their horizontal distance.

-   To highlight selected clusters, use the `rect.hclust()` function in R, specifying border colors with the `border` argument.

```{r}
plot(hclust_ward, cex = 0.6)
rect.hclust(hclust_ward, 
            k = 6, 
            border = 2:5)
```

## Visually-driven hierarchical clustering analysis

```{r}
# Transforming the data frame into a matrix
shan_ict_mat <- data.matrix(shan_ict)

# Plotting interactive cluster heatmap using heatmaply()
heatmaply(normalize(shan_ict_mat),
          Colv=NA,
          dist_method = "euclidean",
          hclust_method = "ward.D",
          seriate = "OLO",
          colors = Blues,
          k_row = 6,
          margins = c(NA,200,60,NA),
          fontsize_row = 4,
          fontsize_col = 5,
          main="Geographic Segmentation of Shan State by ICT indicators",
          xlab = "ICT Indicators",
          ylab = "Townships of Shan State"
          )
```

## Mapping the clusters formed

```{r}
# Retain only 6 clusters
groups <- as.factor(cutree(hclust_ward, k=6))

# The output is called groups. It is a list object.

# In order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.
shan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%
  rename(`CLUSTER`=`as.matrix.groups.`)

# plot
qtm(shan_sf_cluster, "CLUSTER")
```

::: callout-note
The choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used.
:::
