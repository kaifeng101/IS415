[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "sf: Handles geospatial data, including points, lines, and polygons.\nreadr: Imports data from CSV files.\ndplyr: Performs relational joins to merge datasets.\nspdep: Computes spatial weights and calculates spatially lagged variables.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\n\nTwo data sets will be used:\n\nHunan county boundary layer: a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: contains selected Hunan’s local development indicators in 2012.\n\n\nImporting Geospatial DataImporting Aspatial Data\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#setup",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "sf: Handles geospatial data, including points, lines, and polygons.\nreadr: Imports data from CSV files.\ndplyr: Performs relational joins to merge datasets.\nspdep: Computes spatial weights and calculates spatially lagged variables.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\n\nTwo data sets will be used:\n\nHunan county boundary layer: a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: contains selected Hunan’s local development indicators in 2012.\n\n\nImporting Geospatial DataImporting Aspatial Data\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#performing-relational-join",
    "title": "Hands-on Exercise 5",
    "section": "2.0 Performing relational join",
    "text": "2.0 Performing relational join\nupdate the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe.\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 5",
    "section": "3.0 Visualising Regional Development Indicator",
    "text": "3.0 Visualising Regional Development Indicator\nDistribution of GDPPC 2012:\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5",
    "section": "4.0 Computing Contiguity Spatial Weights",
    "text": "4.0 Computing Contiguity Spatial Weights\n\nUse poly2nb() from the spdep package to find neighboring regions.\nThe function creates a list of neighboring areas based on shared borders.\nCan pass ‘queen’ as argument\n\ntake TRUE (default)/FALSE\nif FALSE -&gt; return a list of 1st order neighbours using the Queen criteria\n\n\n\nComputing (QUEEN) contiguity based neighboursCreating (ROOK) contiguity based neighbours\n\n\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\n\n\n\nExplanation\n\n\n\n\nTotal 88 area units in Hunana.\nMost connected area unit has 11 neighbours\n2 area units with only 1 neighbour\n\n\n\n\nTo see the neighbours:\neg. in 1st polygon in the object\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\n\n\n\n\n\n\nExplanation\n\n\n\n\nPolygon 1 has 5 neighbours.\nThe numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\n\n\n\n\n\nTo retrieve country name\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\n\n\nReveal country names of the 5 neighbouring polygons\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\n\n\nRetrieve GDPPC of these 5 countries\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\n\nDisplay the complete weight matrix\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\n\n\n\n\n\n\nExplanation\n\n\n\nTotal 88 area units in Hunan.\nMost connected area unit has 10 neighbours.\n2 area units with only 1 neighbour"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "Introduction\nThe Rise of Armed Conflict and the Potential of Geospatial Analytics\n\nImpact: Millions of lives are shattered by armed conflict each year.\nTrend: Armed conflict has been on the rise since around 2012, reversing the decline from the 1990s and early 2000s.\n\nRecent Major Conflicts:\n\nLibya, Syria, and Yemen (post-2011): Instabilities following the Arab uprisings.\nSahel Region: Crisis exacerbated by Libya’s instability.\nAzerbaijan-Armenian War (2020): Conflict over the Nagorno-Karabakh enclave.\nEthiopia’s Tigray Conflict (2020): Severe fighting in the northern region.\nMyanmar (2021): Conflict following the military’s power grab.\nRussia-Ukraine War (2022): Major assault by Russia on Ukraine.\nSudan and Gaza (2023): New devastating conflicts.\n\n\nCurrent Situation: The number of people affected—through death, displacement, or need for humanitarian aid—is higher than in decades.\n\nThis Geospatial Analytics will Focus on:\n\nObjective: This study will use spatial point patterns analysis to explore the spatial and spatio-temporal distribution of armed conflict in Myanmar.\nPotential: Geospatial analytics offer tremendous potential to address complex societal problems, providing insights into the patterns and dynamics of conflict.\n\nSource: 10 Conflicts to Watch in 2024\n\n\n\n1.0 Setup\n\n1.1 Installing R-Packages\n\nImporting and Transforming DataMapping displayDeriving Quarterly KDE LayersPerforming 2nd-Order Spatial Point Patterns AnalysisDeriving Quarterly Spatio-Temporal KDE LayersPerforming 2nd-Order Spatio-Temporal Point Patterns AnalysisDisplaying Maps with KDE and Spatio-temporal KDE Layers\n\n\n\nsf:\n\nFor handling spatial vector data and transforming it into simple features (sf) objects.\nFunctions like st_read() for importing spatial data and st_transform() for coordinate reference system transformations.\n\ntidyverse: For data manipulation and transformation, including functions for working with tibble data frames.\nreadr: For reading in CSV or other text-based data files if needed.\ndplyr: provide data manipulation capabilities (eg. to group and summarize the relationships between these columns)\n\n\n\n\npatchwork: To arrange map layout\n\n\n\n\nspatstat: For kernel density estimation (KDE) and spatial point pattern analysis.\nstars: For working with raster data and creating raster-based KDE layers.\nraster: Additional functions for raster operations, if necessary.\n\n\n\n\nspatstat: For analyzing second-order spatial point patterns, such as pair correlation functions.\nggplot2: For visualizing the results of spatial analysis.\nanimation, png, magick: For animation work\n\n\n\n\nspatstat: For spatio-temporal point pattern analysis and creating spatio-temporal KDE layers.\nstars: For handling spatio-temporal raster data.\n\n\n\n\nspatstat: For advanced spatio-temporal analysis, including the study of second-order effects over time.\n\n\n\n\ntmap: For creating thematic maps and displaying KDE layers.\nggplot2: For additional custom visualizations if needed.\nleaflet: For interactive maps, if required.\nosmdata: To fetch and integrate OpenStreetMap data for background maps.\n\n\n\n\n\npacman::p_load(tidyverse, sf, readr, spatstat, raster, ggstatsplot, ggplot2, tmap, osmdata, dplyr, patchwork, animation, png, magick)\n\n\n\n\n1.2 Data Acquisition\nWe will be using 2 sets of data:\n\nArmed Conflict DataAdministrative Boundary Data\n\n\n\nSource: Armed Conflict Location & Event Data (ACLED). ACLED is an independent, impartial international non-profit organization that collects data on violent conflict and protests worldwide.\nCoverage: Myanmar, from January 2021 to June 2024.\nEvent Types: Focus on at least four main event types:\n\nBattles\nExplosion/Remote Violence\nStrategic Developments\nViolence Against Civilians\n\nStudy Period: Quarterly armed conflict events from January 2021 to June 2024.\n\n\n\n\nSource: Myanmar Information Management Unit (MIMU).\nFor Broad Analysis:\n\nNational Boundaries: To get an overview of conflict patterns across the entire country.\nState and Region with Sub-region Boundaries: For understanding conflict distribution across larger administrative divisions.\n\nFor Detailed Local Analysis:\n\nDistrict Boundaries: Useful for a more detailed view of conflict distribution within specific districts.\nTownship and Ward Boundaries: For very granular analysis, especially useful if you’re interested in the impact at the community level.\n\nSelf-Administered Region Boundaries: For Analyzing Conflict Dynamics in Self-Administered Regions (SARs) Relative to Administrative Autonomy\n\n\n\n\n\n\n\n1.3 Importing Geospatial Data into R\n\nArmed Conflict DataAdministrative Boundaries\n\n\n\nacled_sf &lt;- read_csv(\"data/ACLED_Myanmar.csv\")\n\nRows: 51553 Columns: 31\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): event_id_cnty, event_date, disorder_type, event_type, sub_event_ty...\ndbl (11): year, time_precision, inter1, inter2, interaction, iso, latitude, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nFor Broad Analysis:\n\n\nnational_boundaries &lt;- st_read(dsn = \"data/National_Boundaries\", layer=\"mmr_polbnda_adm0_250k_mimu_1\")\n\nReading layer `mmr_polbnda_adm0_250k_mimu_1' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex01\\data\\National_Boundaries' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nstate_region_subregion_boundaries &lt;- st_read(dsn = \"data/State_And_Region_With_Sub-regions_Boundaries\", layer=\"mmr_polbnda2_adm1_250k_mimu_1\")\n\nReading layer `mmr_polbnda2_adm1_250k_mimu_1' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex01\\data\\State_And_Region_With_Sub-regions_Boundaries' \n  using driver `ESRI Shapefile'\nSimple feature collection with 18 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\n\nFor Detailed Local Analysis:\n\n\ndistrict_boundaries &lt;- st_read(dsn = \"data/District_Boundaries\", layer=\"mmr_polbnda_adm2_250k_mimu\")\n\nReading layer `mmr_polbnda_adm2_250k_mimu' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex01\\data\\District_Boundaries' \n  using driver `ESRI Shapefile'\nSimple feature collection with 80 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\ntownship_boundaries &lt;- st_read(dsn = \"data/Township_Boundaries\", layer=\"mmr_polbnda_adm3_250k_mimu_1\")\n\nReading layer `mmr_polbnda_adm3_250k_mimu_1' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex01\\data\\Township_Boundaries' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nward_boundaries &lt;- st_read(dsn = \"data/Ward_Boundaries\", layer=\"mmr_polbnda_adm5_mimu_v9_4\")\n\nReading layer `mmr_polbnda_adm5_mimu_v9_4' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex01\\data\\Ward_Boundaries' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1999 features and 15 fields (with 1 geometry empty)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.34521 ymin: 9.974381 xmax: 100.3662 ymax: 27.29535\nGeodetic CRS:  WGS 84\n\n\n\nSelf-Administered region Boundaries\n\n\nself_administered_boundaries &lt;- st_read(dsn = \"data/Self_Administered_Region_Boundaries\", layer=\"mmr_polbnda_self_administered_zones_1\")\n\nReading layer `mmr_polbnda_self_administered_zones_1' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex01\\data\\Self_Administered_Region_Boundaries' \n  using driver `ESRI Shapefile'\nSimple feature collection with 6 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 94.5777 ymin: 19.74308 xmax: 99.56572 ymax: 27.37205\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\n1.4 Checking Geospatial Data\n\nArmed Conflict DataAdministrative Boundaries\n\n\n\nclass(acled_sf)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\nst_crs(acled_sf)\n\nCoordinate Reference System: NA\n\n\n\n\n\n\n\n\nNote\n\n\n\nSince\n\nSince the class of acled_sf != sf object\n\n\n\nCoordinate Reference System of acled_sf = NA\n\nwe have to transform it.\n\n\n\n\n\nclass(national_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(national_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\nclass(state_region_subregion_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(state_region_subregion_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\nclass(district_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(district_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\nclass(township_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(township_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\nclass(ward_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(ward_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\nclass(self_administered_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(self_administered_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\n\n\n\n\nNote\n\n\n\nSince Coordinate Reference System of\n\nnational_boundaries\nstate_region_subregion_boundaries\ndistrict_boundaries\ntownship_boundaries\nward_boundaries\nself_administered_boundaries\n\nis in 4326 (unit of measurement = degree), we have to transform it\n\n\n\n\n\n\n\n\n1.5 Understanding the data\n\n# Select relevant columns and group by disorder_type, event_type, sub_event_type\ntype_of_conflict &lt;- acled_sf %&gt;%\n  dplyr::select(disorder_type, event_type, sub_event_type) %&gt;%\n  group_by(disorder_type, event_type, sub_event_type) %&gt;%\n  summarize(count = n(), .groups = 'drop')  # Count occurrences of each combination\nprint(type_of_conflict, n = Inf)\n\n# A tibble: 25 × 4\n   disorder_type                      event_type            sub_event_type count\n   &lt;chr&gt;                              &lt;chr&gt;                 &lt;chr&gt;          &lt;int&gt;\n 1 Demonstrations                     Protests              Peaceful prot…  8132\n 2 Demonstrations                     Protests              Protest with …   463\n 3 Demonstrations                     Riots                 Violent demon…    94\n 4 Political violence                 Battles               Armed clash    11770\n 5 Political violence                 Battles               Government re…     5\n 6 Political violence                 Battles               Non-state act…   274\n 7 Political violence                 Explosions/Remote vi… Air/drone str…  2646\n 8 Political violence                 Explosions/Remote vi… Chemical weap…     1\n 9 Political violence                 Explosions/Remote vi… Grenade          393\n10 Political violence                 Explosions/Remote vi… Remote explos…  5511\n11 Political violence                 Explosions/Remote vi… Shelling/arti…  3655\n12 Political violence                 Explosions/Remote vi… Suicide bomb       2\n13 Political violence                 Riots                 Mob violence      22\n14 Political violence                 Violence against civ… Abduction/for…   905\n15 Political violence                 Violence against civ… Attack          5257\n16 Political violence                 Violence against civ… Sexual violen…    63\n17 Political violence; Demonstrations Protests              Excessive for…   234\n18 Strategic developments             Strategic developmen… Agreement         10\n19 Strategic developments             Strategic developmen… Arrests         4833\n20 Strategic developments             Strategic developmen… Change to gro…  1346\n21 Strategic developments             Strategic developmen… Disrupted wea…   325\n22 Strategic developments             Strategic developmen… Headquarters …    67\n23 Strategic developments             Strategic developmen… Looting/prope…  4042\n24 Strategic developments             Strategic developmen… Non-violent t…    28\n25 Strategic developments             Strategic developmen… Other           1475\n\n\n\n\n\n\n\n\nNote!\n\n\n\nThe dataset includes non-conflict events such as:\n\n“Change to group/activity”\n“Agreement”\n“Headquarters or base established”\n\nAdditionally, it contains a sub-event category labeled “Other”. Including these non-conflict events under the general category of “conflict nature” may lead to biased or misleading interpretations. To ensure accurate and meaningful analysis, I recommend removing these non-conflict events from the dataset.\n\n\n\n\n\n1.6 Data Preparation and Wrangling\n\nArmed Conflict DataAdministrative Boundaries\n\n\n\nConvert Data Frame to sf Object\n\nacled_sf &lt;- acled_sf %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\nclass(acled_sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\nTransform Coordinate Reference System\n\nacled_sf &lt;- acled_sf %&gt;%\n  st_transform(crs = 32647)\n\n\n\nConvert Date Column to Date Format\n\nacled_sf &lt;- acled_sf %&gt;%\n  mutate(event_date = dmy(event_date))\n\n\n\nEliminating Columns not used for analysis\n\nacled_sf &lt;- acled_sf[, !(names(acled_sf) %in% c(\"event_id_cnty\", \"time_precision\", \"inter1\", \"inter2\", \"notes\", \"tags\"))]\n\n\n\nPreparing Data for Quarterly KDE Analysis\n\nCreate a Quarter Column\n\n\nacled_sf &lt;- acled_sf %&gt;%\n  mutate(quarter = paste0(\"Q\", quarter(event_date), \"-\", year(event_date)))\n\n\nRemove non-conflict data\n\n\nnon_conflict_events &lt;- c(\n  \"Change to group/activity\",\n  \"Agreement\",\n  \"Headquarters or base established\",\n  \"Other\"\n)\n\n# Filter out the non-conflict events from the dataset\nconflict_acled_sf_data &lt;- acled_sf %&gt;%\n  filter(!sub_event_type %in% non_conflict_events)\n\n\n\nAdding a new analysis dimension: month\n\nconflict_acled_sf_data &lt;- conflict_acled_sf_data %&gt;%\n  mutate(month = month(event_date))\n\n\n\n\n\nTransform the Coordinate Reference System of these:\n\nnational_boundaries &lt;- national_boundaries %&gt;%\n  st_transform(crs = 32647)\n\nstate_region_subregion_boundaries &lt;- state_region_subregion_boundaries %&gt;%\n  st_transform(crs = 32647)\n\ndistrict_boundaries &lt;- district_boundaries %&gt;%\n  st_transform(crs = 32647)\n\ntownship_boundaries &lt;- township_boundaries %&gt;%\n  st_transform(crs = 32647)\n\nward_boundaries &lt;- ward_boundaries %&gt;%\n  st_transform(crs = 32647)\n\nself_administered_boundaries &lt;- self_administered_boundaries %&gt;%\n  st_transform(crs = 32647)\n\n\n\nSample plot\n\nggplot(data = state_region_subregion_boundaries) +\n  geom_sf() +\n  theme_minimal() +\n  labs(title = \"Map of Geometries\",\n       subtitle = \"Displaying multipolygon geometries\",\n       caption = \"Source: Example Data\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.0 Exploratory Data Analysis\n\n2.1 Temporal Analysis: Frequency of Conflict Events Over Time\n\nggplot(conflict_acled_sf_data, aes(x = event_date)) +\n  geom_histogram(binwidth = 30, fill = \"steelblue\", color = \"black\") +\n  labs(title = \"Conflict Events Over Time\", x = \"Date\", y = \"Number of Events\")\n\n\n\n\n\n\n\n\n\n\n2.2 Event Type Distribution\n\nggplot(conflict_acled_sf_data, aes(x = event_date, fill = event_type)) +\n  geom_histogram(binwidth = 30) +\n  labs(title = \"Event Types Over Time\", x = \"Date\", y = \"Number of Events\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n2.3 Spatial Analysis\n\n# Plot a choropleth of the conflict events by year using ggplot2\nggplot() +\n  geom_sf(data = national_boundaries, fill = \"lightgrey\") +\n  geom_sf(data = conflict_acled_sf_data, aes(color = event_type), size = 0.1, alpha = 0.6) +\n  facet_wrap(~year, ncol = 4) +  # Facet by year with 4 columns\n  labs(title = \"Spatial Distribution of Conflict Events by Year\", color = \"Event Type\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") + \n  guides(color = guide_legend(override.aes = list(size = 1)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nFrom 2021 to 2024, the conflicts in Myanmar have escalated significantly, evolving from largely peaceful protests to increasingly violent confrontations and armed battles.\n\n\n\n\n2.4 Conflict Hotspots by state & region\n\n2.4.1 Preparing the hotspots\n\n# Ensure the CRS of both datasets match\nconflict_acled_sf_data &lt;- st_transform(conflict_acled_sf_data, crs = st_crs(state_region_subregion_boundaries))\n\n# Perform spatial join to add state/region information to the conflict dataset\nacled_with_state_region &lt;- st_join(conflict_acled_sf_data, state_region_subregion_boundaries, join = st_intersects)\n\n# Filter out rows where ST is NA before summarizing\nacled_with_state_region &lt;- acled_with_state_region %&gt;%\n  filter(!is.na(ST))\n\n# Group by state/region and summarize conflict data\nconflict_summary_by_state_region &lt;- acled_with_state_region %&gt;%\n  group_by(ST, event_type, year) %&gt;%\n  summarise(\n    total_conflicts = n(),\n    total_fatalities = sum(fatalities, na.rm = TRUE),\n    .groups = 'drop'\n  )\n\n# Convert district boundaries to a regular data frame (non-spatial)\nstate_region_boundaries_df &lt;- as.data.frame(state_region_subregion_boundaries)\n\n# Merge the summary data with the district boundaries data frame\nstate_region_boundaries_summary &lt;- state_region_boundaries_df %&gt;%\n  left_join(conflict_summary_by_state_region, by = c(\"ST\" = \"ST\"))\n\n# Convert back to an sf object with geometry\nstate_region_boundaries_summary &lt;- st_as_sf(state_region_boundaries_summary, crs = st_crs(state_region_subregion_boundaries))\n\n\n\n2.4.2 Plot the Hotspots\n\n# Base map with state/region boundaries\nstate_region_hotspot_tm &lt;- tm_shape(state_region_boundaries_summary) +\n  tm_polygons(col = \"lightgrey\", border.col = \"black\") +\n  \n  # Overlay conflict data\n  tm_shape(conflict_summary_by_state_region) +\n  tm_dots(\n    col = \"event_type\", \n    palette = \"viridis\", \n    size = \"total_conflicts\", \n    alpha = 0.6)  +\n  \n  # Layout adjustments\n  tm_layout(\n    frame = FALSE,  # Remove the frame around the plot\n    legend.outside = TRUE,  # Keep the legend outside\n    legend.outside.position = \"bottom\",  # Position the legend outside at the bottom\n    legend.outside.size = 0.1,  # Adjust the size of the outside legend (reduce if too large)\n  ) +\n  \n  # Faceting by state/region\n  tm_facets(\n    by = c(\"ST\"),\n    free.scales = FALSE  # Use a common scale across all facets\n  )\n\nprint(state_region_hotspot_tm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nThis map illustrates conflict patterns across a four-year period, revealing significant regional variations. It highlights that certain states and regions experience relatively lower levels of conflict, indicating greater overall peace.\nConversely, other areas show higher concentrations of specific types of conflicts. This distribution helps identify regions with frequent conflict events and those more prone to particular conflict types, offering valuable insights into the geographical and thematic spread of conflicts.\n\n\n\n\n2.4.3 Visualize by Event Type\n\n# Define the conflict types\nconflict_types &lt;- c(\"Battles\", \"Protests\", \"Strategic developments\", \"Explosions/Remote violence\", \"Riots\", \"Violence against civilians\")\n\n# Initialize an empty list to store summaries\nconflict_summaries &lt;- list()\n\n# Loop through each conflict type and summarize the data\nfor (type in conflict_types) {\n  summary &lt;- acled_with_state_region %&gt;%\n    filter(event_type == type) %&gt;%\n    group_by(ST) %&gt;%\n    summarise(\n      total_events = n(),\n      .groups = 'drop'\n    )\n  \n  # Store the summary in the list with the conflict type as the key\n  conflict_summaries[[type]] &lt;- summary\n}\n\n# Convert district boundaries to a regular data frame (non-spatial)\nstate_region_subregion_boundaries_df &lt;- as.data.frame(state_region_subregion_boundaries)\n\n# Merge each summary with the district boundaries data frame\nregion_conflict_summaries &lt;- lapply(conflict_summaries, function(summary) {\n  region_summary &lt;- state_region_subregion_boundaries_df %&gt;%\n    left_join(summary, by = \"ST\")\n  \n  # Convert back to an sf object with geometry\n  st_as_sf(region_summary, crs = st_crs(state_region_subregion_boundaries))\n})\n\n# Rename the list elements for clarity\nnames(region_conflict_summaries) &lt;- conflict_types\n\n\n# Create a list to store plots\nplots &lt;- list()\n\n# Loop through each conflict type to create a plot\nfor (type in conflict_types) {\n  plots[[type]] &lt;- tm_shape(region_conflict_summaries[[type]]) +\n    tm_polygons(\n      col = \"total_events\", \n      palette = \"Reds\", \n      title = paste(\"Number of\", type),\n      border.col = \"black\",\n      style = \"quantile\"  # This divides the data into quantiles for better visualization\n    ) +\n    \n    tm_text(\n      text = \"ST\",  # Use the column name that contains the region names\n      size = 0.6,        # Adjust the size as needed\n      col = \"black\",     # Text color\n      shadow = TRUE,    # Optional: Add shadow to make text more readable\n      remove.overlap = TRUE  # Avoid text overlapping\n    ) +\n    \n    tm_layout(\n      frame = FALSE,  # Remove the frame around the plot\n      legend.outside = TRUE,  # Keep the legend outside\n      legend.outside.position = \"right\",  # Position the legend outside at the bottom\n      legend.outside.size = 0.4  # Adjust the size of the outside legend (reduce if too large)\n    ) +\n    \n    tm_legend(\n      position = c(\"right\", \"bottom\")  # Position the legend outside at the bottom\n    )\n}\n\n\n# Arrange all plots in a single view using tm_arrange\ncombined_plot &lt;- tmap_arrange(plots, ncol = 2, nrow = 3, \n                             legend.position = c(\"right\", \"bottom\"), \n                             legend.outside = TRUE)\n\n# Print the combined plot\nprint(combined_plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.0 Deriving Quarterly KDE layers\nKernel Density Estimation (KDE) provides a comprehensive view of where conflicts are occurring by visualizing the density of events across different quarters. By analyzing KDE on a quarterly basis, we can identify areas with high conflict intensity and gain insights into how the distribution of conflicts evolves over time. This approach helps in understanding temporal patterns and hotspots, offering a more detailed perspective on conflict dynamics.\nFor quarterly KDE layers:\n\nSubset data by quarter and compute KDE for each subset using spatstat\n\n\n\n\n\n\n\nNote on Handling Duplicate Points\n\n\n\nDuplicate points are removed in the analysis to avoid artificially inflating the density estimate. Including duplicates could lead to an exaggerated representation of conflict hotspots, as each duplicate would incorrectly suggest multiple occurrences of the same event. By removing duplicates, we ensure that the Kernel Density Estimation (KDE) reflects the true intensity and distribution of distinct armed conflict events, providing a more accurate and reliable identification of hotspots.\n\n\n\n1. Create a list to store KDE for each quarter\n\nkde_list &lt;- list()\n\n\n\n2. Get Unique Quarters\n\nquarters &lt;- unique(conflict_acled_sf_data$quarter)\n\n\n\n3. Perform Kernel Density Estimation (KDE)\n\nboundary_window &lt;- as.owin(national_boundaries)\n\n# Loop over each quarter to process data\nfor (q in quarters) {\n  \n  # Filter the dataset for the current quarter\n  quarter_data &lt;- conflict_acled_sf_data %&gt;%\n    filter(quarter == q)\n  \n  # Remove duplicates\n  coords &lt;- st_coordinates(st_geometry(quarter_data))\n  if (any(duplicated(coords))) {\n    quarter_data &lt;- quarter_data %&gt;%\n      distinct(st_coordinates(st_geometry(.)), .keep_all = TRUE)\n  }\n  \n  # Convert the filtered data to a spatial point pattern (ppp object)\n  quarter_ppp &lt;- as.ppp(st_geometry(quarter_data), W = boundary_window)\n  \n  # Perform Kernel Density Estimation (KDE)\n  kde &lt;- density(quarter_ppp, sigma = 0.1)  # Adjust sigma as needed for smoothness\n  \n  # Store KDE in the list\n  kde_list[[q]] &lt;- kde\n}\n\nWarning: 2 points were rejected as lying outside the specified window\n\n\nWarning: 1 point was rejected as lying outside the specified window\nWarning: 1 point was rejected as lying outside the specified window\nWarning: 1 point was rejected as lying outside the specified window\n\n\n\n\n4. Plot the KDE for Each Quarter\n\npar(mfcol=c(5, 3))\n# Plot the KDEs for all quarters\nfor (q in quarters) {\n  if (!is.null(kde_list[[q]])) {\n    plot(kde_list[[q]], main = paste(\"KDE for\", q))\n  } else {\n    print(paste(\"No KDE available for quarter:\", q))\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n3.0 Performing 2nd-Order Spatial Point Patterns Analysis\nNow, we will explore how armed conflict events are distributed and related.\nRipley’s K-function is a useful tool for detecting whether events are clustered or spread out. It measures how the density of events changes with distance, helping to identify clustering or dispersion.\nWhereas G-Function examine the nearest-neighbor distances and understand how far apart the nearest events are.\nF-Function analyze the distribution of distances from a randomly chosen location to the nearest event\n\nComputing K-Function Estimation\n\n# Initialize list to store K-function results\nkfunction_list &lt;- list()\n\n# Get unique quarters from the dataset\nquarters &lt;- unique(conflict_acled_sf_data$quarter)\n\n# Loop over each quarter to compute K-function\nfor (q in quarters) {\n  \n  # Filter the dataset for the current quarter\n  quarter_data &lt;- conflict_acled_sf_data %&gt;%\n    filter(quarter == q)\n  \n  # Remove duplicates\n  coords &lt;- st_coordinates(st_geometry(quarter_data))\n  if (any(duplicated(coords))) {\n    quarter_data &lt;- quarter_data %&gt;%\n      distinct(st_coordinates(st_geometry(.)), .keep_all = TRUE)\n  }\n  \n  # Convert the filtered data to a spatial point pattern (ppp object)\n  quarter_ppp &lt;- as.ppp(st_geometry(quarter_data), W = as.owin(national_boundaries))\n  \n  # Compute the K-function\n  kfunction &lt;- Kest(quarter_ppp, correction = \"border\")\n  \n  # Store the K-function in the list\n  kfunction_list[[q]] &lt;- kfunction\n}\n\nWarning: 2 points were rejected as lying outside the specified window\n\n\nWarning: 1 point was rejected as lying outside the specified window\nWarning: 1 point was rejected as lying outside the specified window\nWarning: 1 point was rejected as lying outside the specified window\n\n\n\n\n\n\n\n\nNote\n\n\n\nRipley’s Correction: Provides a more sophisticated adjustment for edge effects by modifying the expected K-function, leading to potentially more accurate results in large areas. Border Correction: Simplifies the adjustment by extending the study area and is less computationally intensive but might be less accurate in areas with significant boundary effects.\nWe use correction = “border” rather than correction = “Ripley” for our analysis. Our primary goal is to observe the general distribution of conflict hotspots, which will guide more detailed follow-up studies. Given that our focus is on broad patterns rather than precise details, the simpler and less computationally intensive border correction is sufficient. While Ripley’s correction offers more accuracy by adjusting for edge effects, it requires more computational resources and time, which we can afford to forego for this preliminary analysis.\n\n\n\n\nPlotting K-Function\nInterpretation:\n\nAbove the theoretical line: Indicates clustering of points.\nBelow the theoretical line: Suggests dispersion or regularity.\nClose to the line: Implies a random distribution.\n\n\npar(mfcol=c(5, 3))\n# Plot the K-functions for all quarters\nfor (q in quarters) {\n  if (!is.null(kfunction_list[[q]])) {\n    # Plot K-function\n    plot(kfunction_list[[q]], . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\", main = paste(\"K-function for Quarter\", q))\n  } else {\n    print(paste(\"No K-function available for quarter:\", q))\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n4.0 Deriving Quarterly spatio-temporal KDE layers\n\n# Define the output directory for saving KDE plots\noutput_dir &lt;- \"quarterly_kde_images\"\ndir.create(output_dir, showWarnings = FALSE)\n\n# Define a list to hold filenames of saved KDE plots\nsaved_files &lt;- list()\n\n# Define a function to create and save KDE plots for each quarter\nsave_kde_plot &lt;- function(kde, quarter, output_dir) {\n  # Create a file path for the KDE image\n  file_name &lt;- file.path(output_dir, paste0(\"quarterly_kde_\", gsub(\" \", \"_\", quarter), \".png\"))\n  \n  # Open a PNG device to save the plot\n  png(file_name, width = 800, height = 800)\n  \n  # Plot KDE\n  plot(kde, main = paste(\"Spatio-Temporal KDE for\", quarter))\n  \n  # Close the PNG device\n  dev.off()\n  \n  # Print confirmation message\n  print(paste(\"Saved:\", file_name))\n  \n  # Return the filename of the saved plot\n  return(file_name)\n}\n\n# Generate and save KDE plots for each quarter in reverse chronological order\nfor (q in rev(quarters)) {\n  if (!is.null(kde_list[[q]])) {\n    file_name &lt;- save_kde_plot(kde_list[[q]], q, output_dir)\n    saved_files &lt;- append(saved_files, file_name)\n  } else {\n    print(paste(\"No KDE data available for quarter:\", q))\n  }\n}\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q1-2021.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q2-2021.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q3-2021.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q4-2021.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q1-2022.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q2-2022.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q3-2022.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q4-2022.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q1-2023.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q2-2023.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q3-2023.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q4-2023.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q1-2024.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q2-2024.png\"\n\n\n\n# Load saved images and combine them into an animated GIF\nimages &lt;- lapply(saved_files, image_read)\n\n# Create an animation from the KDE images\nanimation &lt;- image_animate(image_join(images), fps = 1)\n\n# Define the path for the GIF animation\ngif_path &lt;- \"spatio_temporal_kde_animation.gif\"\n\n# Save the animation as a GIF file\nimage_write(animation, path = gif_path)\n\n# Print confirmation that the GIF was saved\nprint(\"Spatio-temporal KDE animation saved as spatio_temporal_kde_animation.gif\")\n\n[1] \"Spatio-temporal KDE animation saved as spatio_temporal_kde_animation.gif\"\n\n# Display the GIF using magick\ngif_image &lt;- image_read(gif_path)\nprint(gif_image) \n\n# A tibble: 14 × 7\n   format width height colorspace matte filesize density\n   &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n 1 GIF      800    800 sRGB       FALSE        0 72x72  \n 2 GIF      800    800 sRGB       FALSE        0 72x72  \n 3 GIF      800    800 sRGB       FALSE        0 72x72  \n 4 GIF      800    800 sRGB       FALSE        0 72x72  \n 5 GIF      800    800 sRGB       FALSE        0 72x72  \n 6 GIF      800    800 sRGB       FALSE        0 72x72  \n 7 GIF      800    800 sRGB       FALSE        0 72x72  \n 8 GIF      800    800 sRGB       FALSE        0 72x72  \n 9 GIF      800    800 sRGB       FALSE        0 72x72  \n10 GIF      800    800 sRGB       FALSE        0 72x72  \n11 GIF      800    800 sRGB       FALSE        0 72x72  \n12 GIF      800    800 sRGB       FALSE        0 72x72  \n13 GIF      800    800 sRGB       FALSE        0 72x72  \n14 GIF      800    800 sRGB       FALSE        0 72x72  \n\n\n\n\n\n\n\n\n\n\n\n5.0 Performing 2nd-Order Spatio-temporal Point Patterns\n\n# Define the output directory for saving K-function plots\nkfunction_output_dir &lt;- \"quarterly_kfunction_images\"\ndir.create(kfunction_output_dir, showWarnings = FALSE)\n\n# Define a list to hold filenames of saved K-function plots\nkfunction_files &lt;- list()\n\n# Define a function to create and save K-function plots for each quarter\nsave_kfunction_plot &lt;- function(kfunction, quarter, output_dir) {\n  # Create a file path for the K-function image\n  file_name &lt;- file.path(output_dir, paste0(\"quarterly_kfunction_\", gsub(\" \", \"_\", quarter), \".png\"))\n  \n  # Open a PNG device to save the plot\n  png(file_name, width = 800, height = 800)\n  \n  # Plot K-function\n  plot(kfunction, . -r ~ r, ylab = \"K(d) - d\", xlab = \"d (m)\", main = paste(\"Ripley's K-function for Quarter\", quarter))\n  \n  # Close the PNG device\n  dev.off()\n  \n  # Print confirmation message\n  print(paste(\"Saved:\", file_name))\n  \n  # Return the filename of the saved plot\n  return(file_name)\n}\n\n# Save K-function plots for each quarter\nfor (q in rev(quarters)) {\n  if (!is.null(kfunction_list[[q]])) {\n    file_name &lt;- save_kfunction_plot(kfunction_list[[q]], q, kfunction_output_dir)\n    kfunction_files &lt;- append(kfunction_files, file_name)\n  } else {\n    print(paste(\"No K-function data available for quarter:\", q))\n  }\n}\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q1-2021.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q2-2021.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q3-2021.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q4-2021.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q1-2022.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q2-2022.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q3-2022.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q4-2022.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q1-2023.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q2-2023.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q3-2023.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q4-2023.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q1-2024.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q2-2024.png\"\n\n\n\n# Load saved images and combine them into an animated GIF\nkfunction_images &lt;- lapply(kfunction_files, image_read)\n\n# Create an animation from the K-function images\nkfunction_animation &lt;- image_animate(image_join(kfunction_images), fps = 1)\n\n# Define the path for the GIF animation\nkfunction_gif_path &lt;- \"spatio_temporal_kfunction_animation.gif\"\n\n# Save the animation as a GIF file\nimage_write(kfunction_animation, path = kfunction_gif_path)\n\n# Print confirmation that the GIF was saved\nprint(\"Ripley's K-function animation saved as spatio_temporal_kfunction_animation.gif\")\n\n[1] \"Ripley's K-function animation saved as spatio_temporal_kfunction_animation.gif\"\n\n# Display the GIF using magick\nkfunction_gif_image &lt;- image_read(kfunction_gif_path)\nprint(kfunction_gif_image)\n\n# A tibble: 14 × 7\n   format width height colorspace matte filesize density\n   &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n 1 GIF      800    800 sRGB       FALSE        0 72x72  \n 2 GIF      800    800 sRGB       FALSE        0 72x72  \n 3 GIF      800    800 sRGB       FALSE        0 72x72  \n 4 GIF      800    800 sRGB       FALSE        0 72x72  \n 5 GIF      800    800 sRGB       FALSE        0 72x72  \n 6 GIF      800    800 sRGB       FALSE        0 72x72  \n 7 GIF      800    800 sRGB       FALSE        0 72x72  \n 8 GIF      800    800 sRGB       FALSE        0 72x72  \n 9 GIF      800    800 sRGB       FALSE        0 72x72  \n10 GIF      800    800 sRGB       FALSE        0 72x72  \n11 GIF      800    800 sRGB       FALSE        0 72x72  \n12 GIF      800    800 sRGB       FALSE        0 72x72  \n13 GIF      800    800 sRGB       FALSE        0 72x72  \n14 GIF      800    800 sRGB       FALSE        0 72x72  \n\n\n\n\n\n\n\n\n\n\n\n6.0 KDE and Spatio-temporal KDE layers on openstreetmap of Myanmar\n\n6.1 Download OSM Data for Mynmar\n\n# Get bounding box for Myanmar\nbbox_myanmar &lt;- getbb(\"Yangon\")\n\n# Create Overpass query\nquery &lt;- opq(bbox = bbox_myanmar) \n\n# Download data\nosm_data &lt;- osmdata_sf(query)\n\n\n# Create a basic plot of the OSM data using tmap\ntm_shape(osm_data$osm_points) +\n  tm_dots( # Using tm_dots instead of tm_lines for point data\n    col = \"blue\", # Color of the dots\n    size = 0.01, # Size of the dots (adjust as needed)\n    alpha = 0.7 # Transparency of the dots\n  ) +\n  tm_layout(\n    frame = FALSE, # Remove the frame around the plot\n    legend.outside = TRUE, # Place the legend outside the plot\n    legend.outside.position = \"bottom\", # Position the legend outside at the bottom\n    legend.outside.size = 0.1 # Adjust the size of the outside legend (reduce if too large)\n  ) +\n  tm_scale_bar() # Add a scale bar to the map\n\n\n\n6.2 Extract Points and Prepare Data for KDE\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nacled_sf %&gt;% \n  filter(year == 2024 |\n           event_type == \"Polticial Violence\") %&gt;% \n  tm_shape() +\n  tm_dots()\n\n\n\n\n\n\n\n\n\n# Prepare a list to store tmap objects for each quarter\ntmap_list &lt;- list()\n\n# Loop through each quarter\nfor (q in quarters) {\n  \n  # Filter the dataset for the current quarter\n  quarter_data &lt;- conflict_acled_sf_data %&gt;%\n    filter(quarter == q)\n  \n  # Remove duplicates\n  coords &lt;- st_coordinates(st_geometry(quarter_data))\n  if (any(duplicated(coords))) {\n    quarter_data &lt;- quarter_data %&gt;%\n      distinct(st_coordinates(st_geometry(.)), .keep_all = TRUE)\n  }\n  \n  # Create a tmap visualization\n  tmap_plot &lt;- tm_shape(state_region_subregion_boundaries) +\n    tm_polygons() +\n    tm_shape(quarter_data) +\n    tm_dots(size = 0.01, col = \"event_type\", title = \"Conflicts\") +\n    tm_layout(title = paste(\"Conflicts for\", q),\n              title.size = 1.2,\n              legend.outside = TRUE)\n  \n  # Store the tmap object in the list\n  tmap_list[[q]] &lt;- tmap_plot\n}\n\n# Print all tmap plots\nfor (q in quarters) {\n  if (!is.null(tmap_list[[q]])) {\n    print(tmap_list[[q]])\n  } else {\n    print(paste(\"No data available for quarter:\", q))\n  }\n}"
  },
  {
    "objectID": "Notes/Lesson_2.html",
    "href": "Notes/Lesson_2.html",
    "title": "Notes 2",
    "section": "",
    "text": "A type of thematic map, areas shaded, values aggregated into geographical layer (eg. subzone)\nThe shading is the things we want to map (eg. Dependency ratio)\n\n\n\n\n\n\ncombines areal units into small no. of groups (10 methods eg. ‘equal’, ‘quantile’)\n\nNo. of Classes\n\nif &lt;4, overly generalized map [Can use depending on context, eg. USA election, red camp VS blue camp]\nkeep &lt;= 12, 7/8 shades of the same color\nif too many, our eyes cannot differentiate them wel\n\n\nequal = divide into same range (not suitable for highly skewed data set)\nquantile -&gt; into different percentage\nnatural breaks (a.k.a. jenks) -&gt; fuse between equal & quantile method\nstandard deviation -&gt; if data is normal distribution only\n\n\n\n\nmap it to the color, spectrum (the value) (eg. 0 -&gt; 223)\n\n\n\n\n\n\n* Nominal Color Scheme -&gt; Only for categorical data\n\n\n\n\n\n\n\nColor Scheme\nRemarks\n\n\n\n\n\nOnly for categorical data\n\n\n\nFor continuous\n+\nAll value +/-\n\n\n\nFor continuous\n+\nValue have both +/- only"
  },
  {
    "objectID": "Notes/Lesson_2.html#types-of-choropleth-map",
    "href": "Notes/Lesson_2.html#types-of-choropleth-map",
    "title": "Notes 2",
    "section": "",
    "text": "combines areal units into small no. of groups (10 methods eg. ‘equal’, ‘quantile’)\n\nNo. of Classes\n\nif &lt;4, overly generalized map [Can use depending on context, eg. USA election, red camp VS blue camp]\nkeep &lt;= 12, 7/8 shades of the same color\nif too many, our eyes cannot differentiate them wel\n\n\nequal = divide into same range (not suitable for highly skewed data set)\nquantile -&gt; into different percentage\nnatural breaks (a.k.a. jenks) -&gt; fuse between equal & quantile method\nstandard deviation -&gt; if data is normal distribution only\n\n\n\n\nmap it to the color, spectrum (the value) (eg. 0 -&gt; 223)"
  },
  {
    "objectID": "Notes/Lesson_2.html#colour-scheme--colorbrewer",
    "href": "Notes/Lesson_2.html#colour-scheme--colorbrewer",
    "title": "Notes 2",
    "section": "",
    "text": "* Nominal Color Scheme -&gt; Only for categorical data\n\n\n\n\n\n\n\nColor Scheme\nRemarks\n\n\n\n\n\nOnly for categorical data\n\n\n\nFor continuous\n+\nAll value +/-\n\n\n\nFor continuous\n+\nValue have both +/- only"
  },
  {
    "objectID": "Notes/Lesson_2.html#shape-objects",
    "href": "Notes/Lesson_2.html#shape-objects",
    "title": "Notes 2",
    "section": "Shape objects",
    "text": "Shape objects\n\n\ntmap element\n-&gt; always start with tm_shape()\n* Put plus(+) sign to indicate it is a continuous code (Put it at the back)\n\n-&gt; can later add\n\n-&gt;can choose from this list\n\n\n\n\ntm_polygons()\n\ndefault classes = 5bins\ndefault classification method = “pretty”\ndefault color scheme = “YIOrRd” (yellow-orange)\nmissing value = gray\n\n\n\n\ntm_border()\n\ndefault lwd (border line width) = 1\nalpha = between 0 (totally transparent) and 1 (not transparent)\n\nDefault alpha = 1\n\ncol (border color)\ndefault lty (border line type) = “solid”"
  },
  {
    "objectID": "Notes/Lesson_2.html#map-geographical-data",
    "href": "Notes/Lesson_2.html#map-geographical-data",
    "title": "Notes 2",
    "section": "Map & Geographical Data",
    "text": "Map & Geographical Data"
  },
  {
    "objectID": "Notes/Lesson_2.html#geo-vs-aspatial-data",
    "href": "Notes/Lesson_2.html#geo-vs-aspatial-data",
    "title": "Notes 2",
    "section": "Geo VS Aspatial Data",
    "text": "Geo VS Aspatial Data\n\n\n\n\n\n\n\n\n\nReference Maps\nshow buildings, roads, vegetation, rivers\neg. topo map like Google Map\n\n\nThematic Map\n\nemphasize the spatial pattern of geographic attributes or statistics about places and relationships between places such as Life in Los Angeles."
  },
  {
    "objectID": "Notes/Lesson_2.html#qualitative-thematic-map",
    "href": "Notes/Lesson_2.html#qualitative-thematic-map",
    "title": "Notes 2",
    "section": "Qualitative Thematic Map",
    "text": "Qualitative Thematic Map\n\n\n\n\n\n\n\nPoint symbol map\nUse point to represent school types\n\n\n\nLine symbol map\nShow road network\nDifferent color intensity and thickness are used to differentiate hierarchy of roads\n\n\n\nArea Map\ndifferent colors to represent different land use types"
  },
  {
    "objectID": "Notes/Lesson_2.html#proportional-symbol-map",
    "href": "Notes/Lesson_2.html#proportional-symbol-map",
    "title": "Notes 2",
    "section": "Proportional Symbol Map",
    "text": "Proportional Symbol Map\nUse symbols of different sizes to represent data associated with different areas\n\nGo for this kind:"
  },
  {
    "objectID": "Notes/Lesson_2.html#proportional-symbol-map--bar-chart-map",
    "href": "Notes/Lesson_2.html#proportional-symbol-map--bar-chart-map",
    "title": "Notes 2",
    "section": "Proportional Symbol Map -Bar Chart Map",
    "text": "Proportional Symbol Map -Bar Chart Map"
  },
  {
    "objectID": "Notes/Lesson_2.html#proportional-symbol-map--pie-chart-map",
    "href": "Notes/Lesson_2.html#proportional-symbol-map--pie-chart-map",
    "title": "Notes 2",
    "section": "Proportional Symbol Map -Pie Chart Map",
    "text": "Proportional Symbol Map -Pie Chart Map"
  },
  {
    "objectID": "Notes/Lesson_2.html#proportional-symbol-map--junk-map",
    "href": "Notes/Lesson_2.html#proportional-symbol-map--junk-map",
    "title": "Notes 2",
    "section": "Proportional Symbol Map -Junk Map",
    "text": "Proportional Symbol Map -Junk Map\n\n* ensure geographical lvl used is same"
  },
  {
    "objectID": "Notes/Lesson_2.html#brick-map",
    "href": "Notes/Lesson_2.html#brick-map",
    "title": "Notes 2",
    "section": "Brick Map",
    "text": "Brick Map\n\nbetter to encode quantitative info graphically"
  },
  {
    "objectID": "Notes/Lesson_2.html#bricks-vs-proportional-symbol-map",
    "href": "Notes/Lesson_2.html#bricks-vs-proportional-symbol-map",
    "title": "Notes 2",
    "section": "Bricks VS Proportional Symbol Map",
    "text": "Bricks VS Proportional Symbol Map\n\n\nProportional Symbol map can be more difficult to distinguish than brick"
  },
  {
    "objectID": "Notes/Lesson_2.html#dot-density-map",
    "href": "Notes/Lesson_2.html#dot-density-map",
    "title": "Notes 2",
    "section": "Dot Density Map",
    "text": "Dot Density Map\n\na type of thematic map -&gt; use dot/symbols to show the values of &gt;= 1 numeric value\neach dot represent some amt of data"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "Overview\nSpatio-Temporal Point Pattern: A random collection of points representing time and location of events (eg. disease incidences, species sightings, fires, earthquakes, lightning strikes, tsunamis, volcanic eruptions.)\nImportance: Increasingly necessary due to growth in geographically and temporally indexed data across various fields.\nApplication Example:\n\nAnalysis of forest fire events in Kepulauan Bangka Belitung, Indonesia (1 Jan 2023 - 31 Dec 2023).\n\nWe want to find out\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?\n\n\n\n1.0 Setup\n\n1.1 Installing R-Packages\nsf: provides functions for importing processing and wrangling geospatial data\nraster: for handling raster data in R\nspatstat: for performing Spatial Point Patterns Analysis such as kcross, Lcross, etc.\nsparr: provides functions to estimate fixed and adaptive kernel-smoothed spatial relative risk surfaces via the density-ratio method and perform subsequent inference. Fixed-bandwidth spatiotemporal density and relative risk estimation is also supported\ntmap: provides functions to produce cartographic quality thematic maps\ntidyverser: provide functions to perform common data science tasks including and not limited to data import, data transformation, data wrangling and data visualisation\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, sparr)\n\n\n\n1.2 Data Acquisition\nWe will be using 2 sets of data:\n\nforestfires (CSV file):\n\nContains locations of forest fires from MODIS sensor data.\nDownloaded from the Fire Information for Resource Management System.\nFocus: Only forest fires in Kepulauan Bangka Belitung.\n\nKepulauan_Bangka_Belitung (ESRI shapefile):\n\nShows sub-district boundaries (kelurahan) of Kepulauan Bangka Belitung.\nDownloaded from the Indonesia Geospatial Portal.\nFocus: Only sub-districts within Kepulauan Bangka Belitung (original data covers all of Indonesia).\n\n\n\n\n1.3 Importing And Preparing Study Area/Forest Fire data\n\nStudy AreaForest Fire Data\n\n\n\nImporting study area\n\nkbb &lt;- st_read(dsn = \"data/rawdata\",        \n               layer = \"Kepulauan_Bangka_Belitung\")\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\In-class_Ex\\In-class_Ex04\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nTo dissolve\n\nkbb_sf &lt;- kbb %&gt;% \n  st_union()\n\nst_as_s2(): dropping Z and/or M coordinate\n\n\nDrop the Z value in geometry so it become polygon\n\nkbb_sf &lt;- kbb_sf %&gt;% \n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 32748)\n\n\n\n\n\nImporting Fire Data\n\nfire_sf &lt;- read_csv(\"data/rawdata/forestfires.csv\") %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n           crs = 4326) %&gt;% \n  st_transform(crs = 32748)\n\nRows: 741 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): satellite, instrument, daynight\ndbl  (11): latitude, longitude, brightness, scan, track, acq_time, confidenc...\ndate  (1): acq_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nBecause ppp object only accept numerical or character as mark, we need to convert data type of acq_date to numeric.\n\nfire_sf &lt;- fire_sf %&gt;% \n  mutate(DayOfYear = yday(acq_date)) %&gt;% \n  mutate(Month_num = month(acq_date)) %&gt;% \n  mutate(Month_fac = month(acq_date,\n                           label = TRUE,\n                           abbr = FALSE))\n\n\n\n\n\n\n\n\n2.0 Creating owin\n\nkbb_owin &lt;- as.owin(kbb_sf)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\n\nclass(kbb_owin)\n\n[1] \"owin\"\n\n\n\n\n3.0 Visualising the Fire Points\n\n3.1 Overall plot\n\ntm_shape(kbb_sf)+\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\n\n3.2 Visualizing geographic distribution of forest fires by month\n\ntm_shape(kbb_sf) +\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots(size = 0.1) +\n  tm_facets(by=\"Month_fac\",\n            free.coords = FALSE, #if change to true, the zoom lvl will be to where the data is\n            drop.units = TRUE)\n\n\n\n\n\n\n\n\n\n\n3.3 Computing STKDE by Month\nusing spattemp.density()\n\n3.3.1 Extracting forest fires by month\n* This will create a new dataset with only the month & geometry data\n\nfire_month &lt;- fire_sf %&gt;% \n  select(Month_num)\n\n\n\n3.3.2 Creating ppp\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\nsummary(fire_month_ppp)\n\nMarked planar point pattern:  741 points\nAverage intensity 2.49258e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n                    (174200 x 170600 units)\nWindow area = 29728200000 square units\n\n\n\n\nCheck for duplicated point events\n\nany(duplicated(fire_month_ppp))\n\n[1] FALSE\n\n\n\n\n3.3.3 Including Owin Object\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nsummary(fire_month_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\n\nplot(fire_month_owin)\n\n\n\n\n\n\n\n\n\n\n\n\n4.0 Computing Spatio-temporal KDE\n\nst_kde &lt;- spattemp.density(fire_month_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]\n\n\n\nPlotting the spatio-temporal KDE object\n\ntims &lt;- c(7,8,9,10,11,12)\npar(mfcol=c(2,3))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at month\",i))\n}\n\n\n\n\n\n\n\n\n\n\n\n5.0 Computing STKDE by Day of Year\n\n5.1 Creating ppp object\n\nfire_yday_ppp &lt;- fire_sf %&gt;% \n  select(DayOfYear) %&gt;%\n  as.ppp()\n\n\n\n5.2 Including Owin object\n\nfire_yday_owin &lt;- fire_yday_ppp[kbb_owin]\nsummary(fire_yday_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   10.0   213.0   258.0   245.9   287.0   352.0 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\n\n\n5.3\n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 6.3198 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [3.959516e-27, 2.751287e-12]\n\n\n\nplot(kde_yday)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "Installing R-Packages\n\npacman::p_load(tidyverse, sf, ggstatsplot, tmap, spatstat, raster)\n\n\n\nInstalling Maptools\neval: false = avoid maptools being download and install repetitively every time the Quarto document been rendered.\n\ninstall.packages(\"maptools\",\n                 repos=\"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\n\nImporting Geospatial Data\n\nmpsz_sf &lt;- st_read(dsn = \"data/MasterPlan2014SubzoneBoundaryWebSHP\",                 \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\In-class_Ex\\In-class_Ex03\\data\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;% \n  st_transform(crs=3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\In-class_Ex\\In-class_Ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\nCreating coastal outline\nst_union() to derive the coastal outline sf tibble data.frame\n\nsg_sf &lt;- mpsz_sf %&gt;% \n  st_union()\n\nplot(sg_sf)\n\n\n\n\n\n\n\n\n\n\nCreating ppp objects from sf data.frame\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\nCreating owin object from sf data.frame\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n80 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            14650  6.97996e+08      8.93e-01\npolygon 2 (hole)         3 -2.21090e+00     -2.83e-09\npolygon 3              285  1.61128e+06      2.06e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.63e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.13e-11\npolygon 6              668  5.40368e+07      6.91e-02\npolygon 7               44  2.26577e+03      2.90e-06\npolygon 8               27  1.50315e+04      1.92e-05\npolygon 9              711  1.28815e+07      1.65e-02\npolygon 10 (hole)       36 -4.01660e+04     -5.14e-05\npolygon 11 (hole)      317 -5.11280e+04     -6.54e-05\npolygon 12 (hole)        3 -3.41405e-01     -4.37e-10\npolygon 13 (hole)        3 -2.89050e-05     -3.70e-14\npolygon 14              77  3.29939e+05      4.22e-04\npolygon 15              30  2.80002e+04      3.58e-05\npolygon 16 (hole)        3 -2.83151e-01     -3.62e-10\npolygon 17              71  8.18750e+03      1.05e-05\npolygon 18 (hole)        3 -1.68316e-04     -2.15e-13\npolygon 19 (hole)       36 -7.79904e+03     -9.97e-06\npolygon 20 (hole)        4 -2.05611e-02     -2.63e-11\npolygon 21 (hole)        3 -2.18000e-06     -2.79e-15\npolygon 22 (hole)        3 -3.65501e-03     -4.67e-12\npolygon 23 (hole)        3 -4.95057e-02     -6.33e-11\npolygon 24 (hole)        3 -3.99521e-02     -5.11e-11\npolygon 25 (hole)        3 -6.62377e-01     -8.47e-10\npolygon 26 (hole)        3 -2.09065e-03     -2.67e-12\npolygon 27              91  1.49663e+04      1.91e-05\npolygon 28 (hole)       26 -1.25665e+03     -1.61e-06\npolygon 29 (hole)      349 -1.21433e+03     -1.55e-06\npolygon 30 (hole)       20 -4.39069e+00     -5.62e-09\npolygon 31 (hole)       48 -1.38338e+02     -1.77e-07\npolygon 32 (hole)       28 -1.99862e+01     -2.56e-08\npolygon 33              40  1.38607e+04      1.77e-05\npolygon 34 (hole)       40 -6.00381e+03     -7.68e-06\npolygon 35 (hole)        7 -1.40545e-01     -1.80e-10\npolygon 36 (hole)       12 -8.36709e+01     -1.07e-07\npolygon 37              45  2.51218e+03      3.21e-06\npolygon 38             142  3.22293e+03      4.12e-06\npolygon 39             148  3.10395e+03      3.97e-06\npolygon 40              75  1.73526e+04      2.22e-05\npolygon 41              83  5.28920e+03      6.76e-06\npolygon 42             211  4.70521e+05      6.02e-04\npolygon 43             106  3.04104e+03      3.89e-06\npolygon 44             266  1.50631e+06      1.93e-03\npolygon 45              71  5.63061e+03      7.20e-06\npolygon 46              10  1.99717e+02      2.55e-07\npolygon 47             478  2.06120e+06      2.64e-03\npolygon 48             155  2.67502e+05      3.42e-04\npolygon 49            1027  1.27782e+06      1.63e-03\npolygon 50 (hole)        3 -1.16959e-03     -1.50e-12\npolygon 51              65  8.42861e+04      1.08e-04\npolygon 52              47  3.82087e+04      4.89e-05\npolygon 53               6  4.50259e+02      5.76e-07\npolygon 54             132  9.53357e+04      1.22e-04\npolygon 55 (hole)        3 -3.23310e-04     -4.13e-13\npolygon 56               4  2.69313e+02      3.44e-07\npolygon 57 (hole)        3 -1.46474e-03     -1.87e-12\npolygon 58            1045  4.44510e+06      5.68e-03\npolygon 59              22  6.74651e+03      8.63e-06\npolygon 60              64  3.43149e+04      4.39e-05\npolygon 61 (hole)        3 -1.98390e-03     -2.54e-12\npolygon 62 (hole)        4 -1.13774e-02     -1.46e-11\npolygon 63              14  5.86546e+03      7.50e-06\npolygon 64              95  5.96187e+04      7.62e-05\npolygon 65 (hole)        4 -1.86410e-02     -2.38e-11\npolygon 66 (hole)        3 -5.12482e-03     -6.55e-12\npolygon 67 (hole)        3 -1.96410e-03     -2.51e-12\npolygon 68 (hole)        3 -5.55856e-03     -7.11e-12\npolygon 69             234  2.08755e+06      2.67e-03\npolygon 70              10  4.90942e+02      6.28e-07\npolygon 71             234  4.72886e+05      6.05e-04\npolygon 72 (hole)       13 -3.91907e+02     -5.01e-07\npolygon 73              15  4.03300e+04      5.16e-05\npolygon 74             227  1.10308e+06      1.41e-03\npolygon 75              10  6.60195e+03      8.44e-06\npolygon 76              19  3.09221e+04      3.95e-05\npolygon 77             145  9.61782e+05      1.23e-03\npolygon 78              30  4.28933e+03      5.49e-06\npolygon 79              37  1.29481e+04      1.66e-05\npolygon 80               4  9.47108e+01      1.21e-07\nenclosing rectangle: [2667.54, 56396.44] x [15748.72, 50256.33] units\n                     (53730 x 34510 units)\nWindow area = 781945000 square units\nFraction of frame area: 0.422\n\n\n\n\nCombining point events object and owin object\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\nKernel Density Estimation of Spatial Point Event\nre-scale the unit of measurement to km before performing KDE\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, \n                                  1000, \n                                  \"km\")\n\nkde_childcareSG_adaptive &lt;- adaptive.density(\n  childcareSG_ppp.km, \n  method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\n\nconvert KDE output into grid object\nmaptools method\n\npar(bg = '#E4D5C9')\n\ngridded_kde_childcareSG_ad &lt;- maptools::as.SpatialGridDataFrame.im(\n  kde_childcareSG_adaptive)\n\nPlease note that 'maptools' will be retired during October 2023,\nplan transition at your earliest convenience (see\nhttps://r-spatial.org/r/2023/05/15/evolution4.html and earlier blogs\nfor guidance);some functionality will be moved to 'sp'.\n Checking rgeos availability: FALSE\n\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\nspatstat.geom method\n\ngridded_kde_childcareSG_ad &lt;- as(\n  kde_childcareSG_adaptive,\n  \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\n\n\n\nExtracting study area using sf objects\n\npg_owin &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\") %&gt;%\n  as.owin()\n\nchildcare_pg = childcare_ppp[pg_owin]\n\nplot(childcare_pg)  \n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, ggstatsplot, tmap)\n\n\nmpsz2014_shp = st_read(dsn = \"data/MasterPlan2014SubzoneBoundaryWebSHP\",                 \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\In-class_Ex\\In-class_Ex02\\data\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nTo know the data type:\n\nclass(mpsz2014_shp)\n\n[1] \"sf\"         \"data.frame\"\n\n\n\nmpsz2014_kml = st_read(\"data/MasterPlan2014SubzoneBoundaryWebKML.kml\")\n\n\nst_write(mpsz2014_shp,\n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n         delete_dsn = TRUE)\n\n\nmpsz2014_kml = st_read(\"data/MP14_SUBZONE_WEB_PL.kml\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\In-class_Ex\\In-class_Ex02\\data\\MP14_SUBZONE_WEB_PL.kml' \n  using driver `KML'\nSimple feature collection with 323 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz2019_shp = st_read(dsn = \"data/MPSZ-2019\",                 \n               layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\In-class_Ex\\In-class_Ex02\\data\\MPSZ-2019' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz2019_kml = st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\In-class_Ex\\In-class_Ex02\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\npopdata &lt;- read.csv(\"data/respopagesextod2023/respopagesextod2023.csv\")\n\n\npopdata2023 &lt;- popdata %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP`=sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG,\n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\n\npopdata2023 &lt;- popdata %&gt;%\n  filter(Time == 2023) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nTo standardize data of mpsz2019_shp and popdata2023, is case sensitive:\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\nmpsz_pop2023 &lt;- left_join(mpsz2019_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "NetSPAA is used to analyze events that happen along networks, like roads or rivers.\neg.study where traffic accidents mostly happen on a road, or where childcare centers are located along streets\nIn this exercise, we’ll use a tool called spNetwork:\n\nNetwork Kernel Density Estimation (NKDE): This helps you see where events (like accidents) are happening the most along a network (like a road), showing areas where events are more common.\nNetwork G-function and K-function: These are methods to check if events are clustering together (happening close to each other) or if they’re spread out along the network."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "NetSPAA is used to analyze events that happen along networks, like roads or rivers.\neg.study where traffic accidents mostly happen on a road, or where childcare centers are located along streets\nIn this exercise, we’ll use a tool called spNetwork:\n\nNetwork Kernel Density Estimation (NKDE): This helps you see where events (like accidents) are happening the most along a network (like a road), showing areas where events are more common.\nNetwork G-function and K-function: These are methods to check if events are clustering together (happening close to each other) or if they’re spread out along the network."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#setup",
    "title": "Hands-on Exercise 4",
    "section": "2.0 Setup",
    "text": "2.0 Setup\n\n2.1 Installing R-Packages\n\nsf for handling geospatial data. It can manage, process, and manipulate Simple Features, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons.\nspNetwork, can perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\ntmap to plot cartographic quality static point patterns maps or interactive maps\n\n\npacman::p_load(sf, spNetwork, tmap, tidyverse)\n\n\n\n2.2 Data Acquisition\n2 datasets will be used to analyse the spatial distribution of childcare centre in Punggol planning area (Both data sets are in ESRI shapefile format):\n\nPunggol_St, a line features geospatial data which store the road network within Punggol Planning Area.\nPunggol_CC, a point feature geospatial data which store the location of childcare centres within Punggol Planning Area.\n\n\n\n2.3 Importing Geospatial Data into R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Spatial Point Pattern Analysis is a method used to study how points are spread out over an area. These points can represent:\n\nEvents like crimes, traffic accidents, or disease outbreaks.\nLocations of businesses such as coffee shops, fast food places, or facilities like childcare centers and eldercare services.\n\nIn this exercise, we’ll use a tool called spatstat to analyze the distribution of childcare centers in Singapore.\nQuestions we want to answer are:\n\nAre childcare centers in Singapore spread out randomly, or is there a pattern?\nIf they’re not randomly distributed, where are the areas with the highest concentration of childcare centers?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#st-order-spatial-point-patterns-analysis-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#st-order-spatial-point-patterns-analysis-methods",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Spatial Point Pattern Analysis is a method used to study how points are spread out over an area. These points can represent:\n\nEvents like crimes, traffic accidents, or disease outbreaks.\nLocations of businesses such as coffee shops, fast food places, or facilities like childcare centers and eldercare services.\n\nIn this exercise, we’ll use a tool called spatstat to analyze the distribution of childcare centers in Singapore.\nQuestions we want to answer are:\n\nAre childcare centers in Singapore spread out randomly, or is there a pattern?\nIf they’re not randomly distributed, where are the areas with the highest concentration of childcare centers?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#setup",
    "title": "Hands-on Exercise 3",
    "section": "2.0 Setup",
    "text": "2.0 Setup\n\n2.1 Installing R-Packages\n\nsf for handling geospatial data\nspatstat for point pattern analysis. In this exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer. To study how points are distributed & to create a density map showing where points are concentrated\nraster deals with grid-based spatial data, like satellite img. In this exercise, we’ll use it to convert images created by spatstat into a format that raster can work with.\nmaptools for manupulating geographic data. In this exercise, we mainly use it to convert Spatial objects -&gt; ppp format of spatstat.\ntmap package\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, devtools,sp)\n\n\n\n2.2 Data Acquisition\n3 datasets will be used:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\n\n\n2.3 Importing Geospatial Data into R\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;% \n  st_transform(crs=3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn=\"data\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n2.4 Assigning Standard Coordinate Systems\n\nsg_sf &lt;- st_transform(sg_sf, crs=3414)\nmpsz_sf &lt;- st_transform(mpsz_sf, crs=3414)\n\n\n\n2.5 Data Preparation and Wrangling\n\n2.5.1 Convert simple feature data frame to sp’s Spatial* class\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\n2.5.2 Convert Spatial* class into generic sp format\n* spatstat requires the analytical data in ppp object form. (Need convert to Spatial Object first -&gt; ppp object)\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n* Diff between Spatial* classes & generic sp object:\nSpatial* classes are specialized versions of spatial objects tailored for different types of spatial data, while the generic sp object provides a base class with fundamental spatial features that can be extended by the more specific Spatial* classes.\n\n\n2.5.3 Convert generic sp format into spatstat’s ppp format\n\nchildcare_ppp &lt;- as.ppp(st_coordinates(childcare_sf), st_bbox(childcare_sf))\n\nWarning: data contain duplicated points\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nView Summary Statistics:\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n* There is warning about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#handling-duplicated-points",
    "title": "Hands-on Exercise 3",
    "section": "3.0 Handling duplicated points",
    "text": "3.0 Handling duplicated points\n\n3.1 Check duplication in a ppp object\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\n\n\n3.2 Count no. of co-indicence point\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\n\n\n3.3 Check how many locations &gt;= 1 point event\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\n\n\nView locations of these duplicated point events:\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\n\n3.3 3 ways to overcome duplicate points\n\nDelete the duplicate -&gt; but, this will result in some useful point events be lost\njittering -&gt; this will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nmake each point ‘unique’ + attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\n\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "title": "Hands-on Exercise 3",
    "section": "4.0 Creating owin object",
    "text": "4.0 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nConvert sg SpatialPolygon object -&gt; owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nDisplay:\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n4.1 Combining point events object + owin object\nExtract childcare events that are located within Singapore\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nchildcareSG_ppp &lt;- as.ppp(childcareSG_ppp)\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "title": "Hands-on Exercise 3",
    "section": "5.0 First-order Spatial Point Patterns Analysis",
    "text": "5.0 First-order Spatial Point Patterns Analysis\n\n5.1 Kernel Density Estimation (KDE)\n\n5.1.1 Computing kernel density estimation using automatic bandwidth selection method\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n* Density values is 0 to 0.000035 (too small to understand) -&gt; because default unit of measurement of svy21 is in meter [so it is computed in no. of points/sq meter]\nTo retrieve bandwidth used to compute the kde layer:\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n5.1.2 Convert unit of measurement from meter -&gt; km\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\n\n\n5.1.3 Different automatic badwidth methods\n\nbw.CvL()\nbw.scott()\nbw.ppl()\n\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\n bw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\n bw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\n bw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in ther experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n5.1.4 Different kernel methods\nDefault in density.ppp() is gaussian. [Choose from Epanechnikov, Quartic and Dics]\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\n\n\n\n\n\n\n\n\n\n\n5.1.4 Fixed and Adaptive KDE\n\n5.1.4.1 Computing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\n5.1.4.2 Computing KDE by using adaptive bandwidth\nvery sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nFixed VS Adaptive Kernel density estimation:\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n5.1.4.3 Converting KDE output into grid object\nThe result is the same, we just convert it so that it is suitable for mapping purposes\n\ngridded_kde_childcareSG_bw &lt;- as(kde_childcareSG.bw, \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\n\n5.1.4.4 Converting gridded density objects into raster\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n* crs is NA\n\n\n5.1.4.5 Assigning projection systems\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\n5.1.4.6 Visualising the output in tmap\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\n* Notice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field.\n\n\n5.1.4.7 Comparing Spatial Point Patterns using KDE\ncompare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas.\nExtract target planning areas:\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlot:\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n5.1.4.8 Creating owin object\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nCombining childcare points and the study area\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\nComputing KDE\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\n\n\n\n\nComputing fixed bandwidth KDE\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\n\n\n\n\n\n\n\n\n\n\n\n5.2 Performing Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\n5.2.1 Testing spatial point patterns using Clark and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n5.2.2 Clark and Evans Test: Choa Chu Kang planning area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.94529, p-value = 0.4136\nalternative hypothesis: two-sided\n\n\n\n\n5.2.3 Clark and Evans Test: Tampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.76587, p-value = 2.383e-05\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#drawing-a-spatial-point-map",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#drawing-a-spatial-point-map",
    "title": "Hands-on Exercise 3",
    "section": "6.0 Drawing a Spatial Point Map",
    "text": "6.0 Drawing a Spatial Point Map\n\ntm_shape(mpsz_sf) +\n  tm_polygons() +\n  tm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\n* All the layers on the map fit together properly because they use the same coordinate system. This means they all refer to the same geographical area, which is crucial for accurate mapping and analysis.\n\nOR -&gt; Pin Map\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n* Using interactive mode in tmap -&gt; can zoom in & out. Click on points to see more info\n* Can choose from different background map styles. Default = ESRI.WorldGrayCanvas. (Choose from ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap)\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n* Switch back to “plot”. Because each interactive mode consume a connection. Avoid &gt;10 in 1 RMarkdown doc when publish on Netlify"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#second-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#second-order-spatial-point-patterns-analysis",
    "title": "Hands-on Exercise 3",
    "section": "7.0 Second-order Spatial Point Patterns Analysis",
    "text": "7.0 Second-order Spatial Point Patterns Analysis\n\n7.1 Analysing Spatial Point Process Using G-Function\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event.\nCompute G-function estimation by using Gest() of spatstat package.\nPerform monta carlo simulation test using envelope() of spatstat package.\n\n\n7.1.1 Choa Chu Kang planning area\n\n\nComputing G-function estimation\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n7.1.2 Tampiness planning area\n\n\nComputing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-fucntion\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_tm.csr)\n\n\n\n\n\n\n\n\n\n\n7.2 Analysing Spatial Point Process Using F-Function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape.\nCompute F-function estimation by using Fest() of spatstat package.\nPerform monta carlo simulation test using envelope() of spatstat package.\n\n\n7.2.1 Choa Chu Kang planning area\n\n\nComputing F-function estimation\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-fucntion\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n7.2.2 Tampines planning area\n\n\nComputing F-function estimation\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)\n\n\n\n\n\n\n\n\n\n\n7.3 Analysing Spatial Point Process Using K-Function\nK-function measures the number of events found up to a given distance of any particular event.\nCompute K-function estimates by using Kest() of spatstat package.\nPerform monta carlo simulation test using envelope() of spatstat package.\n\n\n7.3.1 Choa Chu Kang planning area\n\n\nComputing K-function estimation\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n7.3.2 Tampines planning area\n\n\nComputing K-function estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n7.4 Analysing Spatial Point Process Using L-Function\nCompute L-function estimation by using Lest() of spatstat package.\nPerform monta carlo simulation test using envelope() of spatstat package.\n\n\n7.4.1 Choa Chu Kang planning area\n\n\nComputing L-function estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n7.4.2 Tampines planning area\n\n\nComputing L-function estimation\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/data/MPSZ-2019/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex01/data/MPSZ-2019/MPSZ-2019.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/data/MPSZ-2019/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex02/data/MPSZ-2019/MPSZ-2019.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/data/MPSZ-2019/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex03/data/MPSZ-2019/MPSZ-2019.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "href": "In-class_Ex/In-class_Ex04/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Notes/Lesson_1.html",
    "href": "Notes/Lesson_1.html",
    "title": "2 Types of Data Models",
    "section": "",
    "text": "2 Types of Data Models\n\n1. Vector\n\nused for mapping boundaries, networks, and precise locations\nPoints: Discrete location (a city, tree etc)\n\n1 coordinate\n\nLines: Linear features (roads, rivers etc)\n\n&gt;= 2 coordinate pairs\nknow length\n\nPolygons: Area features (lakes, land parcels etc)\n\n&gt;=3 line segment\nknow location, length, and area\n\n\n\n\n2. Raster\n\nused for continuous data (eg. elevation, temperature, satellite, imagery, land cover)\nRepresents geographic features as a grid of cells or pixels.\nEach cell has a value representing information such as color, elevation, or land cover type.\n\n\n\n\n\n\n\n\n\n\n\nVector\nRaster\n\n\n\n\nData Representation\nPoints, lines, and polygons representing discrete features.\nGrid of cells or pixels representing continuous data.\n\n\nData Storage\nStores data as coordinates with associated attributes.\nStores data in a grid format, each cell holding a value.\n\n\nPrecision and Detail\nHighly precise, ideal for exact measurements and boundaries.\nResolution-dependent, better for continuous data representation.\n\n\nData Processing\nSuited for network analysis and topology-based operations.\nEfficient for spatial analysis involving overlays and map algebra.\n\n\nApplications\nUsed in mapping boundaries, networks, and urban planning.\nUsed in remote sensing, environmental modeling, and continuous surface analysis.\n\n\nVisualization\nSharp visuals, clear boundaries, smooth scaling.\nCan become pixelated when zoomed in; best for surface data like satellite imagery.\n\n\n\n\n\n\nCoordinate System\n\n\nProvides a location reference to the geospatial data\nTypes\n\nGCS -Geographic Coordinate System\nPCS -Projected Coordinate System\n\n\n\n\n\n\n\n\n\nGeographic Coordinate System (GCS)\nProjected Coordinate System (PCS)\n\n\n\n\n\n\n\n\nuse a 3D surface (eg. WGS84)\n\n\n\nprovides accurate position info\n\n\n\nnot appropriate for distance & area measurements\nprovides consistent length & area measurement across space\n\n\n\nNeed to transform GCS -&gt; PCS before performing geospatial analysis\n\n\nSimple Features\n\n\n\n\nShapefile\n\n\n\n\n\n\n\n\nif read, no need specify extension\n\n\n\n\n\nFor other vector format, read need to specify extension\n\nconsist of a few files\na simple, non-topological format for storing geometric location & attribute info of geographic features\nGeographic features in a shapefile can be represented by Points, Lines, Polygons(areas)\n\n\n\nSF functions\n\nGeospatial data handling\nst_read & read_sf\n\n\n\n\n\n\n\nShapefile format\nOther format\n\n\n\n\n\n\n\n\n\nread_csv\n\nglimpse -&gt; similar to print()\n\nst_write & write_sf\nst_as_sf -&gt; convert data frames/spatial objects into \"sf\" simple features, allowing for spatial data manipulation & analysis\nst_as_text -&gt; convert to Well Known Text\nst_as_binary\nst_as_sfc -&gt; convert coordinate data into \"sfc\" simple feature collections objects\nst_transform -&gt; convert coordinates to a different coordinate reference system\n\n\nGeospatial confirmation\nst_intersects\n\n\n\n\nst_disjoint -&gt; !intersect\nst_equals\nst_equal_exacts\n\n\nst_crosses -&gt; cross (don’t touch)\nst_touches\nst_within\n\n\nst_contains\nst_covers\nst_covered_by\n\n\nst_overlaps\n\n\n\n\n\n\n\nGeospatial operations\n\n\n\nst_union\nst_intersection\n\n\nst_difference\nst_sym_difference\n\n\n\n\n\n\n\n\n\n\nGeospatial creation\n\n\n\n\n\n\n\nst_interpolate_aw -&gt;\n\narea-weighted interpolation\nuses st_intersection to interpolate/redistribute attribute values, based on area of overlap\n\nst_join\neg. join a point data and polygon data together\n\n\n\n\n\n\nGeospatial operations\n\n\n\n\n\n\n\n\nst_line_merge -&gt; merge lines\nst_segmentize -&gt;\nadds points to straight lines\nst_centroid(poly)\n\n\n\nst_voronoi\nst_convex_hull\nst_triangulate\n\n\nst_polygonize\nst_simplify -&gt;\nsimplify lines by removing articles\nst_buffer(poly, 5)\n\n\n\nst_split -&gt;\nsplit a ploygon given line geometry\nst_make_valid -&gt;\nmake an invalid geometry valid\nis_boundary -&gt;\nreturn the boundary of a geometry\n\n\n\n\n\nGeospatial measurement\n\n\n\n\n\n\n\nst_zm -&gt;\nset/remove z and/or m geometry\nst_coordinates -&gt;\nreturns coordinates in a matrix/data.frame\n\n\nst_geometry\n\nst_is -&gt;\ncheck if geometry is of a particular type\n\n\n\nhead -&gt; reveal complete info of a feature object, can select the number of records to display\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo Check coordinate system of mpsz\n\n\n\nAssign EPSG code to mpsz\n\n\n\nSummary\n\n\n\nTop n\n\n\n\nSum\n\n\n\nCompute density\n\n\n\nHistogram"
  },
  {
    "objectID": "Notes/Lesson_3.html",
    "href": "Notes/Lesson_3.html",
    "title": "Notes 3",
    "section": "",
    "text": "Purpose of Geospatial Analytics\n\nSo that we can quantitatively derive it (eg. using KDE).\nUses data related to locations to find patterns & trends\n\n\n\nSpatial Point Patterns\n\nTo study how points (Event) are spread out over an area\nOnly map Events, no ‘Non-Event’\nThe mapped pattern should not be:\n\nselection bias\nNot a sample (eg. It is ok to take aged 70-80 from the population. But do not do random sampling out of this group)\n\n\nExample:\n\n\n\n\nReal-world spatial point patterns -Random OR Patterned?\n\nhard to have random distribution\n\neg. Some areas like the airport will never have childcare\nWe can use 2nd Order Spatial Point Pattern Analysis to prove\n\nhard to find something uniform in real world\n\neg. For instance a desert, if you zoom out a bit, there could be small hills, different land. It would not be the same across such as flat land\n\nBefore performing any spatial analysis, exclude areas that is definitely dont have the occurence. [Else, when generate the spatial random data, you might have childcare center there]\n\n\n\n\nSpatial Point Patterns Analysis\n\nusually in 2D space\nset X = {x ∈ D}, D = study region, subset of Rn, a n-dimensional Euclidean space\nIssue: We need infer if the given is merely random or result of some process:\n\n\n\n\n\n1st-order VS 2nd-order Analysis\n\n\n\n\n\n\n\n\n\n1st Order\n2nd Order\n\n\n\n\n\n\nfocuses on the overall intensity or density of events across a study area.\n\nexamines how the number of points (events) changes over space, often influenced by external factors such as environmental conditions, socioeconomic factors, or other large-scale trends.\nExample:\n“Where are the points more or less dense?”\n“How does the density of events vary across the study area?\n\nexamines the interaction or relationships between points within a study area.\nhelp to identify whether points tend to cluster, repel, or distribute randomly relative to each other.\n\nExample:\n“Are the points clustered, dispersed, or randomly distributed in relation to each other?”\n“How does the pattern change with distance?”\n\n\nTechnique\nDensity-based:\n\nKDE (Kernel density estimation)\nQuadrat analysis\n\nDistance-based:\n\nNearest Neighbour Index\n\n\nG function\nF function\nK function\nL function\n\n\n\n\n\n\n\n1st-order[Kernel Density Estimation (KDE)]\n\nused to estimate the probability density function of a random variable.\n\n\n\n\nSteps in KDE\n\nPlace a Kernel on Each Point (event location)\n\nThe height and shape of this bump depend on the chosen kernel function and the bandwidth.\n\nSum the Kernels\n\nFor each point in the study area, the contribution of all surrounding kernels is summed to calculate the density value at that point.\n\nCreate a Continuous Surface\n\nThe result is a smooth surface where higher values indicate areas with higher event densities, and lower values indicate areas with fewer events.\n\n\n\n\nKDE Methods\n\n\nUniform -&gt; intensity will not change during this period, immediately after, it will be 0\nTriangular -&gt; move away from center point, it will decrease very fast from the center point\nQuartic & Gaussian -&gt;\n\nnot identical, but similar. If get negative value from Gaussian, can switch to Quartic.\nGaussian is very common (Gives more weight to points closer to the event & less weight to points farther away)\nTry different option, select the appropriate one & explain why\n\n\n\n\nKDE Bandwidth\n\n\n\n\n\n\n\nFixed Bandwidth -determine distance for you\n\nDefine a fixed distance -&gt; use this distance throughout the study\nIn extreme case, might not able to calibrate in local areas where data are too sparse to satisfy the calibration requirements\n\n\n\n\n\nAdaptive Bandwidth -determine the k for you\n\nFixed the no. of spatial points\neg. I will search for 8 childcare center no matter the length\n\n\n\n\n\n\n* Small bandwidth = highly localized estimate, showing fine details (but could miss broader patterns)\n* Large bandwidth = smooth out the estimart (possibly oversimplifying the data)\n* Automatic bandwidth -&gt; bw.diggle()\n\n\n\n\n1st-order [Quadrat Analysis]\n\nSteps\n\n\n\n\n\n\n\n\nDivide the study area into subregion of equal size,\n\noften squares, but don’t have to be.\n\n\n\n\n\n\nCount the frequency of events in each region.\n\n\n\n\n\nCalculate the intensity of events in each region.\n\n\n\n\n\nCalculate the quadrat statistics and perform CSR test.\n\n\n\n\n\nUniform distribution -&gt; variance-mean ratio = 0\nRandom distribution -&gt; variance-mean ratio close to 1\nCluster distribution -&gt; variance-mean ratio greater than 1\n\n\nInterpretation\n\n\n\nWeaknesses\n\nsensitive to the quadrat size\n\nIf too small, they may contain only a couple of points, and\nIf too large, they may contain too many points.\n\nIt is a measure of dispersion rather than a measure of pattern.\n\n\n\nIt results in a single measure for the entire distribution, so variation within the region are not recognised.\n\n\n\n\nComplete Spatial Randomness CSR\n\nsatisfy 2 conditions\n\nany event has equal probability of being in any location, a 1st order effect\nThe location of one event is independent of the location of another event, a 2nd order effect.\n\n\n\n\n1st-order [Distance-based: Nearest Neighbour Index]\n\nDirect distance from a point to its nearest neighbour\nIndex &lt; 1: clustering\nIndex = 1: random\nIndex &gt; 1: dispersion\n\n\nExample:\n\n\np-value is &lt; 0.05, so reject null hypo that the point patterns are randomly distributed\n\n\n2nd-order [G function]\n\n\nwithin this radius, how many childcare i found\nWithin 0-9, what is the intensity\nClustered: If G increases rapidly at short distance\nEvenness: If G increases slowly up to distance where most events spaced, then increases rapidly\n\n\nMonte Carlo simulation test of CSR\n\n\nnsim = 999 &lt;- Performed 999 simulations [Cannot do 1 only, the more = more stable, result will converge]\nfor each simulated point pattern, estimate G(r) & use the max 95th and min 5th of these functions for the simulated patterns to define an upper and lower simulation envelope.\nEstimate G(r) is statistically significant if estimated G(r) lies above the upper envelope or below the lower envelope\n\n\n\n\n\n2nd-order [F function]\n\nSelect a sample of point locations anywhere in the study region at random\n\nDetermine min distance from each point to any event in the study area.\n\n\nClustered = F(r) rises slowly at first, but more rapidly at longer distances.\n\n\n\nEvenness = F(r) rises rapidly at first, then slowly at longer distances.\n\n\n\n\nComparison between F and G function\n\n\n\n2nd-order [K function]\n\nLimitation of nearest neighbor distance method is that it uses only nearest distance\nConsiders only the shortest scales of variation.\nK function uses more points.\n\nProvides an estimate of spatial dependence over a wider range of scales.\nBased on all the distances between events in the study area.\nAssumes isotropy over the region.\n\n\n\n\nCalculating K function\n\nConstruct a circle of radius h around each point event(i).\nCount the number of other events (j) that fall inside this circle.\nRepeat these two steps for all points (i) and sum results.\nIncrement h by a small amount and repeat the calculation.\n\n\nSignificant cluster pattern -&gt; above envelop\nSignificant regular pattern -&gt; below envelop\nCSR -&gt; inside envelop\n\n\n\n2nd-order [L function]\n\nK function will be normalised to obtained a benchmark of zero.\n\n\n\nWhen an observed L value is greater than its corresponding L(theo)(i.e. red break line) value for a particular distance and above the upper confidence envelop, spatial clustering for that distance is statistically significant (e.g. distance beyond C).\nWhen an observed L value is greater than its corresponding L(theo) value for a particular distance and lower than the upper confidence envelop, spatial clustering for that distance is statistically NOT significant (e.g. distance between B and C).\nWhen an observed L value is smaller than its corresponding L(theo) value for a particular distance and beyond the lower confidence envelop, spatial dispersion for that distance is statistically significant. - When an observed L value is smaller than its corresponding L(theo) value for a particular distance and within the lower confidence envelop, spatial dispersion for that distance is statistically NOT significant (e.g. distance between A and B).\n\n\n\nL(r)&gt;0 indicates that the observed distribution is geographically concentrated.\nL(r)&lt;0 implies dispersion.\nL(r)=0 indicates complete spatial randomness (CRS).\n\n* Anything outside of envelop, you will have enough statistical evidence, if inside means you still fall into the confidence lvl (cannot reject null, cause not enough evidence to infer)\n\n\nset.seed()\n\nto produce reproducible result\nresult from algo might change every run, use this to fix it"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5 -",
    "section": "",
    "text": "Overview\nxxx\n\n\n1.0 Setup\n\n1.1 Installing R-Packages\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)\n\nInstalling package into 'C:/Users/ngkng/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\n\n\nalso installing the dependencies 'TH.data', 'sandwich', 'DEoptimR', 'zoo', 'xts', 'intervals', 'LearnBayes', 'multcomp', 'robustbase', 'spacetime', 'spatialreg', 'FNN'\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4:\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4/PACKAGES'\n\n\n\n  There is a binary version available but the source version is later:\n         binary source needs_compilation\nsandwich  3.1-0  3.1-1             FALSE\n\npackage 'TH.data' successfully unpacked and MD5 sums checked\npackage 'DEoptimR' successfully unpacked and MD5 sums checked\npackage 'zoo' successfully unpacked and MD5 sums checked\npackage 'xts' successfully unpacked and MD5 sums checked\npackage 'intervals' successfully unpacked and MD5 sums checked\npackage 'LearnBayes' successfully unpacked and MD5 sums checked\npackage 'multcomp' successfully unpacked and MD5 sums checked\npackage 'robustbase' successfully unpacked and MD5 sums checked\npackage 'spacetime' successfully unpacked and MD5 sums checked\npackage 'spatialreg' successfully unpacked and MD5 sums checked\npackage 'FNN' successfully unpacked and MD5 sums checked\npackage 'GWmodel' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\ngkng\\AppData\\Local\\Temp\\Rtmpi8KwfL\\downloaded_packages\n\n\ninstalling the source package 'sandwich'\n\n\n\nGWmodel installed\n\n\n\n\n1.2 Data Acquisition\nWe will be using 2 sets of data:\n\n\n1.3 Importing Hunan data\n\nHunan shapefileHunan_2012 table\n\n\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\") \n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\nhunan2012\n\n\n\n\n\n\n\nTo save derived data:\n\nwrite_rds(hunan_sf, \"data/rds/hunan_sf.rds\")\nwrite_rds(hunan2012, \"data/rds/hunan2012.rds\")\n\n\n\nTo read stored derived data:\n\n\n\n\n\n\nNote\n\n\n\necho: false, will not print out\n\n\n\n1.4 Data Preparation and Wrangling\n\nJoining Hunan and Hunan_2012\n\nhunan_GDPPC &lt;- left_join(hunan_sf,hunan2012, join_by(County))%&gt;%\n  select(1:4, 7, 15)\n\nhunan_GDPPC\n\nSimple feature collection with 88 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\nConverting to SpatialPolygonDataFrame\n\nhunan_sp &lt;- hunan_GDPPC %&gt;% \n  as_Spatial()\n\n\n\n\n\n\n\nNote\n\n\n\nLook at the difference between the data structure of sp and sf\n\n\n\n\n\n\n\n2.0 Determine fixed bandwidth\n\nCross-alidationAIC\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"CV\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\nbw_CV\n\n[1] 76.29126\n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"AIC\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\nbw_AIC\n\n[1] 160.5517\n\n\n\n\n\n\n\n3.0 Determine adaptive bandwidth\n\nCross-ValidationAIC\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"CV\",\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\nbw_CV\n\n[1] 22\n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"AIC\",\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\nbw_AIC\n\n[1] 22\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFixed distance = will be in km,\nthe neighbors are the same for CV and AIC\n\n\n\n\n\n\n\n\nNote\n\n\n\nFixed bandwidth: adaptive = False\nAdaptive bandwidth: adaptive = True\n\n\n\n\n\n4.0 Geographically Weighted Summary Statistics with Adaptive bandwidth\n\ngwstat &lt;- gwss(data=hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\n\n\n5.0 Extract the data from gwstat\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)\n\n\n\n\n\n\n\nNote\n\n\n\ncbind() to append the newly derived data.frame onto hunan_sf sf data.frame\n\n\n\n\n6.0 Visualising geographically weighted summary statistics\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geographically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 1.0,\n            legend.text.size = 0.5,\n            legend.height = 1.50,\n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "Notes/Lesson_5.html",
    "href": "Notes/Lesson_5.html",
    "title": "Notes 5",
    "section": "",
    "text": "A way to define spatial neighbourhood\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt measure from centroid!\nNeed to clean data properly. EG. If we only need to find the childcare in SG, we should remove the outer island, else u might see centroid being not in the center of where you expect it"
  },
  {
    "objectID": "Notes/Lesson_5.html#spatial-weights-wij",
    "href": "Notes/Lesson_5.html#spatial-weights-wij",
    "title": "Notes 5",
    "section": "",
    "text": "A way to define spatial neighbourhood\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt measure from centroid!\nNeed to clean data properly. EG. If we only need to find the childcare in SG, we should remove the outer island, else u might see centroid being not in the center of where you expect it"
  }
]