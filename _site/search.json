[
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "Introduction\nThe Rise of Armed Conflict and the Potential of Geospatial Analytics\n\nImpact: Millions of lives are shattered by armed conflict each year.\nTrend: Armed conflict has been on the rise since around 2012, reversing the decline from the 1990s and early 2000s.\n\nRecent Major Conflicts:\n\nLibya, Syria, and Yemen (post-2011): Instabilities following the Arab uprisings.\nSahel Region: Crisis exacerbated by Libya’s instability.\nAzerbaijan-Armenian War (2020): Conflict over the Nagorno-Karabakh enclave.\nEthiopia’s Tigray Conflict (2020): Severe fighting in the northern region.\nMyanmar (2021): Conflict following the military’s power grab.\nRussia-Ukraine War (2022): Major assault by Russia on Ukraine.\nSudan and Gaza (2023): New devastating conflicts.\n\n\nCurrent Situation: The number of people affected—through death, displacement, or need for humanitarian aid—is higher than in decades.\n\nThis Geospatial Analytics will Focus on:\n\nObjective: This study will use spatial point patterns analysis to explore the spatial and spatio-temporal distribution of armed conflict in Myanmar.\nPotential: Geospatial analytics offer tremendous potential to address complex societal problems, providing insights into the patterns and dynamics of conflict.\n\nSource: 10 Conflicts to Watch in 2024\n\n\n\n1.0 Setup\n\n1.1 Installing R-Packages\n\nImporting and Transforming DataMapping displayDeriving Quarterly KDE LayersPerforming 2nd-Order Spatial Point Patterns AnalysisDeriving Quarterly Spatio-Temporal KDE LayersPerforming 2nd-Order Spatio-Temporal Point Patterns Analysis\n\n\n\nsf:\n\nFor handling spatial vector data and transforming it into simple features (sf) objects.\nFunctions like st_read() for importing spatial data and st_transform() for coordinate reference system transformations.\n\ntidyverse: For data manipulation and transformation, including functions for working with tibble data frames.\nreadr: For reading in CSV or other text-based data files if needed.\ndplyr: provide data manipulation capabilities (eg. to group and summarize the relationships between these columns)\n\n\n\n\npatchwork: To arrange map layout\n\n\n\n\nspatstat: For kernel density estimation (KDE) and spatial point pattern analysis.\nstars: For working with raster data and creating raster-based KDE layers.\nraster: Additional functions for raster operations, if necessary.\n\n\n\n\nspatstat: For analyzing second-order spatial point patterns, such as pair correlation functions.\nggplot2: For visualizing the results of spatial analysis.\nanimation, png, magick: For animation work\n\n\n\n\nspatstat: For spatio-temporal point pattern analysis and creating spatio-temporal KDE layers.\nstars: For handling spatio-temporal raster data.\n\n\n\n\nspatstat: For advanced spatio-temporal analysis, including the study of second-order effects over time.\n\n\n\n\n\npacman::p_load(tidyverse, sf, readr, spatstat, raster, ggstatsplot, ggplot2, tmap, dplyr, patchwork, animation, png, magick, osmdata, osrm, scales, MASS)\n\n\n\n\n1.2 Data Acquisition\nWe will be using 2 sets of data:\n\nArmed Conflict DataAdministrative Boundary Data\n\n\n\nSource: Armed Conflict Location & Event Data (ACLED). ACLED is an independent, impartial international non-profit organization that collects data on violent conflict and protests worldwide.\nCoverage: Myanmar, from January 2021 to June 2024.\nEvent Types: Focus on at least four main event types:\n\nBattles\nExplosion/Remote Violence\nStrategic Developments\nViolence Against Civilians\n\nStudy Period: Quarterly armed conflict events from January 2021 to June 2024.\n\n\n\n\nSource: Myanmar Information Management Unit (MIMU).\nNational Boundaries: To get an overview of conflict patterns across the entire country.\nState and Region with Sub-region Boundaries: For understanding conflict distribution across larger administrative divisions.\n\n\n\n\n\n\n\n1.3 Importing Geospatial Data into R\n\nArmed Conflict DataAdministrative Boundaries\n\n\n\nacled_sf &lt;- read_csv(\"data/ACLED_Myanmar.csv\")\n\nRows: 51553 Columns: 31\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): event_id_cnty, event_date, disorder_type, event_type, sub_event_ty...\ndbl (11): year, time_precision, inter1, inter2, interaction, iso, latitude, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nnational_boundaries &lt;- st_read(dsn = \"data/National_Boundaries\", layer=\"mmr_polbnda_adm0_250k_mimu_1\")\n\nReading layer `mmr_polbnda_adm0_250k_mimu_1' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex01\\data\\National_Boundaries' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nstate_region_subregion_boundaries &lt;- st_read(dsn = \"data/State_And_Region_With_Sub-regions_Boundaries\", layer=\"mmr_polbnda2_adm1_250k_mimu_1\")\n\nReading layer `mmr_polbnda2_adm1_250k_mimu_1' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex01\\data\\State_And_Region_With_Sub-regions_Boundaries' \n  using driver `ESRI Shapefile'\nSimple feature collection with 18 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\n1.4 Checking Geospatial Data\n\nArmed Conflict DataAdministrative Boundaries\n\n\n\nclass(acled_sf)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\nst_crs(acled_sf)\n\nCoordinate Reference System: NA\n\n\n\n\n\n\n\n\nNote\n\n\n\nSince\n\nSince the class of acled_sf != sf object\nCoordinate Reference System of acled_sf = NA\n\nwe have to transform it.\n\n\n\n\n\nclass(national_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(national_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\nclass(state_region_subregion_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(state_region_subregion_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\n\n\n\n\nNote\n\n\n\nSince Coordinate Reference System of\n\nnational_boundaries\nstate_region_subregion_boundaries\n\nis in 4326 (unit of measurement = degree), we have to transform it\n\n\n\n\n\n\n\n\n1.5 Understanding the data\n\n# Select relevant columns and group by disorder_type, event_type, sub_event_type\ntype_of_conflict &lt;- acled_sf %&gt;%\n  dplyr::select(disorder_type, event_type, sub_event_type) %&gt;%\n  group_by(disorder_type, event_type, sub_event_type) %&gt;%\n  summarize(count = n(), .groups = 'drop')  # Count occurrences of each combination\nprint(type_of_conflict, n = Inf)\n\n# A tibble: 25 × 4\n   disorder_type                      event_type            sub_event_type count\n   &lt;chr&gt;                              &lt;chr&gt;                 &lt;chr&gt;          &lt;int&gt;\n 1 Demonstrations                     Protests              Peaceful prot…  8132\n 2 Demonstrations                     Protests              Protest with …   463\n 3 Demonstrations                     Riots                 Violent demon…    94\n 4 Political violence                 Battles               Armed clash    11770\n 5 Political violence                 Battles               Government re…     5\n 6 Political violence                 Battles               Non-state act…   274\n 7 Political violence                 Explosions/Remote vi… Air/drone str…  2646\n 8 Political violence                 Explosions/Remote vi… Chemical weap…     1\n 9 Political violence                 Explosions/Remote vi… Grenade          393\n10 Political violence                 Explosions/Remote vi… Remote explos…  5511\n11 Political violence                 Explosions/Remote vi… Shelling/arti…  3655\n12 Political violence                 Explosions/Remote vi… Suicide bomb       2\n13 Political violence                 Riots                 Mob violence      22\n14 Political violence                 Violence against civ… Abduction/for…   905\n15 Political violence                 Violence against civ… Attack          5257\n16 Political violence                 Violence against civ… Sexual violen…    63\n17 Political violence; Demonstrations Protests              Excessive for…   234\n18 Strategic developments             Strategic developmen… Agreement         10\n19 Strategic developments             Strategic developmen… Arrests         4833\n20 Strategic developments             Strategic developmen… Change to gro…  1346\n21 Strategic developments             Strategic developmen… Disrupted wea…   325\n22 Strategic developments             Strategic developmen… Headquarters …    67\n23 Strategic developments             Strategic developmen… Looting/prope…  4042\n24 Strategic developments             Strategic developmen… Non-violent t…    28\n25 Strategic developments             Strategic developmen… Other           1475\n\n\n\n\n\n\n\n\nNote!\n\n\n\nThe dataset includes non-conflict events such as:\n\n“Change to group/activity”\n“Agreement”\n“Headquarters or base established”\n\nAdditionally, it contains a sub-event category labeled “Other”. Including these non-conflict events under the general category of “conflict nature” may lead to biased or misleading interpretations. To ensure accurate and meaningful analysis, I recommend removing these non-conflict events from the dataset.\n\n\n\n\n\n1.6 Data Preparation and Wrangling\n\nArmed Conflict DataAdministrative Boundaries\n\n\n\nConvert Data Frame to sf Object\n\nacled_sf &lt;- acled_sf %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\nclass(acled_sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\nTransform Coordinate Reference System\n\nacled_sf &lt;- acled_sf %&gt;%\n  st_transform(crs = 32647)\n\n\n\nConvert Date Column to Date Format\n\nacled_sf &lt;- acled_sf %&gt;%\n  mutate(event_date = dmy(event_date))\n\n\n\nEliminating Columns not used for analysis\n\nacled_sf &lt;- acled_sf[, !(names(acled_sf) %in% c(\"event_id_cnty\", \"time_precision\", \"inter1\", \"inter2\", \"notes\", \"tags\"))]\n\n\n\nPreparing Data for Quarterly KDE Analysis\n\nCreate a Quarter Column\n\n\nacled_sf &lt;- acled_sf %&gt;%\n  mutate(quarter = paste0(\"Q\", quarter(event_date), \"-\", year(event_date)))\n\n\nRemove non-conflict data\n\n\nnon_conflict_events &lt;- c(\n  \"Change to group/activity\",\n  \"Agreement\",\n  \"Headquarters or base established\",\n  \"Other\"\n)\n\n# Filter out the non-conflict events from the dataset\nconflict_acled_sf_data &lt;- acled_sf %&gt;%\n  filter(!sub_event_type %in% non_conflict_events)\n\n\n\nAdding a new analysis dimension: month\n\nconflict_acled_sf_data &lt;- conflict_acled_sf_data %&gt;%\n  mutate(month = month(event_date))\n\nwrite_rds(conflict_acled_sf_data, \"data/rds/conflict_acled_sf_data.rds\")\n\n\n\n\n\nTransform the Coordinate Reference System of these:\n\nnational_boundaries &lt;- national_boundaries %&gt;%\n  st_transform(crs = 32647)\n\nstate_region_subregion_boundaries &lt;- state_region_subregion_boundaries %&gt;%\n  st_transform(crs = 32647)\n\n\n\nSample plot\n\nggplot(data = state_region_subregion_boundaries) +\n  geom_sf() +\n  theme_minimal() +\n  labs(title = \"Map of Geometries\",\n       subtitle = \"Displaying multipolygon geometries\",\n       caption = \"Source: Example Data\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.0 Exploratory Data Analysis\n\n2.1 Temporal Analysis: Frequency of Conflict Events Over Time\n\nggplot(conflict_acled_sf_data, aes(x = event_date)) +\n  geom_histogram(binwidth = 30, fill = \"steelblue\", color = \"black\") +\n  labs(title = \"Conflict Events Over Time\", x = \"Date\", y = \"Number of Events\")\n\n\n\n\n\n\n\n\n\n\n2.2 Event Type Distribution\n\nggplot(conflict_acled_sf_data, aes(x = event_date, fill = event_type)) +\n  geom_histogram(binwidth = 30) +\n  labs(title = \"Event Types Over Time\", x = \"Date\", y = \"Number of Events\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n2.3 Spatial Analysis\n\n# Plot a choropleth of the conflict events by year using ggplot2\nggplot() +\n  geom_sf(data = national_boundaries, fill = \"lightgrey\") +\n  geom_sf(data = conflict_acled_sf_data, aes(color = event_type), size = 0.1, alpha = 0.6) +\n  facet_wrap(~year, ncol = 4) +  # Facet by year with 4 columns\n  labs(title = \"Spatial Distribution of Conflict Events by Year\", color = \"Event Type\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") + \n  guides(color = guide_legend(override.aes = list(size = 1)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nFrom 2021 to 2024, the conflicts in Myanmar have escalated significantly, evolving from largely peaceful protests to increasingly violent confrontations and armed battles.\n\n\n\n\n2.4 Conflict Hotspots by state & region\n\n2.4.1 Preparing the hotspots\n\n# Ensure the CRS of both datasets match\nconflict_acled_sf_data &lt;- st_transform(conflict_acled_sf_data, crs = st_crs(state_region_subregion_boundaries))\n\n# Perform spatial join to add state/region information to the conflict dataset\nacled_with_state_region &lt;- st_join(conflict_acled_sf_data, state_region_subregion_boundaries, join = st_intersects)\n\n# Filter out rows where ST is NA before summarizing\nacled_with_state_region &lt;- acled_with_state_region %&gt;%\n  filter(!is.na(ST))\n\n# Group by state/region and summarize conflict data\nconflict_summary_by_state_region &lt;- acled_with_state_region %&gt;%\n  group_by(ST, event_type, year) %&gt;%\n  summarise(\n    total_conflicts = n(),\n    total_fatalities = sum(fatalities, na.rm = TRUE),\n    .groups = 'drop'\n  )\n\n# Convert state boundaries to a regular data frame (non-spatial)\nstate_region_boundaries_df &lt;- as.data.frame(state_region_subregion_boundaries)\n\n# Merge the summary data with the state boundaries data frame\nstate_region_boundaries_summary &lt;- state_region_boundaries_df %&gt;%\n  left_join(conflict_summary_by_state_region, by = c(\"ST\" = \"ST\"))\n\n# Convert back to an sf object with geometry\nstate_region_boundaries_summary &lt;- st_as_sf(state_region_boundaries_summary, crs = st_crs(state_region_subregion_boundaries))\n\n\n\n2.4.2 Plot the Hotspots\n\n# Base map with state/region boundaries\nstate_region_hotspot_tm &lt;- tm_shape(state_region_boundaries_summary) +\n  tm_polygons(col = \"lightgrey\", border.col = \"black\") +\n  \n  # Overlay conflict data\n  tm_shape(conflict_summary_by_state_region) +\n  tm_dots(\n    col = \"event_type\", \n    palette = \"viridis\", \n    size = \"total_conflicts\", \n    alpha = 0.6)  +\n  \n  # Layout adjustments\n  tm_layout(\n    frame = FALSE,  # Remove the frame around the plot\n    legend.outside = TRUE,  # Keep the legend outside\n    legend.outside.position = \"bottom\",  # Position the legend outside at the bottom\n    legend.outside.size = 0.1,  # Adjust the size of the outside legend (reduce if too large)\n  ) +\n  \n  # Faceting by state/region\n  tm_facets(\n    by = c(\"ST\"),\n    free.scales = FALSE  # Use a common scale across all facets\n  )\n\nprint(state_region_hotspot_tm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nThis map illustrates conflict patterns across a four-year period, revealing significant regional variations. It highlights that certain states and regions experience relatively lower levels of conflict, indicating greater overall peace.\nConversely, other areas show higher concentrations of specific types of conflicts. This distribution helps identify regions with frequent conflict events and those more prone to particular conflict types, offering valuable insights into the geographical and thematic spread of conflicts.\n\n\n\n\n2.4.3 Visualize by Event Type\n\n# Define the conflict types\nconflict_types &lt;- c(\"Battles\", \"Protests\", \"Strategic developments\", \"Explosions/Remote violence\", \"Riots\", \"Violence against civilians\")\n\n# Initialize an empty list to store summaries\nconflict_summaries &lt;- list()\n\n# Loop through each conflict type and summarize the data\nfor (type in conflict_types) {\n  summary &lt;- acled_with_state_region %&gt;%\n    filter(event_type == type) %&gt;%\n    group_by(ST) %&gt;%\n    summarise(\n      total_events = n(),\n      .groups = 'drop'\n    )\n  \n  # Store the summary in the list with the conflict type as the key\n  conflict_summaries[[type]] &lt;- summary\n}\n\n# Convert state boundaries to a regular data frame (non-spatial)\nstate_region_subregion_boundaries_df &lt;- as.data.frame(state_region_subregion_boundaries)\n\n# Merge each summary with the state boundaries data frame\nregion_conflict_summaries &lt;- lapply(conflict_summaries, function(summary) {\n  region_summary &lt;- state_region_subregion_boundaries_df %&gt;%\n    left_join(summary, by = \"ST\")\n  \n  # Convert back to an sf object with geometry\n  st_as_sf(region_summary, crs = st_crs(state_region_subregion_boundaries))\n})\n\n# Rename the list elements for clarity\nnames(region_conflict_summaries) &lt;- conflict_types\n\n\n# Create a list to store plots\nplots &lt;- list()\n\n# Loop through each conflict type to create a plot\nfor (type in conflict_types) {\n  plots[[type]] &lt;- tm_shape(region_conflict_summaries[[type]]) +\n    tm_polygons(\n      col = \"total_events\", \n      palette = \"Reds\", \n      title = paste(\"Number of\", type),\n      border.col = \"black\",\n      style = \"quantile\"  # This divides the data into quantiles for better visualization\n    ) +\n    \n    tm_text(\n      text = \"ST\",  # Use the column name that contains the region names\n      size = 0.6,        # Adjust the size as needed\n      col = \"black\",     # Text color\n      shadow = TRUE,    # Optional: Add shadow to make text more readable\n      remove.overlap = TRUE  # Avoid text overlapping\n    ) +\n    \n    tm_layout(\n      frame = FALSE,  # Remove the frame around the plot\n      legend.outside = TRUE,  # Keep the legend outside\n      legend.outside.position = \"right\",  # Position the legend outside at the bottom\n      legend.outside.size = 0.4  # Adjust the size of the outside legend (reduce if too large)\n    ) +\n    \n    tm_legend(\n      position = c(\"right\", \"bottom\")  # Position the legend outside at the bottom\n    )\n}\n\n\n# Arrange all plots in a single view using tm_arrange\ncombined_plot &lt;- tmap_arrange(plots, ncol = 2, nrow = 3, \n                             legend.position = c(\"right\", \"bottom\"), \n                             legend.outside = TRUE)\n\n# Print the combined plot\nprint(combined_plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.0 Deriving Quarterly KDE layers\nKernel Density Estimation (KDE) provides a comprehensive view of where conflicts are occurring by visualizing the density of events across different quarters. By analyzing KDE on a quarterly basis, we can identify areas with high conflict intensity and gain insights into how the distribution of conflicts evolves over time. This approach helps in understanding temporal patterns and hotspots, offering a more detailed perspective on conflict dynamics.\nFor quarterly KDE layers:\n\nSubset data by quarter and compute KDE for each subset using spatstat\n\n\n\n\n\n\n\nNote on Handling Duplicate Points\n\n\n\nDuplicate points are removed in the analysis to avoid artificially inflating the density estimate. Including duplicates could lead to an exaggerated representation of conflict hotspots, as each duplicate would incorrectly suggest multiple occurrences of the same event. By removing duplicates, we ensure that the Kernel Density Estimation (KDE) reflects the true intensity and distribution of distinct armed conflict events, providing a more accurate and reliable identification of hotspots.\n\n\n\n1. Create a list to store KDE for each quarter\n\nkde_list &lt;- list()\n\n\n\n2. Get Unique Quarters\n\nquarters &lt;- unique(conflict_acled_sf_data$quarter)\n\n\n\n3. Perform Kernel Density Estimation (KDE)\n\nboundary_window &lt;- as.owin(national_boundaries)\n\n# Loop over each quarter to process data\nfor (q in quarters) {\n  \n  # Filter the dataset for the current quarter\n  quarter_data &lt;- conflict_acled_sf_data %&gt;%\n    filter(quarter == q)\n  \n  # Remove duplicates\n  coords &lt;- st_coordinates(st_geometry(quarter_data))\n  if (any(duplicated(coords))) {\n    quarter_data &lt;- quarter_data %&gt;%\n      distinct(st_coordinates(st_geometry(.)), .keep_all = TRUE)\n  }\n  \n  # Convert the filtered data to a spatial point pattern (ppp object)\n  quarter_ppp &lt;- as.ppp(st_geometry(quarter_data), W = boundary_window)\n  \n  # Perform Kernel Density Estimation (KDE)\n  kde &lt;- density(quarter_ppp, sigma = 0.1)  # Adjust sigma as needed for smoothness\n  \n  # Store KDE in the list\n  kde_list[[q]] &lt;- kde\n}\n\nWarning: 2 points were rejected as lying outside the specified window\n\n\nWarning: 1 point was rejected as lying outside the specified window\nWarning: 1 point was rejected as lying outside the specified window\nWarning: 1 point was rejected as lying outside the specified window\n\n\n\n\n4. Plot the KDE for Each Quarter\n\npar(mfcol=c(5, 3))\n# Plot the KDEs for all quarters\nfor (q in quarters) {\n  if (!is.null(kde_list[[q]])) {\n    plot(kde_list[[q]], main = paste(\"KDE for\", q))\n  } else {\n    print(paste(\"No KDE available for quarter:\", q))\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n3.0 Performing 2nd-Order Spatial Point Patterns Analysis\nNow, we will explore how armed conflict events are distributed and related.\nRipley’s K-function is a useful tool for detecting whether events are clustered or spread out. It measures how the density of events changes with distance, helping to identify clustering or dispersion.\nWhereas G-Function examine the nearest-neighbor distances and understand how far apart the nearest events are.\nF-Function analyze the distribution of distances from a randomly chosen location to the nearest event\n\nComputing K-Function Estimation\n\n# Initialize list to store K-function results\nkfunction_list &lt;- list()\n\n# Get unique quarters from the dataset\nquarters &lt;- unique(conflict_acled_sf_data$quarter)\n\n# Loop over each quarter to compute K-function\nfor (q in quarters) {\n  \n  # Filter the dataset for the current quarter\n  quarter_data &lt;- conflict_acled_sf_data %&gt;%\n    filter(quarter == q)\n  \n  # Remove duplicates\n  coords &lt;- st_coordinates(st_geometry(quarter_data))\n  if (any(duplicated(coords))) {\n    quarter_data &lt;- quarter_data %&gt;%\n      distinct(st_coordinates(st_geometry(.)), .keep_all = TRUE)\n  }\n  \n  # Convert the filtered data to a spatial point pattern (ppp object)\n  quarter_ppp &lt;- as.ppp(st_geometry(quarter_data), W = as.owin(national_boundaries))\n  \n  # Compute the K-function\n  kfunction &lt;- Kest(quarter_ppp, correction = \"border\")\n  \n  # Store the K-function in the list\n  kfunction_list[[q]] &lt;- kfunction\n}\n\nWarning: 2 points were rejected as lying outside the specified window\n\n\nWarning: 1 point was rejected as lying outside the specified window\nWarning: 1 point was rejected as lying outside the specified window\nWarning: 1 point was rejected as lying outside the specified window\n\n\n\n\n\n\n\n\nNote\n\n\n\nRipley’s Correction: Provides a more sophisticated adjustment for edge effects by modifying the expected K-function, leading to potentially more accurate results in large areas. Border Correction: Simplifies the adjustment by extending the study area and is less computationally intensive but might be less accurate in areas with significant boundary effects.\nWe use correction = “border” rather than correction = “Ripley” for our analysis. Our primary goal is to observe the general distribution of conflict hotspots, which will guide more detailed follow-up studies. Given that our focus is on broad patterns rather than precise details, the simpler and less computationally intensive border correction is sufficient. While Ripley’s correction offers more accuracy by adjusting for edge effects, it requires more computational resources and time, which we can afford to forego for this preliminary analysis.\n\n\n\n\nPlotting K-Function\nInterpretation:\n\nAbove the theoretical line: Indicates clustering of points.\nBelow the theoretical line: Suggests dispersion or regularity.\nClose to the line: Implies a random distribution.\n\n\npar(mfcol=c(5, 3))\n# Plot the K-functions for all quarters\nfor (q in quarters) {\n  if (!is.null(kfunction_list[[q]])) {\n    # Plot K-function\n    plot(kfunction_list[[q]], . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\", main = paste(\"K-function for Quarter\", q))\n  } else {\n    print(paste(\"No K-function available for quarter:\", q))\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n4.0 Deriving Quarterly spatio-temporal KDE layers\n\n# Define the output directory for saving KDE plots\noutput_dir &lt;- \"quarterly_kde_images\"\ndir.create(output_dir, showWarnings = FALSE)\n\n# Define a list to hold filenames of saved KDE plots\nsaved_files &lt;- list()\n\n# Define a function to create and save KDE plots for each quarter\nsave_kde_plot &lt;- function(kde, quarter, output_dir) {\n  # Create a file path for the KDE image\n  file_name &lt;- file.path(output_dir, paste0(\"quarterly_kde_\", gsub(\" \", \"_\", quarter), \".png\"))\n  \n  # Open a PNG device to save the plot\n  png(file_name, width = 800, height = 800)\n  \n  # Plot KDE\n  plot(kde, main = paste(\"Spatio-Temporal KDE for\", quarter))\n  \n  # Close the PNG device\n  dev.off()\n  \n  # Print confirmation message\n  print(paste(\"Saved:\", file_name))\n  \n  # Return the filename of the saved plot\n  return(file_name)\n}\n\n# Generate and save KDE plots for each quarter in reverse chronological order\nfor (q in rev(quarters)) {\n  if (!is.null(kde_list[[q]])) {\n    file_name &lt;- save_kde_plot(kde_list[[q]], q, output_dir)\n    saved_files &lt;- append(saved_files, file_name)\n  } else {\n    print(paste(\"No KDE data available for quarter:\", q))\n  }\n}\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q1-2021.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q2-2021.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q3-2021.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q4-2021.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q1-2022.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q2-2022.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q3-2022.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q4-2022.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q1-2023.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q2-2023.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q3-2023.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q4-2023.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q1-2024.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q2-2024.png\"\n\n\n\n# Load saved images and combine them into an animated GIF\nimages &lt;- lapply(saved_files, image_read)\n\n# Create an animation from the KDE images\nanimation &lt;- image_animate(image_join(images), fps = 1)\n\n# Define the path for the GIF animation\ngif_path &lt;- \"spatio_temporal_kde_animation.gif\"\n\n# Save the animation as a GIF file\nimage_write(animation, path = gif_path)\n\n# Print confirmation that the GIF was saved\nprint(\"Spatio-temporal KDE animation saved as spatio_temporal_kde_animation.gif\")\n\n[1] \"Spatio-temporal KDE animation saved as spatio_temporal_kde_animation.gif\"\n\n# Display the GIF using magick\ngif_image &lt;- image_read(gif_path)\nprint(gif_image) \n\n# A tibble: 14 × 7\n   format width height colorspace matte filesize density\n   &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n 1 GIF      800    800 sRGB       FALSE        0 72x72  \n 2 GIF      800    800 sRGB       FALSE        0 72x72  \n 3 GIF      800    800 sRGB       FALSE        0 72x72  \n 4 GIF      800    800 sRGB       FALSE        0 72x72  \n 5 GIF      800    800 sRGB       FALSE        0 72x72  \n 6 GIF      800    800 sRGB       FALSE        0 72x72  \n 7 GIF      800    800 sRGB       FALSE        0 72x72  \n 8 GIF      800    800 sRGB       FALSE        0 72x72  \n 9 GIF      800    800 sRGB       FALSE        0 72x72  \n10 GIF      800    800 sRGB       FALSE        0 72x72  \n11 GIF      800    800 sRGB       FALSE        0 72x72  \n12 GIF      800    800 sRGB       FALSE        0 72x72  \n13 GIF      800    800 sRGB       FALSE        0 72x72  \n14 GIF      800    800 sRGB       FALSE        0 72x72  \n\n\n\n\n\n\n\n\n\n\n\n5.0 Performing 2nd-Order Spatio-temporal Point Patterns\n\n# Define the output directory for saving K-function plots\nkfunction_output_dir &lt;- \"quarterly_kfunction_images\"\ndir.create(kfunction_output_dir, showWarnings = FALSE)\n\n# Define a list to hold filenames of saved K-function plots\nkfunction_files &lt;- list()\n\n# Define a function to create and save K-function plots for each quarter\nsave_kfunction_plot &lt;- function(kfunction, quarter, output_dir) {\n  # Create a file path for the K-function image\n  file_name &lt;- file.path(output_dir, paste0(\"quarterly_kfunction_\", gsub(\" \", \"_\", quarter), \".png\"))\n  \n  # Open a PNG device to save the plot\n  png(file_name, width = 800, height = 800)\n  \n  # Plot K-function\n  plot(kfunction, . -r ~ r, ylab = \"K(d) - d\", xlab = \"d (m)\", main = paste(\"Ripley's K-function for Quarter\", quarter))\n  \n  # Close the PNG device\n  dev.off()\n  \n  # Print confirmation message\n  print(paste(\"Saved:\", file_name))\n  \n  # Return the filename of the saved plot\n  return(file_name)\n}\n\n# Save K-function plots for each quarter\nfor (q in rev(quarters)) {\n  if (!is.null(kfunction_list[[q]])) {\n    file_name &lt;- save_kfunction_plot(kfunction_list[[q]], q, kfunction_output_dir)\n    kfunction_files &lt;- append(kfunction_files, file_name)\n  } else {\n    print(paste(\"No K-function data available for quarter:\", q))\n  }\n}\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q1-2021.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q2-2021.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q3-2021.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q4-2021.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q1-2022.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q2-2022.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q3-2022.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q4-2022.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q1-2023.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q2-2023.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q3-2023.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q4-2023.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q1-2024.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q2-2024.png\"\n\n\n\n# Load saved images and combine them into an animated GIF\nkfunction_images &lt;- lapply(kfunction_files, image_read)\n\n# Create an animation from the K-function images\nkfunction_animation &lt;- image_animate(image_join(kfunction_images), fps = 1)\n\n# Define the path for the GIF animation\nkfunction_gif_path &lt;- \"spatio_temporal_kfunction_animation.gif\"\n\n# Save the animation as a GIF file\nimage_write(kfunction_animation, path = kfunction_gif_path)\n\n# Print confirmation that the GIF was saved\nprint(\"Ripley's K-function animation saved as spatio_temporal_kfunction_animation.gif\")\n\n[1] \"Ripley's K-function animation saved as spatio_temporal_kfunction_animation.gif\"\n\n# Display the GIF using magick\nkfunction_gif_image &lt;- image_read(kfunction_gif_path)\nprint(kfunction_gif_image)\n\n# A tibble: 14 × 7\n   format width height colorspace matte filesize density\n   &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n 1 GIF      800    800 sRGB       FALSE        0 72x72  \n 2 GIF      800    800 sRGB       FALSE        0 72x72  \n 3 GIF      800    800 sRGB       FALSE        0 72x72  \n 4 GIF      800    800 sRGB       FALSE        0 72x72  \n 5 GIF      800    800 sRGB       FALSE        0 72x72  \n 6 GIF      800    800 sRGB       FALSE        0 72x72  \n 7 GIF      800    800 sRGB       FALSE        0 72x72  \n 8 GIF      800    800 sRGB       FALSE        0 72x72  \n 9 GIF      800    800 sRGB       FALSE        0 72x72  \n10 GIF      800    800 sRGB       FALSE        0 72x72  \n11 GIF      800    800 sRGB       FALSE        0 72x72  \n12 GIF      800    800 sRGB       FALSE        0 72x72  \n13 GIF      800    800 sRGB       FALSE        0 72x72  \n14 GIF      800    800 sRGB       FALSE        0 72x72  \n\n\n\n\n\n\n\n\n\n\n\n\n6.0 Analysis using Openstreetmap of Myanmar\nWe can make use of OpenStreetMap(OSM) data to create a vivid picture of how armed conflict affects not just the landscape but also the lives and infrastructure essential for the population. From identifying hotspots to understanding the disruption of critical services, here’s how we can delve deeper into the conflict’s impact.\n\n6.1 Download OSM Data\n\n\n\n\n\n\n\nMapping Conflict Hotspots and Assessing Infrastructure Risks\n\n\nConflicts are rarely isolated events. They often impact critical infrastructures such as roads, hospitals, and schools. By mapping these infrastructures and overlaying conflict event data, we can identify areas at risk and evaluate the potential disruption to civilian services.\n\nProximity Analysis to Critical Infrastructure:\nUsing OSM, we can pinpoint key infrastructure locations. For instance, if we map hospitals and schools across conflict-affected regions, we can then measure how close these events are to such critical points. This helps us identify high-risk zones where services are most likely to be disrupted, putting civilian lives and wellbeing at immediate risk.\nAssessing Road and Transportation Disruption:\nRoads are the lifelines that connect people to essential services and humanitarian aid. By mapping major highways and railways, we can overlay conflict data to see which routes are most affected. Visualizing these disrupted routes can highlight areas where civilian movement is restricted, potentially hindering access to safety or relief.\n\n\nconflict_acled_sf_data &lt;- read_rds(\"data/rds/conflict_acled_sf_data.rds\")\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n# List of all states in Myanmar\nstates &lt;- c(\"Ayeyarwady\", \"Kayah\", \"Kayin\", \n            \"Magway\", \"Rakhine\", \"Tanintharyi\", \"Yangon\")\n\n# Initialize an empty list to store the maps\nmaps &lt;- list()\n\n# Loop through each state to create maps\nfor (state in states) {\n  # Construct file paths for roads and amenities data\n  road_data_path &lt;- paste0(\"data/rds/\", tolower(state), \"_roads.rds\")\n  amenity_data_path &lt;- paste0(\"data/rds/\", tolower(state), \"_amenities.rds\")\n  \n  # Check if the files exist before reading\n  if (file.exists(road_data_path) && file.exists(amenity_data_path)) {\n    # Read road and amenities data for the current state\n    roads &lt;- read_rds(road_data_path)\n    amenities &lt;- read_rds(amenity_data_path)\n    \n    # Check that the road and amenities data have valid geometry\n    if (!is.null(roads$osm_lines) && !is.null(amenities)) {\n      roads_sf &lt;- roads$osm_lines\n      amenities_sf &lt;- amenities\n      \n      # Set conflict dot size based on the state\n      conflict_dot_size &lt;- ifelse(state %in% c(\"Ayeyarwady\", \"Magway\"), 0.01, 0.1)\n      \n      # Create the map for the current state\n      state_map &lt;- tm_shape(roads_sf) +\n        tm_lines(col = \"gray\", lwd = 0.5) +  # Add lines for roads\n        tm_shape(amenities_sf) +  \n        tm_symbols(col = \"amenity\", size = 0.01, shape = 21,\n                   palette = c(\"yellow\", \"blue\", \"green\", \"orange\", \"purple\"),\n                   title.col = \"Amenity Type\") +  # Color by amenity type\n        tm_shape(conflict_acled_sf_data) +  # Ensure this is defined correctly\n        tm_symbols(size = conflict_dot_size, col = \"red\", shape = 3, style = \"cont\") +\n        tm_layout(title = paste(\"Key Amenities and Conflict Events in\", state),\n                  title.position = c(\"center\", \"top\"),\n                  legend.text.size = 0.8,\n                  legend.title.size = 1.0,\n                  title.size = 1.0,\n                  title.color = \"black\",\n                  legend.position = c(\"right\", \"bottom\"))\n      \n      # Store the map in the list\n      maps[[state]] &lt;- state_map\n    } else {\n      warning(paste(\"Invalid or empty data for state:\", state))\n    }\n  } else {\n    warning(paste(\"Files not found for state:\", state))\n  }\n}\n\nif (length(maps) &gt; 0) {\n  # Arrange and display all maps in a grid format\n  do.call(tmap_arrange, c(maps, list(ncol = 2)))\n} else {\n  warning(\"No maps available to display.\")\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotably, conflict events tend to be concentrated around major road networks, indicating potential hotspots of unrest and activity.\n\n\n\n\n\n\n\n\nLearnings/Reflections\n\nLearningsReflections\n\n\n\nImportance of Data Storage: To speed up my project, I used the write_rds method to save downloaded files, especially from OpenStreetMap (OSM). This helps me avoid repeated downloads.\nChoosing Visualization Tools: I found that tmap is easier for users to understand when visualizing maps compared to ggplot2, which can be more complex, especially for global views.\nKDE Selection: The choice of bandwidth for Kernel Density Estimation (KDE) depends on the specific needs of the analysis.\n\n\n\nThis exercise has been both insightful and challenging. I tried various plotting methods, experiencing both successes and failures. Some results met my expectations, while others revealed new insights that encouraged me to dig deeper.\nI’ve not only improved my technical skills but also gained a greater understanding of the ethical aspects of data representation. Each map I create tells a story of resilience and struggle. Merging data, cleaning it, and presenting it with ggplot2 and tmap has shown me how important it is to communicate clearly and accurately."
  },
  {
    "objectID": "Notes/Lesson_5.html",
    "href": "Notes/Lesson_5.html",
    "title": "Notes 5",
    "section": "",
    "text": "A way to define spatial neighbourhood\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt measure from centroid!\nNeed to clean data properly. EG. If we only need to find the childcare in SG, we should remove the outer island, else u might see centroid being not in the center of where you expect it"
  },
  {
    "objectID": "Notes/Lesson_5.html#spatial-weights-wij",
    "href": "Notes/Lesson_5.html#spatial-weights-wij",
    "title": "Notes 5",
    "section": "",
    "text": "A way to define spatial neighbourhood\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt measure from centroid!\nNeed to clean data properly. EG. If we only need to find the childcare in SG, we should remove the outer island, else u might see centroid being not in the center of where you expect it"
  },
  {
    "objectID": "Notes/Lesson_2.html",
    "href": "Notes/Lesson_2.html",
    "title": "Notes 2",
    "section": "",
    "text": "A type of thematic map, areas shaded, values aggregated into geographical layer (eg. subzone)\nThe shading is the things we want to map (eg. Dependency ratio)\n\n\n\n\n\n\ncombines areal units into small no. of groups (10 methods eg. ‘equal’, ‘quantile’)\n\nNo. of Classes\n\nif &lt;4, overly generalized map [Can use depending on context, eg. USA election, red camp VS blue camp]\nkeep &lt;= 12, 7/8 shades of the same color\nif too many, our eyes cannot differentiate them wel\n\n\nequal = divide into same range (not suitable for highly skewed data set)\nquantile -&gt; into different percentage\nnatural breaks (a.k.a. jenks) -&gt; fuse between equal & quantile method\nstandard deviation -&gt; if data is normal distribution only\n\n\n\n\nmap it to the color, spectrum (the value) (eg. 0 -&gt; 223)\n\n\n\n\n\n\n* Nominal Color Scheme -&gt; Only for categorical data\n\n\n\n\n\n\n\nColor Scheme\nRemarks\n\n\n\n\n\nOnly for categorical data\n\n\n\nFor continuous\n+\nAll value +/-\n\n\n\nFor continuous\n+\nValue have both +/- only"
  },
  {
    "objectID": "Notes/Lesson_2.html#types-of-choropleth-map",
    "href": "Notes/Lesson_2.html#types-of-choropleth-map",
    "title": "Notes 2",
    "section": "",
    "text": "combines areal units into small no. of groups (10 methods eg. ‘equal’, ‘quantile’)\n\nNo. of Classes\n\nif &lt;4, overly generalized map [Can use depending on context, eg. USA election, red camp VS blue camp]\nkeep &lt;= 12, 7/8 shades of the same color\nif too many, our eyes cannot differentiate them wel\n\n\nequal = divide into same range (not suitable for highly skewed data set)\nquantile -&gt; into different percentage\nnatural breaks (a.k.a. jenks) -&gt; fuse between equal & quantile method\nstandard deviation -&gt; if data is normal distribution only\n\n\n\n\nmap it to the color, spectrum (the value) (eg. 0 -&gt; 223)"
  },
  {
    "objectID": "Notes/Lesson_2.html#colour-scheme--colorbrewer",
    "href": "Notes/Lesson_2.html#colour-scheme--colorbrewer",
    "title": "Notes 2",
    "section": "",
    "text": "* Nominal Color Scheme -&gt; Only for categorical data\n\n\n\n\n\n\n\nColor Scheme\nRemarks\n\n\n\n\n\nOnly for categorical data\n\n\n\nFor continuous\n+\nAll value +/-\n\n\n\nFor continuous\n+\nValue have both +/- only"
  },
  {
    "objectID": "Notes/Lesson_2.html#shape-objects",
    "href": "Notes/Lesson_2.html#shape-objects",
    "title": "Notes 2",
    "section": "Shape objects",
    "text": "Shape objects\n\n\ntmap element\n-&gt; always start with tm_shape()\n* Put plus(+) sign to indicate it is a continuous code (Put it at the back)\n\n-&gt; can later add\n\n-&gt;can choose from this list\n\n\n\n\ntm_polygons()\n\ndefault classes = 5bins\ndefault classification method = “pretty”\ndefault color scheme = “YIOrRd” (yellow-orange)\nmissing value = gray\n\n\n\n\ntm_border()\n\ndefault lwd (border line width) = 1\nalpha = between 0 (totally transparent) and 1 (not transparent)\n\nDefault alpha = 1\n\ncol (border color)\ndefault lty (border line type) = “solid”"
  },
  {
    "objectID": "Notes/Lesson_2.html#map-geographical-data",
    "href": "Notes/Lesson_2.html#map-geographical-data",
    "title": "Notes 2",
    "section": "Map & Geographical Data",
    "text": "Map & Geographical Data"
  },
  {
    "objectID": "Notes/Lesson_2.html#geo-vs-aspatial-data",
    "href": "Notes/Lesson_2.html#geo-vs-aspatial-data",
    "title": "Notes 2",
    "section": "Geo VS Aspatial Data",
    "text": "Geo VS Aspatial Data\n\n\n\n\n\n\n\n\n\nReference Maps\nshow buildings, roads, vegetation, rivers\neg. topo map like Google Map\n\n\nThematic Map\n\nemphasize the spatial pattern of geographic attributes or statistics about places and relationships between places such as Life in Los Angeles."
  },
  {
    "objectID": "Notes/Lesson_2.html#qualitative-thematic-map",
    "href": "Notes/Lesson_2.html#qualitative-thematic-map",
    "title": "Notes 2",
    "section": "Qualitative Thematic Map",
    "text": "Qualitative Thematic Map\n\n\n\n\n\n\n\nPoint symbol map\nUse point to represent school types\n\n\n\nLine symbol map\nShow road network\nDifferent color intensity and thickness are used to differentiate hierarchy of roads\n\n\n\nArea Map\ndifferent colors to represent different land use types"
  },
  {
    "objectID": "Notes/Lesson_2.html#proportional-symbol-map",
    "href": "Notes/Lesson_2.html#proportional-symbol-map",
    "title": "Notes 2",
    "section": "Proportional Symbol Map",
    "text": "Proportional Symbol Map\nUse symbols of different sizes to represent data associated with different areas\n\nGo for this kind:"
  },
  {
    "objectID": "Notes/Lesson_2.html#proportional-symbol-map--bar-chart-map",
    "href": "Notes/Lesson_2.html#proportional-symbol-map--bar-chart-map",
    "title": "Notes 2",
    "section": "Proportional Symbol Map -Bar Chart Map",
    "text": "Proportional Symbol Map -Bar Chart Map"
  },
  {
    "objectID": "Notes/Lesson_2.html#proportional-symbol-map--pie-chart-map",
    "href": "Notes/Lesson_2.html#proportional-symbol-map--pie-chart-map",
    "title": "Notes 2",
    "section": "Proportional Symbol Map -Pie Chart Map",
    "text": "Proportional Symbol Map -Pie Chart Map"
  },
  {
    "objectID": "Notes/Lesson_2.html#proportional-symbol-map--junk-map",
    "href": "Notes/Lesson_2.html#proportional-symbol-map--junk-map",
    "title": "Notes 2",
    "section": "Proportional Symbol Map -Junk Map",
    "text": "Proportional Symbol Map -Junk Map\n\n* ensure geographical lvl used is same"
  },
  {
    "objectID": "Notes/Lesson_2.html#brick-map",
    "href": "Notes/Lesson_2.html#brick-map",
    "title": "Notes 2",
    "section": "Brick Map",
    "text": "Brick Map\n\nbetter to encode quantitative info graphically"
  },
  {
    "objectID": "Notes/Lesson_2.html#bricks-vs-proportional-symbol-map",
    "href": "Notes/Lesson_2.html#bricks-vs-proportional-symbol-map",
    "title": "Notes 2",
    "section": "Bricks VS Proportional Symbol Map",
    "text": "Bricks VS Proportional Symbol Map\n\n\nProportional Symbol map can be more difficult to distinguish than brick"
  },
  {
    "objectID": "Notes/Lesson_2.html#dot-density-map",
    "href": "Notes/Lesson_2.html#dot-density-map",
    "title": "Notes 2",
    "section": "Dot Density Map",
    "text": "Dot Density Map\n\na type of thematic map -&gt; use dot/symbols to show the values of &gt;= 1 numeric value\neach dot represent some amt of data"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS455",
    "section": "",
    "text": "Welcome to IS455 Geospatial Analytics and Application. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "Overview\nSpatio-Temporal Point Pattern: A random collection of points representing time and location of events (eg. disease incidences, species sightings, fires, earthquakes, lightning strikes, tsunamis, volcanic eruptions.)\nImportance: Increasingly necessary due to growth in geographically and temporally indexed data across various fields.\nApplication Example:\n\nAnalysis of forest fire events in Kepulauan Bangka Belitung, Indonesia (1 Jan 2023 - 31 Dec 2023).\n\nWe want to find out\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?\n\n\n\n1.0 Setup\n\n1.1 Installing R-Packages\nsf: provides functions for importing processing and wrangling geospatial data\nraster: for handling raster data in R\nspatstat: for performing Spatial Point Patterns Analysis such as kcross, Lcross, etc.\nsparr: provides functions to estimate fixed and adaptive kernel-smoothed spatial relative risk surfaces via the density-ratio method and perform subsequent inference. Fixed-bandwidth spatiotemporal density and relative risk estimation is also supported\ntmap: provides functions to produce cartographic quality thematic maps\ntidyverser: provide functions to perform common data science tasks including and not limited to data import, data transformation, data wrangling and data visualisation\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, sparr)\n\n\n\n1.2 Data Acquisition\nWe will be using 2 sets of data:\n\nforestfires (CSV file):\n\nContains locations of forest fires from MODIS sensor data.\nDownloaded from the Fire Information for Resource Management System.\nFocus: Only forest fires in Kepulauan Bangka Belitung.\n\nKepulauan_Bangka_Belitung (ESRI shapefile):\n\nShows sub-district boundaries (kelurahan) of Kepulauan Bangka Belitung.\nDownloaded from the Indonesia Geospatial Portal.\nFocus: Only sub-districts within Kepulauan Bangka Belitung (original data covers all of Indonesia).\n\n\n\n\n1.3 Importing And Preparing Study Area/Forest Fire data\n\nStudy AreaForest Fire Data\n\n\n\nImporting study area\n\nkbb &lt;- st_read(dsn = \"data/rawdata\",        \n               layer = \"Kepulauan_Bangka_Belitung\")\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\In-class_Ex\\In-class_Ex04\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nTo dissolve\n\nkbb_sf &lt;- kbb %&gt;% \n  st_union()\n\nst_as_s2(): dropping Z and/or M coordinate\n\n\nDrop the Z value in geometry so it become polygon\n\nkbb_sf &lt;- kbb_sf %&gt;% \n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 32748)\n\n\n\n\n\nImporting Fire Data\n\nfire_sf &lt;- read_csv(\"data/rawdata/forestfires.csv\") %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n           crs = 4326) %&gt;% \n  st_transform(crs = 32748)\n\nRows: 741 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): satellite, instrument, daynight\ndbl  (11): latitude, longitude, brightness, scan, track, acq_time, confidenc...\ndate  (1): acq_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nBecause ppp object only accept numerical or character as mark, we need to convert data type of acq_date to numeric.\n\nfire_sf &lt;- fire_sf %&gt;% \n  mutate(DayOfYear = yday(acq_date)) %&gt;% \n  mutate(Month_num = month(acq_date)) %&gt;% \n  mutate(Month_fac = month(acq_date,\n                           label = TRUE,\n                           abbr = FALSE))\n\n\n\n\n\n\n\n\n2.0 Creating owin\n\nkbb_owin &lt;- as.owin(kbb_sf)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\n\nclass(kbb_owin)\n\n[1] \"owin\"\n\n\n\n\n3.0 Visualising the Fire Points\n\n3.1 Overall plot\n\ntm_shape(kbb_sf)+\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\n\n3.2 Visualizing geographic distribution of forest fires by month\n\ntm_shape(kbb_sf) +\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots(size = 0.1) +\n  tm_facets(by=\"Month_fac\",\n            free.coords = FALSE, #if change to true, the zoom lvl will be to where the data is\n            drop.units = TRUE)\n\n\n\n\n\n\n\n\n\n\n3.3 Computing STKDE by Month\nusing spattemp.density()\n\n3.3.1 Extracting forest fires by month\n* This will create a new dataset with only the month & geometry data\n\nfire_month &lt;- fire_sf %&gt;% \n  select(Month_num)\n\n\n\n3.3.2 Creating ppp\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\nsummary(fire_month_ppp)\n\nMarked planar point pattern:  741 points\nAverage intensity 2.49258e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n                    (174200 x 170600 units)\nWindow area = 29728200000 square units\n\n\n\n\nCheck for duplicated point events\n\nany(duplicated(fire_month_ppp))\n\n[1] FALSE\n\n\n\n\n3.3.3 Including Owin Object\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nsummary(fire_month_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\n\nplot(fire_month_owin)\n\n\n\n\n\n\n\n\n\n\n\n\n4.0 Computing Spatio-temporal KDE\n\nst_kde &lt;- spattemp.density(fire_month_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]\n\n\n\nPlotting the spatio-temporal KDE object\n\ntims &lt;- c(7,8,9,10,11,12)\npar(mfcol=c(2,3))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at month\",i))\n}\n\n\n\n\n\n\n\n\n\n\n\n5.0 Computing STKDE by Day of Year\n\n5.1 Creating ppp object\n\nfire_yday_ppp &lt;- fire_sf %&gt;% \n  select(DayOfYear) %&gt;%\n  as.ppp()\n\n\n\n5.2 Including Owin object\n\nfire_yday_owin &lt;- fire_yday_ppp[kbb_owin]\nsummary(fire_yday_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   10.0   213.0   258.0   245.9   287.0   352.0 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\n\n\n5.3\n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 6.3198 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [3.959516e-27, 2.751287e-12]\n\n\n\nplot(kde_yday)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "Installing R-Packages\n\npacman::p_load(tidyverse, sf, ggstatsplot, tmap, spatstat, raster)\n\n\n\nInstalling Maptools\neval: false = avoid maptools being download and install repetitively every time the Quarto document been rendered.\n\ninstall.packages(\"maptools\",\n                 repos=\"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\n\nImporting Geospatial Data\n\nmpsz_sf &lt;- st_read(dsn = \"data/MasterPlan2014SubzoneBoundaryWebSHP\",                 \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\In-class_Ex\\In-class_Ex03\\data\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;% \n  st_transform(crs=3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\In-class_Ex\\In-class_Ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\nCreating coastal outline\nst_union() to derive the coastal outline sf tibble data.frame\n\nsg_sf &lt;- mpsz_sf %&gt;% \n  st_union()\n\nplot(sg_sf)\n\n\n\n\n\n\n\n\n\n\nCreating ppp objects from sf data.frame\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\nCreating owin object from sf data.frame\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n80 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            14650  6.97996e+08      8.93e-01\npolygon 2 (hole)         3 -2.21090e+00     -2.83e-09\npolygon 3              285  1.61128e+06      2.06e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.63e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.13e-11\npolygon 6              668  5.40368e+07      6.91e-02\npolygon 7               44  2.26577e+03      2.90e-06\npolygon 8               27  1.50315e+04      1.92e-05\npolygon 9              711  1.28815e+07      1.65e-02\npolygon 10 (hole)       36 -4.01660e+04     -5.14e-05\npolygon 11 (hole)      317 -5.11280e+04     -6.54e-05\npolygon 12 (hole)        3 -3.41405e-01     -4.37e-10\npolygon 13 (hole)        3 -2.89050e-05     -3.70e-14\npolygon 14              77  3.29939e+05      4.22e-04\npolygon 15              30  2.80002e+04      3.58e-05\npolygon 16 (hole)        3 -2.83151e-01     -3.62e-10\npolygon 17              71  8.18750e+03      1.05e-05\npolygon 18 (hole)        3 -1.68316e-04     -2.15e-13\npolygon 19 (hole)       36 -7.79904e+03     -9.97e-06\npolygon 20 (hole)        4 -2.05611e-02     -2.63e-11\npolygon 21 (hole)        3 -2.18000e-06     -2.79e-15\npolygon 22 (hole)        3 -3.65501e-03     -4.67e-12\npolygon 23 (hole)        3 -4.95057e-02     -6.33e-11\npolygon 24 (hole)        3 -3.99521e-02     -5.11e-11\npolygon 25 (hole)        3 -6.62377e-01     -8.47e-10\npolygon 26 (hole)        3 -2.09065e-03     -2.67e-12\npolygon 27              91  1.49663e+04      1.91e-05\npolygon 28 (hole)       26 -1.25665e+03     -1.61e-06\npolygon 29 (hole)      349 -1.21433e+03     -1.55e-06\npolygon 30 (hole)       20 -4.39069e+00     -5.62e-09\npolygon 31 (hole)       48 -1.38338e+02     -1.77e-07\npolygon 32 (hole)       28 -1.99862e+01     -2.56e-08\npolygon 33              40  1.38607e+04      1.77e-05\npolygon 34 (hole)       40 -6.00381e+03     -7.68e-06\npolygon 35 (hole)        7 -1.40545e-01     -1.80e-10\npolygon 36 (hole)       12 -8.36709e+01     -1.07e-07\npolygon 37              45  2.51218e+03      3.21e-06\npolygon 38             142  3.22293e+03      4.12e-06\npolygon 39             148  3.10395e+03      3.97e-06\npolygon 40              75  1.73526e+04      2.22e-05\npolygon 41              83  5.28920e+03      6.76e-06\npolygon 42             211  4.70521e+05      6.02e-04\npolygon 43             106  3.04104e+03      3.89e-06\npolygon 44             266  1.50631e+06      1.93e-03\npolygon 45              71  5.63061e+03      7.20e-06\npolygon 46              10  1.99717e+02      2.55e-07\npolygon 47             478  2.06120e+06      2.64e-03\npolygon 48             155  2.67502e+05      3.42e-04\npolygon 49            1027  1.27782e+06      1.63e-03\npolygon 50 (hole)        3 -1.16959e-03     -1.50e-12\npolygon 51              65  8.42861e+04      1.08e-04\npolygon 52              47  3.82087e+04      4.89e-05\npolygon 53               6  4.50259e+02      5.76e-07\npolygon 54             132  9.53357e+04      1.22e-04\npolygon 55 (hole)        3 -3.23310e-04     -4.13e-13\npolygon 56               4  2.69313e+02      3.44e-07\npolygon 57 (hole)        3 -1.46474e-03     -1.87e-12\npolygon 58            1045  4.44510e+06      5.68e-03\npolygon 59              22  6.74651e+03      8.63e-06\npolygon 60              64  3.43149e+04      4.39e-05\npolygon 61 (hole)        3 -1.98390e-03     -2.54e-12\npolygon 62 (hole)        4 -1.13774e-02     -1.46e-11\npolygon 63              14  5.86546e+03      7.50e-06\npolygon 64              95  5.96187e+04      7.62e-05\npolygon 65 (hole)        4 -1.86410e-02     -2.38e-11\npolygon 66 (hole)        3 -5.12482e-03     -6.55e-12\npolygon 67 (hole)        3 -1.96410e-03     -2.51e-12\npolygon 68 (hole)        3 -5.55856e-03     -7.11e-12\npolygon 69             234  2.08755e+06      2.67e-03\npolygon 70              10  4.90942e+02      6.28e-07\npolygon 71             234  4.72886e+05      6.05e-04\npolygon 72 (hole)       13 -3.91907e+02     -5.01e-07\npolygon 73              15  4.03300e+04      5.16e-05\npolygon 74             227  1.10308e+06      1.41e-03\npolygon 75              10  6.60195e+03      8.44e-06\npolygon 76              19  3.09221e+04      3.95e-05\npolygon 77             145  9.61782e+05      1.23e-03\npolygon 78              30  4.28933e+03      5.49e-06\npolygon 79              37  1.29481e+04      1.66e-05\npolygon 80               4  9.47108e+01      1.21e-07\nenclosing rectangle: [2667.54, 56396.44] x [15748.72, 50256.33] units\n                     (53730 x 34510 units)\nWindow area = 781945000 square units\nFraction of frame area: 0.422\n\n\n\n\nCombining point events object and owin object\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\nKernel Density Estimation of Spatial Point Event\nre-scale the unit of measurement to km before performing KDE\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, \n                                  1000, \n                                  \"km\")\n\nkde_childcareSG_adaptive &lt;- adaptive.density(\n  childcareSG_ppp.km, \n  method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\n\nconvert KDE output into grid object\nmaptools method\n\npar(bg = '#E4D5C9')\n\ngridded_kde_childcareSG_ad &lt;- maptools::as.SpatialGridDataFrame.im(\n  kde_childcareSG_adaptive)\n\nPlease note that 'maptools' will be retired during October 2023,\nplan transition at your earliest convenience (see\nhttps://r-spatial.org/r/2023/05/15/evolution4.html and earlier blogs\nfor guidance);some functionality will be moved to 'sp'.\n Checking rgeos availability: FALSE\n\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\nspatstat.geom method\n\ngridded_kde_childcareSG_ad &lt;- as(\n  kde_childcareSG_adaptive,\n  \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\n\n\n\nExtracting study area using sf objects\n\npg_owin &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\") %&gt;%\n  as.owin()\n\nchildcare_pg = childcare_ppp[pg_owin]\n\nplot(childcare_pg)  \n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, ggstatsplot, tmap)\n\n\nmpsz2014_shp = st_read(dsn = \"data/MasterPlan2014SubzoneBoundaryWebSHP\",                 \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\In-class_Ex\\In-class_Ex02\\data\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nTo know the data type:\n\nclass(mpsz2014_shp)\n\n[1] \"sf\"         \"data.frame\"\n\n\n\nmpsz2014_kml = st_read(\"data/MasterPlan2014SubzoneBoundaryWebKML.kml\")\n\n\nst_write(mpsz2014_shp,\n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n         delete_dsn = TRUE)\n\n\nmpsz2014_kml = st_read(\"data/MP14_SUBZONE_WEB_PL.kml\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\In-class_Ex\\In-class_Ex02\\data\\MP14_SUBZONE_WEB_PL.kml' \n  using driver `KML'\nSimple feature collection with 323 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz2019_shp = st_read(dsn = \"data/MPSZ-2019\",                 \n               layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\In-class_Ex\\In-class_Ex02\\data\\MPSZ-2019' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz2019_kml = st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\In-class_Ex\\In-class_Ex02\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\npopdata &lt;- read.csv(\"data/respopagesextod2023/respopagesextod2023.csv\")\n\n\npopdata2023 &lt;- popdata %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP`=sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG,\n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\n\npopdata2023 &lt;- popdata %&gt;%\n  filter(Time == 2023) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nTo standardize data of mpsz2019_shp and popdata2023, is case sensitive:\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\nmpsz_pop2023 &lt;- left_join(mpsz2019_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "Objective of spatial policy: Ensure equal distribution of development in the province.\nStudy Purpose: Use spatial statistics to check for even distribution of development.\nIf Not Even:\n\nInvestigate signs of spatial clustering (areas where development is grouped).\nIdentify where these clusters are located.\n\nFocus: Analyze the spatial pattern of GDP per capita in Hunan Province, China."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "Objective of spatial policy: Ensure equal distribution of development in the province.\nStudy Purpose: Use spatial statistics to check for even distribution of development.\nIf Not Even:\n\nInvestigate signs of spatial clustering (areas where development is grouped).\nIdentify where these clusters are located.\n\nFocus: Analyze the spatial pattern of GDP per capita in Hunan Province, China."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#setup",
    "title": "Hands-on Exercise 6",
    "section": "2.0 Setup",
    "text": "2.0 Setup\n\n2.1 Installing R-Packages\n\nsf: Importing and handling geospatial data in R\nspdep: Compute spatial weights, global and local spatial autocorrelation statistics\ntmap: Trepare cartographic quality chropleth map\ntidyverse: For wrangling attribute data in R\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)\n\n\n\n\n2.2 Data Acquisition\nTwo data sets will be used:\n\nHunan county boundary layer: a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: contains selected Hunan’s local development indicators in 2012.\n\n\nImporting Geospatial DataImporting Aspatial Data\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n2.3 Performing relational join\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n2.4 Visualising Regional Development Indicator\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation",
    "title": "Hands-on Exercise 6",
    "section": "3.0 Global Measures of Spatial Autocorrelation",
    "text": "3.0 Global Measures of Spatial Autocorrelation\n\nStep 1: Computing Contiguity Spatial WeightsStep 2: Row-standardised weights matrix\n\n\nBefore we can compute the Global Spatial autocorrelation statistics, we need to:\n\nConstruct spatial weights for the study area.\n\nBy Computing contiguity weight matrices based on adjacent regions.\nusing Queen Criteria:\n\nDefault is TRUE: Includes all neighbors that touch at edges or corners.\nYou can set queen = FALSE to consider only edge-touching neighbors (first-order neighbors).\n\n\nSo we can Define neighborhood relationships between geographical units (e.g., counties).\n\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere are 88 area units in Hunan.\nThe most connected area unit has 11 neighbours\nOnly 2 area aunits with 1 link\n\n\n\n\nNow, assign weights to each neighboring polygon.\n\nMethod: Assign each using equal weights (style = “W”)\nWeight Calculation:\n\nAssign weight of fraction 1/(#ofneighbors) to each neighboring county\nSum the weighted values (e.g., income) from neighbors.\n\nDrawback:\n\nEdge polygons have fewer neighbors, which can skew results (over- or under-estimate spatial autocorrelation).\n\nNote: For this example, we’ll use style = “W” for simplicity, but other options, like style = “B,” are more robust.\n\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe function nb2listw() requires an object of class nb (neighborhood list).\nstyle: Defines how weights are calculated. Options include:\n\n“W”: Row standardized weights (sums to 1 across neighbors).\n“B”: Basic binary coding (weights are either 0 or 1).\n“C”: Globally standardized weights (sums to the total number of connections).\n“U”: Equal weights divided by the number of neighbors (sums to 1).\n“minmax”: Min-max normalization (scales weights between 0 and 1).\n“S”: Variance-stabilizing coding (improves stability of weights).\n\nzero.poly:\n\nIf set to TRUE, this includes weights of zero for regions without neighbors.\nThis results in lag values of zero for those regions, which means they won’t affect the analysis.\nIt uses a formula that generates a vector of zeros for regions without neighbors, leading to a spatially lagged value of zero for those regions.\n\nSummary\n\nThe style argument determines how to handle the weights for neighboring regions.\nzero.poly allows for handling of regions that have no neighbors, potentially simplifying analysis but may not always be sensible."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-morans-i",
    "title": "Hands-on Exercise 6",
    "section": "3.0 Global Measures of Spatial Autocorrelation: Moran’s I",
    "text": "3.0 Global Measures of Spatial Autocorrelation: Moran’s I\n\nMaron’s I testComputing Monte Carlo Moran’s IVisualising Monte Carlo Moran’s IPlotting using ggplot2\n\n\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nFindings\n\n\n\nMoran I statistic (0.300749970) -&gt; indicate Positive correlation in GDP per capita\nSD of 4.7351 -&gt; indicate Moran’s I is &gt; expected value under null hypo\nP-value of 1.095e-06 (0.000001095) -&gt; is &lt; 0.05, indicates strong statistical significance\nExpectation of -0.011494253 -&gt; we expect slight negative autocorrelation if there were no spatial structure\nSince p-value &lt; 0.05, we reject null hypo of no spatial autocorrelation. This strongly suggests there is significant positive spatial clustering of GDPPC in Hunan Province. (Regions with High GDPPC is near areas with high GDPPC\n\n\n\n\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nFindings\n\n\n\nMoran I statistic (0.30075) -&gt; indicate Positive correlation in GDP per capita\nP-value of 0.001 -&gt; &lt; 0.05, indicates that the probability of obtaining a Moran’s I value as extreme as the observed &gt;= 1 under the null hypo\nThus, we reject null hypo as p value &lt; 0.05. There is strong evidence that areas with high GDPPC are near areas with high GDPPC\n\n\n\n\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\n\n\n\n# Create a data frame from the simulated results\ndata &lt;- data.frame(Simulated_Morans_I = bperm$res[1:999])\n\n# Plot using ggplot2\nggplot(data, aes(x = Simulated_Morans_I)) +\n  geom_histogram(binwidth = (max(data$Simulated_Morans_I) - min(data$Simulated_Morans_I)) / 20, \n                 fill = \"blue\", \n                 color = \"black\") +\n  geom_vline(xintercept = 0, \n             color = \"red\", \n             linetype = \"dashed\", \n             size = 1) +\n  labs(title = \"Histogram of Simulated Moran's I\",\n       x = \"Simulated Moran's I\",\n       y = \"Frequency\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "title": "Hands-on Exercise 6",
    "section": "3.0 Global Measures of Spatial Autocorrelation: Geary’s C",
    "text": "3.0 Global Measures of Spatial Autocorrelation: Geary’s C\n\nGeary’s C test\n\n\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\n\n\n\nFindings\n\n\n\nGeary C statistic (0.6907223) -&gt; indicate a level of spatial autocorrelation, lower value suggest positive spatial autocorrelation\nSD of 3.6108 -&gt; indicates significant lower than expected value under null hypo\nP-value of 0.0001526 -&gt; is &lt; 0.05, indicates strong statistical significance\nExpectation of 1.0000000 -&gt; on avg, we would expect no spatial autocorrelation\nSince p-value &lt; 0.05, we reject null hypo of no spatial autocorrelation. This strongly suggests there is significant positive spatial clustering of GDPPC in Hunan Province. (Regions with High GDPPC is near areas with high GDPPC than would be expected by chance\n\n\n\nComputing Monte Carlo Geary’s C\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nFindings\n\n\n\nGeary’s C Statistic (0.69072) -&gt; indicate some level of positive spatial autocorrelation\nObserved Rank of 1 -&gt; indicates that the observed value is the smallest among all the simulated values. This suggests that the observed spatial autocorrelation is much stronger than what would be expected under the null hypothesis.\nP-value of 0.001 -&gt; &lt; 0.05, indicates strong statistical significance\nThus, we reject null hypo as p value &lt; 0.05. There is strong evidence that areas with high GDPPC are near areas with high GDPPC\n\n\n\n\nVisualising Monte Carlo Geary’s C\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-monte-carlo-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-monte-carlo-gearys-c",
    "title": "Hands-on Exercise 6",
    "section": "Computing Monte Carlo Geary’s C",
    "text": "Computing Monte Carlo Geary’s C\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nFindings\n\n\n\nGeary’s C Statistic (0.69072) -&gt; indicate some level of positive spatial autocorrelation\nObserved Rank of 1 -&gt; indicates that the observed value is the smallest among all the simulated values. This suggests that the observed spatial autocorrelation is much stronger than what would be expected under the null hypothesis.\nP-value of 0.001 -&gt; &lt; 0.05, indicates strong statistical significance\nThus, we reject null hypo as p value &lt; 0.05. There is strong evidence that areas with high GDPPC are near areas with high GDPPC"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-monte-carlo-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-monte-carlo-gearys-c",
    "title": "Hands-on Exercise 6",
    "section": "Visualising Monte Carlo Geary’s C",
    "text": "Visualising Monte Carlo Geary’s C\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "title": "Hands-on Exercise 6",
    "section": "4.0 Spatial Correlogram",
    "text": "4.0 Spatial Correlogram\n\nSpatial Correlograms: Useful for examining patterns of spatial autocorrelation.\nFunction: Show how correlated pairs of spatial observations are as distance (lag) increases.\nPlot Type: Graphs of autocorrelation indices (like Moran’s I or Geary’s c) against distance.\nComparison with Variograms:\n\nNot as fundamental as variograms, which are key in geostatistics.\nProvide richer information for exploratory and descriptive analysis than variograms.\n\n\n\nCompute Moran’s I correlogramCompute Geary’s C correlogram and plot\n\n\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\n\nPlot Limitations:\n\nPlots may not give a complete interpretation of autocorrelation results.\nNot all autocorrelation values are statistically significant.\n\nImportance of Full Analysis:\n\nNecessary to examine the complete analysis report.\nPrinting the analysis results provides more detailed insights.\n\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nStatistical Observations\n\n\n\n\nPositive Autocorrelation:\n\nThe first three lags (1, 2, and 3) show positive Moran’s I values (0.30075, 0.20601, and 0.06683), indicating clustering of similar GDP per capita values at these distances.\n\nStatistical Significance:\n\nLags 1 and 2: Highly significant (p-values of 2.189e-06 and 2.029e-06), suggesting strong evidence of positive spatial autocorrelation.\nLag 3: Also significant (p-value of 0.0404), indicating some level of clustering, but less strong than the first two lags.\nLag 4: Not significant (p-value of 0.2260), suggesting a lack of clustering at this distance.\nLag 5 and 6: Show negative values (-0.15305 and -0.11871) with significant p-values (5.984e-05 and 0.008886), indicating that at these distances, similar values are less clustered.\n\nGeneral Trend:\n\nThe trend shows strong positive autocorrelation at shorter distances (lags 1-3), but transitions to negative autocorrelation at longer distances (lags 5-6).\n\n\n\nConclusion:\n\nThere is strong evidence of positive spatial clustering of GDP per capita in Hunan Province at shorter distances, but this pattern diminishes and even reverses at greater distances, suggesting that local clusters may dissipate as distance increases.\n\n\n\n\n\n\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#local-measures-of-spatial-autocorrelation-lmsa",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#local-measures-of-spatial-autocorrelation-lmsa",
    "title": "Hands-on Exercise 6",
    "section": "5.0 Local Measures of Spatial Autocorrelation (LMSA)",
    "text": "5.0 Local Measures of Spatial Autocorrelation (LMSA)\n\nFocus: Examines relationships between each observation and its surrounding observations.\n\n\n\nNature:\n\nNot summary statistics; they provide individual scores for each location.\nHelps understand the spatial structure of data.\n\nSimilarity to Global Measures:\n\nIntuition is similar to global statistics.\nSome global measures can be broken down into local measures.\n\nKey Examples:\n\nLocal Indicators of Spatial Association (LISA): Provides insights into local clustering and relationships.\nGetis-Ord’s Gi-statistics: Another LMSA method that offers complementary insights for geographic data.\n\n\n\n5.1 Local Indicators of Spatial Association(LISA)\n\nPurpose: Evaluate the presence of clusters and outliers in spatial data.\nExample: Analyzing GDP per capita in Hunan Province, China.\n\nClusters: Areas with significantly higher or lower GDP per capita than expected by chance.\nInterpretation: Identifies counties with values above or below a random distribution.\n\n\n\nStep 1: Computing Contiguity Spatial WeightsStep 2: Row-standardised weights matrix\n\n\nSame as how we compute for Global Indicators of Spatial Autocorrelation\n\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\nSame as how we compute for Global Indicators of Spatial Autocorrelation\n\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\nComputing local Moran’s IMapping the local Moran’s IMapping local Moran’s I valuesMapping local Moran’s I p-valuesMapping both local Moran’s I values and p-values\n\n\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\n\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n\nBefore mapping, Append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nthere is evidence for both positive and negative Ii values. Next we should consider p-values for each of these values\n\n\n\n\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.2 Creating a LISA Cluster Map\nPurpose: to categorize areas based on their spatial relationships.\n\nStep 1: Plotting Moran scatterplotStep 2: Plotting Moran scatterplot with standardised variable\n\n\neg.can show us whether counties with high GDP per capita are clustered together or if low GDP counties are near each other, indicating spatial patterns in economic development.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC.\nThis are high-high locations\n\n\n\n\n\nPurpose: Standardizes the GDP per capita variable for better comparison in the Moran scatterplot.\nSteps:\n\nCentering: Subtract the mean of the GDP per capita values (ignoring NAs) to center the data around zero.\nScaling: Divide the centered values by their standard deviation to standardize the data.\n\n\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\nas.vector(): Ensures the output is a vector, which fits neatly into the data frame for further analysis.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\n\n\nStep 3: Preparing LISA map classesPlotting Local Moran’s I and P-Values\n\n\nInitialize Quadrant Vector:\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nCalculate Spatially Lagged GDPPC & Center around its mean:\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nCenters the local Moran’s I values around their mean:\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nSet Significance Level:\n\nsignif &lt;- 0.05\n\nDefine Cluster Categories:\n\nAssigns values to the quadrant vector based on the relationships:\n\nLow-Low (1): Low lag and high local Moran’s I\nLow-High (2): High lag and low local Moran’s I\nHigh-Low (3): Low lag and low local Moran’s I\nHigh-High (4): High lag and high local Moran’s I\n\n\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4\n\nMarks locations with non-significant Moran’s I results as category 0:\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\nStep 4: Plotting LISA map\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\n\n\nPros:\n\nAllows for a clearer understanding of significant clusters and outliers.\nHelps identify not only where clusters exist but also their statistical significance.\n\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\ntmap_arrange(localMI.map, pvalue.map, asp=2, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-on Exercise 6",
    "section": "6.0 Hot Spot and Cold Spot Area Analysis",
    "text": "6.0 Hot Spot and Cold Spot Area Analysis\n\nPurpose: Identify hot spot (high-value) and cold spot (low-value) areas using localized spatial statistics.\nDefinition of Hot Spot: A region that has higher values relative to its surroundings.\n\n\n6.1 Getis and Ord’s G-Statistics\n\nA statistical method to detect spatial anomalies by analyzing neighbors within a certain distance.\nKey Steps:\n\nDerive Spatial Weight Matrix: Define neighbors based on distance, not just shared borders.\nCompute G_i Statistics: Calculate statistics to identify spatial clusters.\nMap G_i Statistics: Visualize the results to highlight hot and cold spots.\n\n\n\n\n6.2 Deriving Distance-Based Weight Matrix\nTypes of Matrices:\n\nFixed Distance Weight Matrix: Neighbors defined by a set distance.\nAdaptive Distance Weight Matrix: Neighbors defined by varying distances based on data density.\n\nDeriving the Centroid\n\nBecause Points are required to associate with each polygon for connectivity analysis.\n\n\n\nMap the centroid function to extract coordinates:\n\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\n\nDetermine the Cut-Off Distance\n\nto establish an upper limit for the distance band in spatial analysis.\n1) Find K Nearest Neighbors:\n\nUse knearneigh() from the spdep package to get indices of points that are the k nearest neighbors of each other.\n\n2) Convert to Neighbors List:\n\nTransform the output from knearneigh() into a neighbors list format using knn2nb(), which creates a list of neighbor region IDs.\n\n3) Calculate Distances:\n\nUse nbdists() to compute the lengths of the neighbor relationships, which gives distances in the coordinate units (kilometers if not projected).\n\n4) Flatten the List:\n\nRemove the list structure of the distances using unlist().\n\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\n\n\n\n\nNote\n\n\n\nMax is 61.79, can use this as the upper threshold.\nUsing this gives certainty that all units will have at least one neighbour\n\n\n\nComputing fixed distance weight matrixComputing adaptive distance weight matrix\n\n\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nconvert the nb object into spatial weights object:\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nPurpose: Address the variability in neighbor counts based on population density.\nCharacteristics:\n\nFixed Distance Weight Matrix:\n\nUrban areas often have more neighbors due to higher density.\nRural areas have fewer neighbors, leading to less smooth neighbor relationships.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSolution:\n\nUse k-nearest neighbors (k-NN) to control the number of neighbors directly.\nThis allows for more balanced neighbor relationships, either by accepting asymmetric neighbors or enforcing symmetry.\n\n\n\n\n\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "title": "Hands-on Exercise 6",
    "section": "7.0 Computing Gi statistics",
    "text": "7.0 Computing Gi statistics\n\nGi statistics using fixed distanceMapping Gi values with fixed distance weightsGi statistics using adaptive distanceMapping Gi values with adaptive distance weights\n\n\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nInterpretation of Gi Statistics:\n\nRepresented as a Z-score.\nHigher values indicate stronger clustering intensity.\nThe sign (positive or negative) shows whether it is a high or low cluster.\n\n\n\nJoining Gi Values to Hunan Data\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\n\n\n\n\n\nNote\n\n\n\nTasks Performed:\n\nConvert Output: Changes the G* values from a vector to a matrix using as.matrix().\nJoin Data: Uses cbind() to combine the original hunan data with the G* values, creating a new SpatialPolygonDataFrame called hunan.gi.\nRename Field: Renames the G* values column to gstat_fixed for clarity.\n\n\n\n\n\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "NetSPAA is used to analyze events that happen along networks, like roads or rivers.\neg.study where traffic accidents mostly happen on a road, or where childcare centers are located along streets\nIn this exercise, we’ll use a tool called spNetwork:\n\nNetwork Kernel Density Estimation (NKDE): This helps you see where events (like accidents) are happening the most along a network (like a road), showing areas where events are more common.\nNetwork G-function and K-function: These are methods to check if events are clustering together (happening close to each other) or if they’re spread out along the network."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "NetSPAA is used to analyze events that happen along networks, like roads or rivers.\neg.study where traffic accidents mostly happen on a road, or where childcare centers are located along streets\nIn this exercise, we’ll use a tool called spNetwork:\n\nNetwork Kernel Density Estimation (NKDE): This helps you see where events (like accidents) are happening the most along a network (like a road), showing areas where events are more common.\nNetwork G-function and K-function: These are methods to check if events are clustering together (happening close to each other) or if they’re spread out along the network."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#setup",
    "title": "Hands-on Exercise 4",
    "section": "2.0 Setup",
    "text": "2.0 Setup\n\n2.1 Installing R-Packages\n\nsf for handling geospatial data. It can manage, process, and manipulate Simple Features, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons.\nspNetwork, can perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\ntmap to plot cartographic quality static point patterns maps or interactive maps\n\n\npacman::p_load(sf, spNetwork, tmap, tidyverse)\n\n\n\n2.2 Data Acquisition\n2 datasets will be used to analyse the spatial distribution of childcare centre in Punggol planning area (Both data sets are in ESRI shapefile format):\n\nPunggol_St, a line features geospatial data which store the road network within Punggol Planning Area.\nPunggol_CC, a point feature geospatial data which store the location of childcare centres within Punggol Planning Area.\n\n\n\n2.3 Importing Geospatial Data into R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Display info about a topic/theme on a geographic location leveraging our spatial cognition & vision systems\nUsage exmaples\n\nVisualize population, temperature, crime rates, property prices using symbols\n\nObjective\n\nPlot functional & truthful choropleth maps using tmap packages\n\nOutcome"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview--thematic-map",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview--thematic-map",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Display info about a topic/theme on a geographic location leveraging our spatial cognition & vision systems\nUsage exmaples\n\nVisualize population, temperature, crime rates, property prices using symbols\n\nObjective\n\nPlot functional & truthful choropleth maps using tmap packages\n\nOutcome"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#setup",
    "title": "Hands-on Exercise 2",
    "section": "2.0 Setup",
    "text": "2.0 Setup\n\n2.1 Installing R-Packages\n\ntmap package\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data\n\n* Among the four packages, readr, tidyr and dplyr are part of tidyverse package. [Only need to install tidyverse]\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n2.2 Data Acquisition\n2 datasets will be used:\n\nURA Master Plan 2014 Subzone Boundary (Web) -(i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format\n\ngeographical boundary of Singapore at the planning subzone level\n\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 -(i.e. respopagesextod2011to2020.csv) in csv format\n\naspatial data file\nDoes not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\n2.3 Importing Geospatial Data into R\n\nImport MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz\n\n\nmpsz = st_read(dsn = \"data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP\",                 \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nExamine content of mpsz\n\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n* Why show 10 only? -&gt; Ans: By default, only show a subset of data.\n\nUse print(mpsz, n=20) -&gt; show 20 data\n\n\n\n2.4 Importing Aspatial Data into R\n\nImport Population data\n\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n2.5 Data Preparation and Wrangling\nTo create a thematic map, first, gather a data table for the year 2020. This table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n2.5.1 Data Wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package\n -&gt; \nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\nfilter\nonly take Time == 2020\n\n\nmutate\ncalculation\n\n\nmutate(YOUNG = rowSums(.[3:6]) + rowSums(.[12]))\n\nmutate(YOUNG = …): add new column ‘YOUNG’ to dataset\nrowSums(.[3:6]): calculate sum of values across column 3 to 6 each row\nrowSums(.[12]): return only column 12 value\n\n\n\n\n\npopdata2020\n\n# A tibble: 332 × 7\n   PA         SZ                   YOUNG `ECONOMY ACTIVE`  AGED TOTAL DEPENDENCY\n   &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Cen…  1440             2610   760  4810      0.843\n 2 Ang Mo Kio Cheng San             6640            15460  6050 28150      0.821\n 3 Ang Mo Kio Chong Boon            6150            13950  6470 26570      0.905\n 4 Ang Mo Kio Kebun Bahru           5540            12090  5120 22750      0.882\n 5 Ang Mo Kio Sembawang Hills       2100             3410  1310  6820      1    \n 6 Ang Mo Kio Shangri-La            3960             8420  3610 15990      0.899\n 7 Ang Mo Kio Tagore                2220             4200  1530  7950      0.893\n 8 Ang Mo Kio Townsville            4690            11450  5100 21240      0.855\n 9 Ang Mo Kio Yio Chu Kang             0                0     0     0    NaN    \n10 Ang Mo Kio Yio Chu Kang East     1220             2300   750  4270      0.857\n# ℹ 322 more rows\n\n\n\n\n2.5.2 Joining Geospatial Data and Attribute Data\nBefore performing georelational join,\n\nconvert values in PA & SZ fields to UPPERCASE -right now is both upper & lower case\n\n(SUBZONE_N and PLN_AREA_N are already in UPPERCASE)\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\nuse ‘left_join()’ from dplyr to merge geo data with the attribute table, matching them by the planning subzone names (like SUBZONE_N and SZ).\n\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n(By using mpsz as the starting point (the left table), we make sure that the result keeps all the special geographic information (like shapes and locations) from mpsz.)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 2",
    "section": "3.0 Choropleth Mapping Geospatial Data Using tmap",
    "text": "3.0 Choropleth Mapping Geospatial Data Using tmap\nChoropleth mapping is a way to show information on a map using colors or patterns for different areas like countries or states. For example, a researcher might use this type of map to show where older people live in Singapore based on specific zones.\nTo create these maps with the tmap package, you can:\n\nUse qtm() &gt; Plot a thematic map.\nUse tmap elements -&gt; Plot a more detailed and customized map.\n\n\n3.1 Plot with qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\",\n    fill.palette =\"plasma\")\n\n\n\n\n\n\n\n\ntmap_mode(“plot”) -&gt; produce static map\ntmap_mode(“view”) -&gt; interactive mode\nfill = “DEPENDENCY” -&gt; use this attribute to determine color fill for each polygon(area) on the map\n\n\n3.2 Usage of tmap’s element\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n3.3 Drawing a base map\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\nStart with tm_shape() -&gt; data to use for map\ntm_fill() and tm_polygons() -&gt; add details\n\n\n3.4 Drawing a choropleth map using tm_polygons()\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nDefault: Missing Value(grey), Color scheme of ColorBrewer(YlOrRd), Interval binning(pretty)\n\n\n3.5 Drawing a choropleth map using tm_fill() and tm_border()\nm_polygons() is a wraper of tm_fill() and tm_border(). \ntm_fill() -&gt; shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n* planning subzones are shared according to the respective dependecy values\ntm_borders()-&gt; add boundary of the planning subzones\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nalpha -&gt; transparency no. between 0 (totally transparent) and 1 (not transparent) [Default = 1]\n\ncol = border colour,\nlwd = border line width. default is 1\nlty = border line type. default is “solid”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "title": "Hands-on Exercise 2",
    "section": "4.0 Data classification methods of tmap",
    "text": "4.0 Data classification methods of tmap\n10 methods: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\n* Need to put style arg in tm_fill() or tm_polygons()\n\n4.1.0 style = “quantile”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n‘quantile’ are more evenly distributed than “equal”\n\n\n4.1.1 style = “equal”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.1.2 style = “sd”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.1.3 style = “pretty”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.1.4 style = “kmeans”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.1.5 style = “hclust”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.1.6 style = “bclust”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\n\n\n4.1.7 style = “fisher”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.1.8 style = “jenks”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-choropleth-maps-with-custom-breaks",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-choropleth-maps-with-custom-breaks",
    "title": "Hands-on Exercise 2",
    "section": "5.0 Plotting Choropleth Maps with Custom Breaks",
    "text": "5.0 Plotting Choropleth Maps with Custom Breaks\nFor built-in styles, the map automatically determines the category breaks.\nManual -&gt; use breaks argument in tm_fill(), in tmap (need specify n+1 values for n categories in ascending order, because each break range includes a min & max)\nCurrently,\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a min and max, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#colour-scheme",
    "title": "Hands-on Exercise 2",
    "section": "6.0 Colour Scheme",
    "text": "6.0 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n6.1 Using ColourBrewer palette\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-layouts",
    "title": "Hands-on Exercise 2",
    "section": "7.0 Map Layouts",
    "text": "7.0 Map Layouts\neg. Title, scale bar, compass, margins, aspects ratios\n\n7.1 Map Legend\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n7.2 Map Style (tmap_style)\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n7.3 Cartographic Furniture\nAdding compass, scale bar, grid\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n7.4 Drawing Small Multiple Choropleth Maps\nSmall multiple maps (a.k.a facet map)\nEnable the visualisation of how spatial relationships change with respect to another variable, such as time\nPlotted in 3 ways:\n\nassigning multiple values to &gt;= 1 asthetic arguments\ndefining a group-by variable in tm_facets()\ncreating multiple stand-alone maps with tmap_arrange()\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nDifferent color:\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\nGroup By using tm_facets():\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\nStand-alone maps using tmap_arrange():\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n7.4 Mapping Spatial Object Meeting a Selection Criterion\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Geospatial Data Science is a process of importing, wrangling, integrating, and processing geographically referenced data sets. In this hands-on exercise, you will learn how to perform geospatial data science tasks in R by using sf package.\nBy the end of this hands-on exercise, you should acquire the following competencies:\n\ninstalling and loading sf and tidyverse packages into R environment,\nimporting geospatial data by using appropriate functions of sf package,\nimporting aspatial data by using appropriate function of readr package,\nexploring the content of simple feature data frame by using appropriate Base R and sf functions,\nassigning or transforming coordinate systems by using using appropriate sf functions,\nconverting an aspatial data into a sf data frame by using appropriate function of sf package,\nperforming geoprocessing tasks by using appropriate functions of sf package,\nperforming data wrangling tasks by using appropriate functions of dplyr package and\nperforming Exploratory Data Analysis (EDA) by using appropriate functions from ggplot2 package.\n\n\n\n\n\nData are key to data analytics including geospatial analytics. Hence, before analysing, I extract the necessary data sets from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\n\n\n\nIn this exercise, I will be using two R packages will be used. They are:\n\nsf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTidyverse consists of a family of R packages. In this hands-on exercise, the following packages will be used:\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\nI install the required packages using the code chunk below.\n\npacman::p_load(sf, tidyverse)\n\n\n\n\n\nIn this section, I will import the following geospatial data into R by using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n\nDataset used: MP14_SUBZONE_WEB_PL File format: shapefile Data frame type: polygon feature\n\nmpsz = st_read(dsn = \"data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP\",                 \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nFrom the output message, we can see that in our mpsz simple feature data frame, there are 323 multipolygon features, 15 fields and is in the svy21 projected coordinates system.\n\n\n\nDataset used: CyclingPathGazette File format: shapefile Data frame type: line feature\n\ncyclingpath = st_read(dsn = \"data/geospatial/CyclingPath_Jul2024\",                        \n                      layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\CyclingPath_Jul2024' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nFrom the output message, we can see that in our cyclingpath linestring feature data frame, there are 1625 linestring features, 2 fields and is in the svy21 projected coordinates system.\n\n\n\nDataset used: pre-schools-location-kml File format: kml Data frame type: point feature\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nFrom the output message, we can see that in our preschool point feature data frame, there are 1359 linestring features, 2 fields and is in the wgs84 projected coordinates system.\n\n\n\n\nFor aspatial data, such as the listings Airbnb datset, there’s an extra step in the importing process. We’ll import it into a tibble data frame, then convert it into a simple feature data frame.\n\n\nSince our listings data set is in a csv file format, we’ll use the read_csv() function from the readr package, like so:\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(listings) \n\nRows: 3,540\nColumns: 18\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ latitude                       &lt;dbl&gt; 1.34537, 1.34754, 1.34531, 1.29015, 1.2…\n$ longitude                      &lt;dbl&gt; 103.9589, 103.9596, 103.9610, 103.8081,…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n\n\nFrom the output message, we can see that in our listing tibble data frame, there are 4252 rows and 16 columns (not features and fields like in our simple data feature frame!) Take note of the latitude and longitude fields - we’ll be using them in the next phase.\n\nAssumption: The data is in the wgs84 Geographic Coordinate System on account of its latitude/longtitude fields.\n\n\n\n\nNow, let’s convert our listing tibble data frame into a by using the st_as_sf() function from the sf package.\n\nlistings_sf &lt;- st_as_sf(listings,                         \n                        coords = c(\"longitude\", \"latitude\"),\n                        crs=4326) %&gt;%   \n  st_transform(crs = 3414)\n\nThis gives us the new simple feature data frame, listings_sf:\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\n\nNote that a new column called geometry has been added! In addition, longtitude and latitude have both been dropped.\n\n\n\n\n\nIn this sub-section, you will learn different ways to retrieve information related to the content of a simple feature data frame.\n\n\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nNotice that the print only displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\n\n\nBeside the basic feature information, we also would like to learn more about the associated attribute information in the data frame. This is the time you will find glimpse() of dplyr. very handy as shown in the code chunk below.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nglimpse() report reveals the data type of each fields. For example FMEL-UPD_D field is in date data type and X_ADDR, Y_ADDR, SHAPE_L and SHAPE_AREA fields are all in double-precision values.\n\n\n\nSometimes we would like to reveal complete information of a feature object, this is the job of head() of Base R\n\nhead(mpsz, n=5) \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\nNote: One of the useful argument of head() is it allows user to select the numbers of record to display (i.e. the n argument).\n\n\n\n\n\nIn geospatial data science, by looking at the feature information is not enough. We are also interested to visualise the geospatial features. I use plot() to quickly plot a sf object as shown in the code chunk below.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. We can, however, choose to plot only the geometry by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\n\n\n\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nIn this section, I project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nTo check the coordinate system of mpsz simple feature data frame, I use st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in SVY21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for SVY21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nNow, let us check the CSR again by using the code chunk below.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nI take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\nGeometry set for 2290 features  \nGeometry type: POINT \nDimension:     XYZ \nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134 \nz_range:       zmin: 0 zmax: 0 \nGeodetic CRS:  WGS 84 \nFirst 5 geometries:\nPOINT Z (103.8072 1.299333 0)\nPOINT Z (103.826 1.312839 0)\nPOINT Z (103.8409 1.348843 0)\nPOINT Z (103.8048 1.435024 0)\nPOINT Z (103.839 1.33315 0)\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool3414 &lt;- st_transform(preschool,                                \n                              crs = 3414)\n\n\nNote: In practice, we need find out the appropriate project coordinate system to use before performing the projection transformation.\n\nNext, let us display the content of preschool3414 sf data frame as shown below.\nGeometry set for 2290 features  \nGeometry type: POINT \nDimension:     XYZ \nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88 \nz_range:       zmin: 0 zmax: 0 \nProjected CRS: SVY21 / Singapore TM \nFirst 5 geometries:\nPOINT Z (25089.46 31299.16 0)\nPOINT Z (27189.07 32792.54 0)\nPOINT Z (28844.56 36773.76 0)\nPOINT Z (24821.92 46303.16 0)\nPOINT Z (28637.82 35038.49 0)\nNotice that it is in svy21 projected coordinate system now. Furthermore, if you refer to Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems.\n\n\n\n\nBesides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, I perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\n\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath,                                 \n                            dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\n\n\n\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nNext, I calculate the density of pre-school by planning subzone.\nFirstly, the code chunk below uses st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%   st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%   mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\n\n\n\nIn practice, many geospatial analytics start with Exploratory Data Analysis. In this section, you will learn how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data=mpsz3414,         \n       aes(x= as.numeric(`PreSch Density`)))+   \n  geom_histogram(bins=20,                   \n                 color=\"black\",                   \n                 fill=\"light blue\") +   \n  labs(title = \"Are pre-school even distributed in Singapore?\",        \n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",       \n       x = \"Pre-school density (per km sq)\",       \n       y = \"Frequency\")\n\n\n\n\n\n\n\n\nUsing ggplot2 method, I plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz3414,         \n       aes(y = `PreSch Count`,             \n          x= as.numeric(`PreSch Density`)))+   \n  geom_point(color=\"black\",               \n             fill=\"light blue\") +   \n  xlim(0, 40) +   \n  ylim(0, 40) +   \n  labs(title = \"\",       \n       x = \"Pre-school density (per km sq)\",       \n       y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#setup",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Data are key to data analytics including geospatial analytics. Hence, before analysing, I extract the necessary data sets from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\n\n\n\nIn this exercise, I will be using two R packages will be used. They are:\n\nsf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTidyverse consists of a family of R packages. In this hands-on exercise, the following packages will be used:\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\nI install the required packages using the code chunk below.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data-into-r",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "In this section, I will import the following geospatial data into R by using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n\nDataset used: MP14_SUBZONE_WEB_PL File format: shapefile Data frame type: polygon feature\n\nmpsz = st_read(dsn = \"data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP\",                 \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nFrom the output message, we can see that in our mpsz simple feature data frame, there are 323 multipolygon features, 15 fields and is in the svy21 projected coordinates system.\n\n\n\nDataset used: CyclingPathGazette File format: shapefile Data frame type: line feature\n\ncyclingpath = st_read(dsn = \"data/geospatial/CyclingPath_Jul2024\",                        \n                      layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\CyclingPath_Jul2024' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nFrom the output message, we can see that in our cyclingpath linestring feature data frame, there are 1625 linestring features, 2 fields and is in the svy21 projected coordinates system.\n\n\n\nDataset used: pre-schools-location-kml File format: kml Data frame type: point feature\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nFrom the output message, we can see that in our preschool point feature data frame, there are 1359 linestring features, 2 fields and is in the wgs84 projected coordinates system."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-converting-aspatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-converting-aspatial-data-into-r",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "For aspatial data, such as the listings Airbnb datset, there’s an extra step in the importing process. We’ll import it into a tibble data frame, then convert it into a simple feature data frame.\n\n\nSince our listings data set is in a csv file format, we’ll use the read_csv() function from the readr package, like so:\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(listings) \n\nRows: 3,540\nColumns: 18\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ latitude                       &lt;dbl&gt; 1.34537, 1.34754, 1.34531, 1.29015, 1.2…\n$ longitude                      &lt;dbl&gt; 103.9589, 103.9596, 103.9610, 103.8081,…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n\n\nFrom the output message, we can see that in our listing tibble data frame, there are 4252 rows and 16 columns (not features and fields like in our simple data feature frame!) Take note of the latitude and longitude fields - we’ll be using them in the next phase.\n\nAssumption: The data is in the wgs84 Geographic Coordinate System on account of its latitude/longtitude fields.\n\n\n\n\nNow, let’s convert our listing tibble data frame into a by using the st_as_sf() function from the sf package.\n\nlistings_sf &lt;- st_as_sf(listings,                         \n                        coords = c(\"longitude\", \"latitude\"),\n                        crs=4326) %&gt;%   \n  st_transform(crs = 3414)\n\nThis gives us the new simple feature data frame, listings_sf:\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\n\nNote that a new column called geometry has been added! In addition, longtitude and latitude have both been dropped."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "In this sub-section, you will learn different ways to retrieve information related to the content of a simple feature data frame.\n\n\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nNotice that the print only displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\n\n\nBeside the basic feature information, we also would like to learn more about the associated attribute information in the data frame. This is the time you will find glimpse() of dplyr. very handy as shown in the code chunk below.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nglimpse() report reveals the data type of each fields. For example FMEL-UPD_D field is in date data type and X_ADDR, Y_ADDR, SHAPE_L and SHAPE_AREA fields are all in double-precision values.\n\n\n\nSometimes we would like to reveal complete information of a feature object, this is the job of head() of Base R\n\nhead(mpsz, n=5) \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\nNote: One of the useful argument of head() is it allows user to select the numbers of record to display (i.e. the n argument)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "In geospatial data science, by looking at the feature information is not enough. We are also interested to visualise the geospatial features. I use plot() to quickly plot a sf object as shown in the code chunk below.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. We can, however, choose to plot only the geometry by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-projection",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Map projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nIn this section, I project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nTo check the coordinate system of mpsz simple feature data frame, I use st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in SVY21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for SVY21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nNow, let us check the CSR again by using the code chunk below.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nI take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\nGeometry set for 2290 features  \nGeometry type: POINT \nDimension:     XYZ \nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134 \nz_range:       zmin: 0 zmax: 0 \nGeodetic CRS:  WGS 84 \nFirst 5 geometries:\nPOINT Z (103.8072 1.299333 0)\nPOINT Z (103.826 1.312839 0)\nPOINT Z (103.8409 1.348843 0)\nPOINT Z (103.8048 1.435024 0)\nPOINT Z (103.839 1.33315 0)\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool3414 &lt;- st_transform(preschool,                                \n                              crs = 3414)\n\n\nNote: In practice, we need find out the appropriate project coordinate system to use before performing the projection transformation.\n\nNext, let us display the content of preschool3414 sf data frame as shown below.\nGeometry set for 2290 features  \nGeometry type: POINT \nDimension:     XYZ \nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88 \nz_range:       zmin: 0 zmax: 0 \nProjected CRS: SVY21 / Singapore TM \nFirst 5 geometries:\nPOINT Z (25089.46 31299.16 0)\nPOINT Z (27189.07 32792.54 0)\nPOINT Z (28844.56 36773.76 0)\nPOINT Z (24821.92 46303.16 0)\nPOINT Z (28637.82 35038.49 0)\nNotice that it is in svy21 projected coordinate system now. Furthermore, if you refer to Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Besides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, I perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\n\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath,                                 \n                            dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\n\n\n\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nNext, I calculate the density of pre-school by planning subzone.\nFirstly, the code chunk below uses st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%   st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%   mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "In practice, many geospatial analytics start with Exploratory Data Analysis. In this section, you will learn how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data=mpsz3414,         \n       aes(x= as.numeric(`PreSch Density`)))+   \n  geom_histogram(bins=20,                   \n                 color=\"black\",                   \n                 fill=\"light blue\") +   \n  labs(title = \"Are pre-school even distributed in Singapore?\",        \n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",       \n       x = \"Pre-school density (per km sq)\",       \n       y = \"Frequency\")\n\n\n\n\n\n\n\n\nUsing ggplot2 method, I plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz3414,         \n       aes(y = `PreSch Count`,             \n          x= as.numeric(`PreSch Density`)))+   \n  geom_point(color=\"black\",               \n             fill=\"light blue\") +   \n  xlim(0, 40) +   \n  ylim(0, 40) +   \n  labs(title = \"\",       \n       x = \"Pre-school density (per km sq)\",       \n       y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Spatial Point Pattern Analysis is a method used to study how points are spread out over an area. These points can represent:\n\nEvents like crimes, traffic accidents, or disease outbreaks.\nLocations of businesses such as coffee shops, fast food places, or facilities like childcare centers and eldercare services.\n\nIn this exercise, we’ll use a tool called spatstat to analyze the distribution of childcare centers in Singapore.\nQuestions we want to answer are:\n\nAre childcare centers in Singapore spread out randomly, or is there a pattern?\nIf they’re not randomly distributed, where are the areas with the highest concentration of childcare centers?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#st-order-spatial-point-patterns-analysis-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#st-order-spatial-point-patterns-analysis-methods",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Spatial Point Pattern Analysis is a method used to study how points are spread out over an area. These points can represent:\n\nEvents like crimes, traffic accidents, or disease outbreaks.\nLocations of businesses such as coffee shops, fast food places, or facilities like childcare centers and eldercare services.\n\nIn this exercise, we’ll use a tool called spatstat to analyze the distribution of childcare centers in Singapore.\nQuestions we want to answer are:\n\nAre childcare centers in Singapore spread out randomly, or is there a pattern?\nIf they’re not randomly distributed, where are the areas with the highest concentration of childcare centers?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#setup",
    "title": "Hands-on Exercise 3",
    "section": "2.0 Setup",
    "text": "2.0 Setup\n\n2.1 Installing R-Packages\n\nsf for handling geospatial data\nspatstat for point pattern analysis. In this exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer. To study how points are distributed & to create a density map showing where points are concentrated\nraster deals with grid-based spatial data, like satellite img. In this exercise, we’ll use it to convert images created by spatstat into a format that raster can work with.\nmaptools for manupulating geographic data. In this exercise, we mainly use it to convert Spatial objects -&gt; ppp format of spatstat.\ntmap package\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, devtools,sp)\n\n\n\n2.2 Data Acquisition\n3 datasets will be used:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\n\n\n2.3 Importing Geospatial Data into R\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;% \n  st_transform(crs=3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Hands-on_Ex\\Hands-on_Ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn=\"data\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n2.4 Assigning Standard Coordinate Systems\n\nsg_sf &lt;- st_transform(sg_sf, crs=3414)\nmpsz_sf &lt;- st_transform(mpsz_sf, crs=3414)\n\n\n\n2.5 Data Preparation and Wrangling\n\n2.5.1 Convert simple feature data frame to sp’s Spatial* class\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\n2.5.2 Convert Spatial* class into generic sp format\n* spatstat requires the analytical data in ppp object form. (Need convert to Spatial Object first -&gt; ppp object)\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n* Diff between Spatial* classes & generic sp object:\nSpatial* classes are specialized versions of spatial objects tailored for different types of spatial data, while the generic sp object provides a base class with fundamental spatial features that can be extended by the more specific Spatial* classes.\n\n\n2.5.3 Convert generic sp format into spatstat’s ppp format\n\nchildcare_ppp &lt;- as.ppp(st_coordinates(childcare_sf), st_bbox(childcare_sf))\n\nWarning: data contain duplicated points\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nView Summary Statistics:\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n* There is warning about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#handling-duplicated-points",
    "title": "Hands-on Exercise 3",
    "section": "3.0 Handling duplicated points",
    "text": "3.0 Handling duplicated points\n\n3.1 Check duplication in a ppp object\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\n\n\n3.2 Count no. of co-indicence point\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\n\n\n3.3 Check how many locations &gt;= 1 point event\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\n\n\nView locations of these duplicated point events:\n\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\n\n3.3 3 ways to overcome duplicate points\n\nDelete the duplicate -&gt; but, this will result in some useful point events be lost\njittering -&gt; this will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nmake each point ‘unique’ + attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\n\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "title": "Hands-on Exercise 3",
    "section": "4.0 Creating owin object",
    "text": "4.0 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nConvert sg SpatialPolygon object -&gt; owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nDisplay:\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n4.1 Combining point events object + owin object\nExtract childcare events that are located within Singapore\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nchildcareSG_ppp &lt;- as.ppp(childcareSG_ppp)\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "title": "Hands-on Exercise 3",
    "section": "5.0 First-order Spatial Point Patterns Analysis",
    "text": "5.0 First-order Spatial Point Patterns Analysis\n\n5.1 Kernel Density Estimation (KDE)\n\n5.1.1 Computing kernel density estimation using automatic bandwidth selection method\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n* Density values is 0 to 0.000035 (too small to understand) -&gt; because default unit of measurement of svy21 is in meter [so it is computed in no. of points/sq meter]\nTo retrieve bandwidth used to compute the kde layer:\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n5.1.2 Convert unit of measurement from meter -&gt; km\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\n\n\n5.1.3 Different automatic badwidth methods\n\nbw.CvL()\nbw.scott()\nbw.ppl()\n\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\n bw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\n bw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\n bw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in ther experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n5.1.4 Different kernel methods\nDefault in density.ppp() is gaussian. [Choose from Epanechnikov, Quartic and Dics]\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\n\n\n\n\n\n\n\n\n\n\n5.1.4 Fixed and Adaptive KDE\n\n5.1.4.1 Computing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\n5.1.4.2 Computing KDE by using adaptive bandwidth\nvery sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nFixed VS Adaptive Kernel density estimation:\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n5.1.4.3 Converting KDE output into grid object\nThe result is the same, we just convert it so that it is suitable for mapping purposes\n\ngridded_kde_childcareSG_bw &lt;- as(kde_childcareSG.bw, \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\n\n5.1.4.4 Converting gridded density objects into raster\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n* crs is NA\n\n\n5.1.4.5 Assigning projection systems\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\n5.1.4.6 Visualising the output in tmap\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\n* Notice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field.\n\n\n5.1.4.7 Comparing Spatial Point Patterns using KDE\ncompare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas.\nExtract target planning areas:\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlot:\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n5.1.4.8 Creating owin object\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nCombining childcare points and the study area\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\nComputing KDE\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\n\nWarning: Berman-Diggle Cross-Validation criterion was minimised at right-hand\nend of interval [0, 0.198]; use argument 'hmax' to specify a wider interval for\nbandwidth 'sigma'\n\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\n\n\n\n\nComputing fixed bandwidth KDE\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\n\n\n\n\n\n\n\n\n\n\n\n5.2 Performing Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\n5.2.1 Testing spatial point patterns using Clark and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n5.2.2 Clark and Evans Test: Choa Chu Kang planning area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.92168, p-value = 0.2419\nalternative hypothesis: two-sided\n\n\n\n\n5.2.3 Clark and Evans Test: Tampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.77871, p-value = 6.503e-05\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#drawing-a-spatial-point-map",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#drawing-a-spatial-point-map",
    "title": "Hands-on Exercise 3",
    "section": "6.0 Drawing a Spatial Point Map",
    "text": "6.0 Drawing a Spatial Point Map\n\ntm_shape(mpsz_sf) +\n  tm_polygons() +\n  tm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\n* All the layers on the map fit together properly because they use the same coordinate system. This means they all refer to the same geographical area, which is crucial for accurate mapping and analysis.\n\nOR -&gt; Pin Map\n\ntmap_mode('view')\ntm_shape(childcare_sf) +\n  tm_dots()\n\n* Using interactive mode in tmap -&gt; can zoom in & out. Click on points to see more info\n* Can choose from different background map styles. Default = ESRI.WorldGrayCanvas. (Choose from ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap)\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n* Switch back to “plot”. Because each interactive mode consume a connection. Avoid &gt;10 in 1 RMarkdown doc when publish on Netlify"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#second-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#second-order-spatial-point-patterns-analysis",
    "title": "Hands-on Exercise 3",
    "section": "7.0 Second-order Spatial Point Patterns Analysis",
    "text": "7.0 Second-order Spatial Point Patterns Analysis\n\n7.1 Analysing Spatial Point Process Using G-Function\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event.\nCompute G-function estimation by using Gest() of spatstat package.\nPerform monta carlo simulation test using envelope() of spatstat package.\n\n\n7.1.1 Choa Chu Kang planning area\n\n\nComputing G-function estimation\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n7.1.2 Tampiness planning area\n\n\nComputing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-fucntion\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_tm.csr)\n\n\n\n\n\n\n\n\n\n\n7.2 Analysing Spatial Point Process Using F-Function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape.\nCompute F-function estimation by using Fest() of spatstat package.\nPerform monta carlo simulation test using envelope() of spatstat package.\n\n\n7.2.1 Choa Chu Kang planning area\n\n\nComputing F-function estimation\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-fucntion\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n7.2.2 Tampines planning area\n\n\nComputing F-function estimation\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)\n\n\n\n\n\n\n\n\n\n\n7.3 Analysing Spatial Point Process Using K-Function\nK-function measures the number of events found up to a given distance of any particular event.\nCompute K-function estimates by using Kest() of spatstat package.\nPerform monta carlo simulation test using envelope() of spatstat package.\n\n\n7.3.1 Choa Chu Kang planning area\n\n\nComputing K-function estimation\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n7.3.2 Tampines planning area\n\n\nComputing K-function estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n7.4 Analysing Spatial Point Process Using L-Function\nCompute L-function estimation by using Lest() of spatstat package.\nPerform monta carlo simulation test using envelope() of spatstat package.\n\n\n7.4.1 Choa Chu Kang planning area\n\n\nComputing L-function estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n7.4.2 Tampines planning area\n\n\nComputing L-function estimation\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "sf: Handles geospatial data, including points, lines, and polygons.\nreadr: Imports data from CSV files.\ndplyr: Performs relational joins to merge datasets.\nspdep: Computes spatial weights and calculates spatially lagged variables.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\n\nTwo data sets will be used:\n\nHunan county boundary layer: a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: contains selected Hunan’s local development indicators in 2012.\n\n\nImporting Geospatial DataImporting Aspatial Data\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#setup",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "sf: Handles geospatial data, including points, lines, and polygons.\nreadr: Imports data from CSV files.\ndplyr: Performs relational joins to merge datasets.\nspdep: Computes spatial weights and calculates spatially lagged variables.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\n\nTwo data sets will be used:\n\nHunan county boundary layer: a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: contains selected Hunan’s local development indicators in 2012.\n\n\nImporting Geospatial DataImporting Aspatial Data\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#performing-relational-join",
    "title": "Hands-on Exercise 5",
    "section": "2.0 Performing relational join",
    "text": "2.0 Performing relational join\nupdate the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe.\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 5",
    "section": "3.0 Visualising Regional Development Indicator",
    "text": "3.0 Visualising Regional Development Indicator\nDistribution of GDPPC 2012:\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5",
    "section": "4.0 Computing Contiguity Spatial Weights",
    "text": "4.0 Computing Contiguity Spatial Weights\n\nUse poly2nb() from the spdep package to find neighboring regions.\nThe function creates a list of neighboring areas based on shared borders.\nCan pass ‘queen’ as argument\n\ntake TRUE (default)/FALSE\nif FALSE -&gt; return a list of 1st order neighbours using the Queen criteria\n\n\n\nComputing (QUEEN) contiguity based neighboursCreating (ROOK) contiguity based neighbours\n\n\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\n\n\n\nExplanation\n\n\n\n\nTotal 88 area units in Hunana.\nMost connected area unit has 11 neighbours\n2 area units with only 1 neighbour\n\n\n\n\nTo see the neighbours:\neg. in 1st polygon in the object\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\n\n\n\n\n\n\nExplanation\n\n\n\n\nPolygon 1 has 5 neighbours.\nThe numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\n\n\n\n\n\nTo retrieve country name\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\n\n\nReveal country names of the 5 neighbouring polygons\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\n\n\nRetrieve GDPPC of these 5 countries\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\n\nDisplay the complete weight matrix\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\n\n\n\n\n\n\nExplanation\n\n\n\nTotal 88 area units in Hunan.\nMost connected area unit has 10 neighbours.\n2 area units with only 1 neighbour"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/data/MPSZ-2019/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex01/data/MPSZ-2019/MPSZ-2019.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/data/MPSZ-2019/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex02/data/MPSZ-2019/MPSZ-2019.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/data/MPSZ-2019/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex03/data/MPSZ-2019/MPSZ-2019.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "href": "In-class_Ex/In-class_Ex04/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5 -",
    "section": "",
    "text": "Overview\nxxx\n\n\n1.0 Setup\n\n1.1 Installing R-Packages\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)\n\nInstalling package into 'C:/Users/ngkng/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\n\n\nalso installing the dependencies 'TH.data', 'sandwich', 'DEoptimR', 'zoo', 'xts', 'intervals', 'LearnBayes', 'multcomp', 'robustbase', 'spacetime', 'spatialreg', 'FNN'\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4:\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4/PACKAGES'\n\n\n\n  There is a binary version available but the source version is later:\n         binary source needs_compilation\nsandwich  3.1-0  3.1-1             FALSE\n\npackage 'TH.data' successfully unpacked and MD5 sums checked\npackage 'DEoptimR' successfully unpacked and MD5 sums checked\npackage 'zoo' successfully unpacked and MD5 sums checked\npackage 'xts' successfully unpacked and MD5 sums checked\npackage 'intervals' successfully unpacked and MD5 sums checked\npackage 'LearnBayes' successfully unpacked and MD5 sums checked\npackage 'multcomp' successfully unpacked and MD5 sums checked\npackage 'robustbase' successfully unpacked and MD5 sums checked\npackage 'spacetime' successfully unpacked and MD5 sums checked\npackage 'spatialreg' successfully unpacked and MD5 sums checked\npackage 'FNN' successfully unpacked and MD5 sums checked\npackage 'GWmodel' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\ngkng\\AppData\\Local\\Temp\\Rtmpi8KwfL\\downloaded_packages\n\n\ninstalling the source package 'sandwich'\n\n\n\nGWmodel installed\n\n\n\n\n1.2 Data Acquisition\nWe will be using 2 sets of data:\n\n\n1.3 Importing Hunan data\n\nHunan shapefileHunan_2012 table\n\n\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\") \n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\nhunan2012\n\n\n\n\n\n\n\nTo save derived data:\n\nwrite_rds(hunan_sf, \"data/rds/hunan_sf.rds\")\nwrite_rds(hunan2012, \"data/rds/hunan2012.rds\")\n\n\n\nTo read stored derived data:\n\n\n\n\n\n\nNote\n\n\n\necho: false, will not print out\n\n\n\n1.4 Data Preparation and Wrangling\n\nJoining Hunan and Hunan_2012\n\nhunan_GDPPC &lt;- left_join(hunan_sf,hunan2012, join_by(County))%&gt;%\n  select(1:4, 7, 15)\n\nhunan_GDPPC\n\nSimple feature collection with 88 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\nConverting to SpatialPolygonDataFrame\n\nhunan_sp &lt;- hunan_GDPPC %&gt;% \n  as_Spatial()\n\n\n\n\n\n\n\nNote\n\n\n\nLook at the difference between the data structure of sp and sf\n\n\n\n\n\n\n\n2.0 Determine fixed bandwidth\n\nCross-alidationAIC\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"CV\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\nbw_CV\n\n[1] 76.29126\n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"AIC\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\nbw_AIC\n\n[1] 160.5517\n\n\n\n\n\n\n\n3.0 Determine adaptive bandwidth\n\nCross-ValidationAIC\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"CV\",\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\nbw_CV\n\n[1] 22\n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"AIC\",\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\nbw_AIC\n\n[1] 22\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFixed distance = will be in km,\nthe neighbors are the same for CV and AIC\n\n\n\n\n\n\n\n\nNote\n\n\n\nFixed bandwidth: adaptive = False\nAdaptive bandwidth: adaptive = True\n\n\n\n\n\n4.0 Geographically Weighted Summary Statistics with Adaptive bandwidth\n\ngwstat &lt;- gwss(data=hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\n\n\n5.0 Extract the data from gwstat\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)\n\n\n\n\n\n\n\nNote\n\n\n\ncbind() to append the newly derived data.frame onto hunan_sf sf data.frame\n\n\n\n\n6.0 Visualising geographically weighted summary statistics\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geographically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 1.0,\n            legend.text.size = 0.5,\n            legend.height = 1.50,\n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "Notes/Lesson_1.html",
    "href": "Notes/Lesson_1.html",
    "title": "2 Types of Data Models",
    "section": "",
    "text": "2 Types of Data Models\n\n1. Vector\n\nused for mapping boundaries, networks, and precise locations\nPoints: Discrete location (a city, tree etc)\n\n1 coordinate\n\nLines: Linear features (roads, rivers etc)\n\n&gt;= 2 coordinate pairs\nknow length\n\nPolygons: Area features (lakes, land parcels etc)\n\n&gt;=3 line segment\nknow location, length, and area\n\n\n\n\n2. Raster\n\nused for continuous data (eg. elevation, temperature, satellite, imagery, land cover)\nRepresents geographic features as a grid of cells or pixels.\nEach cell has a value representing information such as color, elevation, or land cover type.\n\n\n\n\n\n\n\n\n\n\n\nVector\nRaster\n\n\n\n\nData Representation\nPoints, lines, and polygons representing discrete features.\nGrid of cells or pixels representing continuous data.\n\n\nData Storage\nStores data as coordinates with associated attributes.\nStores data in a grid format, each cell holding a value.\n\n\nPrecision and Detail\nHighly precise, ideal for exact measurements and boundaries.\nResolution-dependent, better for continuous data representation.\n\n\nData Processing\nSuited for network analysis and topology-based operations.\nEfficient for spatial analysis involving overlays and map algebra.\n\n\nApplications\nUsed in mapping boundaries, networks, and urban planning.\nUsed in remote sensing, environmental modeling, and continuous surface analysis.\n\n\nVisualization\nSharp visuals, clear boundaries, smooth scaling.\nCan become pixelated when zoomed in; best for surface data like satellite imagery.\n\n\n\n\n\n\nCoordinate System\n\n\nProvides a location reference to the geospatial data\nTypes\n\nGCS -Geographic Coordinate System\nPCS -Projected Coordinate System\n\n\n\n\n\n\n\n\n\nGeographic Coordinate System (GCS)\nProjected Coordinate System (PCS)\n\n\n\n\n\n\n\n\nuse a 3D surface (eg. WGS84)\n\n\n\nprovides accurate position info\n\n\n\nnot appropriate for distance & area measurements\nprovides consistent length & area measurement across space\n\n\n\nNeed to transform GCS -&gt; PCS before performing geospatial analysis\n\n\nSimple Features\n\n\n\n\nShapefile\n\n\n\n\n\n\n\n\nif read, no need specify extension\n\n\n\n\n\nFor other vector format, read need to specify extension\n\nconsist of a few files\na simple, non-topological format for storing geometric location & attribute info of geographic features\nGeographic features in a shapefile can be represented by Points, Lines, Polygons(areas)\n\n\n\nSF functions\n\nGeospatial data handling\nst_read & read_sf\n\n\n\n\n\n\n\nShapefile format\nOther format\n\n\n\n\n\n\n\n\n\nread_csv\n\nglimpse -&gt; similar to print()\n\nst_write & write_sf\nst_as_sf -&gt; convert data frames/spatial objects into \"sf\" simple features, allowing for spatial data manipulation & analysis\nst_as_text -&gt; convert to Well Known Text\nst_as_binary\nst_as_sfc -&gt; convert coordinate data into \"sfc\" simple feature collections objects\nst_transform -&gt; convert coordinates to a different coordinate reference system\n\n\nGeospatial confirmation\nst_intersects\n\n\n\n\nst_disjoint -&gt; !intersect\nst_equals\nst_equal_exacts\n\n\nst_crosses -&gt; cross (don’t touch)\nst_touches\nst_within\n\n\nst_contains\nst_covers\nst_covered_by\n\n\nst_overlaps\n\n\n\n\n\n\n\nGeospatial operations\n\n\n\nst_union\nst_intersection\n\n\nst_difference\nst_sym_difference\n\n\n\n\n\n\n\n\n\n\nGeospatial creation\n\n\n\n\n\n\n\nst_interpolate_aw -&gt;\n\narea-weighted interpolation\nuses st_intersection to interpolate/redistribute attribute values, based on area of overlap\n\nst_join\neg. join a point data and polygon data together\n\n\n\n\n\n\nGeospatial operations\n\n\n\n\n\n\n\n\nst_line_merge -&gt; merge lines\nst_segmentize -&gt;\nadds points to straight lines\nst_centroid(poly)\n\n\n\nst_voronoi\nst_convex_hull\nst_triangulate\n\n\nst_polygonize\nst_simplify -&gt;\nsimplify lines by removing articles\nst_buffer(poly, 5)\n\n\n\nst_split -&gt;\nsplit a ploygon given line geometry\nst_make_valid -&gt;\nmake an invalid geometry valid\nis_boundary -&gt;\nreturn the boundary of a geometry\n\n\n\n\n\nGeospatial measurement\n\n\n\n\n\n\n\nst_zm -&gt;\nset/remove z and/or m geometry\nst_coordinates -&gt;\nreturns coordinates in a matrix/data.frame\n\n\nst_geometry\n\nst_is -&gt;\ncheck if geometry is of a particular type\n\n\n\nhead -&gt; reveal complete info of a feature object, can select the number of records to display\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo Check coordinate system of mpsz\n\n\n\nAssign EPSG code to mpsz\n\n\n\nSummary\n\n\n\nTop n\n\n\n\nSum\n\n\n\nCompute density\n\n\n\nHistogram"
  },
  {
    "objectID": "Notes/Lesson_3.html",
    "href": "Notes/Lesson_3.html",
    "title": "Notes 3",
    "section": "",
    "text": "Purpose of Geospatial Analytics\n\nSo that we can quantitatively derive it (eg. using KDE).\nUses data related to locations to find patterns & trends\n\n\n\nSpatial Point Patterns\n\nTo study how points (Event) are spread out over an area\nOnly map Events, no ‘Non-Event’\nThe mapped pattern should not be:\n\nselection bias\nNot a sample (eg. It is ok to take aged 70-80 from the population. But do not do random sampling out of this group)\n\n\nExample:\n\n\n\n\nReal-world spatial point patterns -Random OR Patterned?\n\nhard to have random distribution\n\neg. Some areas like the airport will never have childcare\nWe can use 2nd Order Spatial Point Pattern Analysis to prove\n\nhard to find something uniform in real world\n\neg. For instance a desert, if you zoom out a bit, there could be small hills, different land. It would not be the same across such as flat land\n\nBefore performing any spatial analysis, exclude areas that is definitely dont have the occurence. [Else, when generate the spatial random data, you might have childcare center there]\n\n\n\n\nSpatial Point Patterns Analysis\n\nusually in 2D space\nset X = {x ∈ D}, D = study region, subset of Rn, a n-dimensional Euclidean space\nIssue: We need infer if the given is merely random or result of some process:\n\n\n\n\n\n1st-order VS 2nd-order Analysis\n\n\n\n\n\n\n\n\n\n1st Order\n2nd Order\n\n\n\n\n\n\nfocuses on the overall intensity or density of events across a study area.\n\nexamines how the number of points (events) changes over space, often influenced by external factors such as environmental conditions, socioeconomic factors, or other large-scale trends.\nExample:\n“Where are the points more or less dense?”\n“How does the density of events vary across the study area?\n\nexamines the interaction or relationships between points within a study area.\nhelp to identify whether points tend to cluster, repel, or distribute randomly relative to each other.\n\nExample:\n“Are the points clustered, dispersed, or randomly distributed in relation to each other?”\n“How does the pattern change with distance?”\n\n\nTechnique\nDensity-based:\n\nKDE (Kernel density estimation)\nQuadrat analysis\n\nDistance-based:\n\nNearest Neighbour Index\n\n\nG function\nF function\nK function\nL function\n\n\n\n\n\n\n\n1st-order[Kernel Density Estimation (KDE)]\n\nused to estimate the probability density function of a random variable.\n\n\n\n\nSteps in KDE\n\nPlace a Kernel on Each Point (event location)\n\nThe height and shape of this bump depend on the chosen kernel function and the bandwidth.\n\nSum the Kernels\n\nFor each point in the study area, the contribution of all surrounding kernels is summed to calculate the density value at that point.\n\nCreate a Continuous Surface\n\nThe result is a smooth surface where higher values indicate areas with higher event densities, and lower values indicate areas with fewer events.\n\n\n\n\nKDE Methods\n\n\nUniform -&gt; intensity will not change during this period, immediately after, it will be 0\nTriangular -&gt; move away from center point, it will decrease very fast from the center point\nQuartic & Gaussian -&gt;\n\nnot identical, but similar. If get negative value from Gaussian, can switch to Quartic.\nGaussian is very common (Gives more weight to points closer to the event & less weight to points farther away)\nTry different option, select the appropriate one & explain why\n\n\n\n\nKDE Bandwidth\n\n\n\n\n\n\n\nFixed Bandwidth -determine distance for you\n\nDefine a fixed distance -&gt; use this distance throughout the study\nIn extreme case, might not able to calibrate in local areas where data are too sparse to satisfy the calibration requirements\n\n\n\n\n\nAdaptive Bandwidth -determine the k for you\n\nFixed the no. of spatial points\neg. I will search for 8 childcare center no matter the length\n\n\n\n\n\n\n* Small bandwidth = highly localized estimate, showing fine details (but could miss broader patterns)\n* Large bandwidth = smooth out the estimart (possibly oversimplifying the data)\n* Automatic bandwidth -&gt; bw.diggle()\n\n\n\n\n1st-order [Quadrat Analysis]\n\nSteps\n\n\n\n\n\n\n\n\nDivide the study area into subregion of equal size,\n\noften squares, but don’t have to be.\n\n\n\n\n\n\nCount the frequency of events in each region.\n\n\n\n\n\nCalculate the intensity of events in each region.\n\n\n\n\n\nCalculate the quadrat statistics and perform CSR test.\n\n\n\n\n\nUniform distribution -&gt; variance-mean ratio = 0\nRandom distribution -&gt; variance-mean ratio close to 1\nCluster distribution -&gt; variance-mean ratio greater than 1\n\n\nInterpretation\n\n\n\nWeaknesses\n\nsensitive to the quadrat size\n\nIf too small, they may contain only a couple of points, and\nIf too large, they may contain too many points.\n\nIt is a measure of dispersion rather than a measure of pattern.\n\n\n\nIt results in a single measure for the entire distribution, so variation within the region are not recognised.\n\n\n\n\nComplete Spatial Randomness CSR\n\nsatisfy 2 conditions\n\nany event has equal probability of being in any location, a 1st order effect\nThe location of one event is independent of the location of another event, a 2nd order effect.\n\n\n\n\n1st-order [Distance-based: Nearest Neighbour Index]\n\nDirect distance from a point to its nearest neighbour\nIndex &lt; 1: clustering\nIndex = 1: random\nIndex &gt; 1: dispersion\n\n\nExample:\n\n\np-value is &lt; 0.05, so reject null hypo that the point patterns are randomly distributed\n\n\n2nd-order [G function]\n\n\nwithin this radius, how many childcare i found\nWithin 0-9, what is the intensity\nClustered: If G increases rapidly at short distance\nEvenness: If G increases slowly up to distance where most events spaced, then increases rapidly\n\n\nMonte Carlo simulation test of CSR\n\n\nnsim = 999 &lt;- Performed 999 simulations [Cannot do 1 only, the more = more stable, result will converge]\nfor each simulated point pattern, estimate G(r) & use the max 95th and min 5th of these functions for the simulated patterns to define an upper and lower simulation envelope.\nEstimate G(r) is statistically significant if estimated G(r) lies above the upper envelope or below the lower envelope\n\n\n\n\n\n2nd-order [F function]\n\nSelect a sample of point locations anywhere in the study region at random\n\nDetermine min distance from each point to any event in the study area.\n\n\nClustered = F(r) rises slowly at first, but more rapidly at longer distances.\n\n\n\nEvenness = F(r) rises rapidly at first, then slowly at longer distances.\n\n\n\n\nComparison between F and G function\n\n\n\n2nd-order [K function]\n\nLimitation of nearest neighbor distance method is that it uses only nearest distance\nConsiders only the shortest scales of variation.\nK function uses more points.\n\nProvides an estimate of spatial dependence over a wider range of scales.\nBased on all the distances between events in the study area.\nAssumes isotropy over the region.\n\n\n\n\nCalculating K function\n\nConstruct a circle of radius h around each point event(i).\nCount the number of other events (j) that fall inside this circle.\nRepeat these two steps for all points (i) and sum results.\nIncrement h by a small amount and repeat the calculation.\n\n\nSignificant cluster pattern -&gt; above envelop\nSignificant regular pattern -&gt; below envelop\nCSR -&gt; inside envelop\n\n\n\n2nd-order [L function]\n\nK function will be normalised to obtained a benchmark of zero.\n\n\n\nWhen an observed L value is greater than its corresponding L(theo)(i.e. red break line) value for a particular distance and above the upper confidence envelop, spatial clustering for that distance is statistically significant (e.g. distance beyond C).\nWhen an observed L value is greater than its corresponding L(theo) value for a particular distance and lower than the upper confidence envelop, spatial clustering for that distance is statistically NOT significant (e.g. distance between B and C).\nWhen an observed L value is smaller than its corresponding L(theo) value for a particular distance and beyond the lower confidence envelop, spatial dispersion for that distance is statistically significant. - When an observed L value is smaller than its corresponding L(theo) value for a particular distance and within the lower confidence envelop, spatial dispersion for that distance is statistically NOT significant (e.g. distance between A and B).\n\n\n\nL(r)&gt;0 indicates that the observed distribution is geographically concentrated.\nL(r)&lt;0 implies dispersion.\nL(r)=0 indicates complete spatial randomness (CRS).\n\n* Anything outside of envelop, you will have enough statistical evidence, if inside means you still fall into the confidence lvl (cannot reject null, cause not enough evidence to infer)\n\n\nset.seed()\n\nto produce reproducible result\nresult from algo might change every run, use this to fix it"
  },
  {
    "objectID": "Notes/Lesson_6.html",
    "href": "Notes/Lesson_6.html",
    "title": "Notes 6",
    "section": "",
    "text": "“Everything is related to everything else, but near things are more related than distant things.”"
  },
  {
    "objectID": "Notes/Lesson_6.html#spatial-weights-wij",
    "href": "Notes/Lesson_6.html#spatial-weights-wij",
    "title": "Notes 5",
    "section": "",
    "text": "A way to define spatial neighbourhood\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt measure from centroid!\nNeed to clean data properly. EG. If we only need to find the childcare in SG, we should remove the outer island, else u might see centroid being not in the center of where you expect it"
  },
  {
    "objectID": "Notes/Lesson_6.html#toblers-first-law-of-geography",
    "href": "Notes/Lesson_6.html#toblers-first-law-of-geography",
    "title": "Notes 6",
    "section": "Tobler’s First Law of Geography",
    "text": "Tobler’s First Law of Geography\n“Everything is related to everything else, but near things are more related than distant things.”"
  },
  {
    "objectID": "Notes/Lesson_6.html#spatial-dependency",
    "href": "Notes/Lesson_6.html#spatial-dependency",
    "title": "Notes 6",
    "section": "Spatial Dependency",
    "text": "Spatial Dependency\n\nrefers to the way that the value of a variable at one location is influenced by values at neighboring locations\nhighlights the interconnectedness of spatial data\nSimilar values are likely to cluster than randomly distributed"
  },
  {
    "objectID": "Notes/Lesson_6.html#types-of-autocorrelation",
    "href": "Notes/Lesson_6.html#types-of-autocorrelation",
    "title": "Notes 6",
    "section": "Types of Autocorrelation",
    "text": "Types of Autocorrelation\n\nPositive Autocorrelation:high rainfall areas likely to be near other high rainfall areas\nNegative Autocorrleation: eg. a region where high property values are next to areas of low property values."
  },
  {
    "objectID": "Notes/Lesson_6.html#measures-of-global-spatial-autocorrelation",
    "href": "Notes/Lesson_6.html#measures-of-global-spatial-autocorrelation",
    "title": "Notes 6",
    "section": "Measures of Global Spatial Autocorrelation",
    "text": "Measures of Global Spatial Autocorrelation\n\n\n\n\n\n\nNote\n\n\n\n* Can use both together -&gt; if Moran’s I shows clustering + Geary’s C indicate low differences between neighbors = strengthen the conclusion that there’s a strong spatial pattern\nThe 2 measures are inversely related -&gt; High C correspond to Low I\n\n\n\nMoran’s IGeary’s c\n\n\nbroad view of overall spatial patterns—are similar values clustered or dispersed?\n\nNegative (I &lt;0) -&gt; Dissimilar values, eg. High value next to low value\nPositive (I&gt;0) -&gt; Lots of similar values nearby, eg high temp areas near each other\nClose to 0 -&gt; No real pattern\n\n\n\nlocal differences between neighbors—how similar or different are individual locations from their immediate surroundings?\n\nSmall c (&lt;1) -&gt; neighbours are similar -Clustered\n(C = 1) -&gt; observations are arranged randomly over space\nLarge c (&gt; 1) -&gt; neighbours are very different from u -Dispersed\n\n\n\n\n\nZ-ScoreP-valueSpatial Randomness (Null Hypo)\n\n\n\nSee how far away a value is from the avg(mean) in S.D.\nHigh score = value is much higher than avg\n\n\n\n\nHelp to  decide if result are significant or due to chance\nLow p = unlikely to happen by chance, so reject null hypo\nFail to reject null hypo if p-value &gt; alpha value (0.05)[95% confidence]\n\n\n\n\nAssumes the value at 1 place doesn’t depend on any value nearby\nSo, moving values around won’t change the overall info\n\n\n\n\n\n\n\n\n\n\nIf your Data violates assumptions\n\n\n\nIf Moran’s I and Geary’s C aren’t true, can use Monte Carlo simulation\n\nSimulate Moran’s I many times with the assumption that there’s no pattern\nAssigning all regions the mean value\nCalculate Moran’s I\nCompare it with Actual Moran’s I value to get a p-value"
  },
  {
    "objectID": "Notes/Lesson_6.html#measures-of-global-highlow-clustering-getis-ord-global-g",
    "href": "Notes/Lesson_6.html#measures-of-global-highlow-clustering-getis-ord-global-g",
    "title": "Notes 6",
    "section": "Measures of Global High/Low Clustering: Getis-Ord Global G",
    "text": "Measures of Global High/Low Clustering: Getis-Ord Global G\n\nmeasures how clustered/spread out high & low values are among neighbouring areas.\nThe variables must contain only positive\nIf P-Value Not Significant (High P-value): can’t reject the null hypothesis. The pattern could just be random.\nIf P-Value Significant (Low P-value): can reject null hypo\n\n+ Z score -&gt; High values are more clustered together than expected by chance.\n- Z score -&gt; Low values are more clustered together than expected by chance."
  },
  {
    "objectID": "Notes/Lesson_6.html#local-vs-global-measures",
    "href": "Notes/Lesson_6.html#local-vs-global-measures",
    "title": "Notes 6",
    "section": "Local VS Global Measures",
    "text": "Local VS Global Measures\nGlobal\n\nSummary for entire area. Eg, Overall, are crime rates clumped together or not\n\nLocal\n\nZoom on specific area. Eg. Where exactly are clusters or unusal spots in this area"
  },
  {
    "objectID": "Notes/Lesson_6.html#local-spatial-autocorrelation-statistics",
    "href": "Notes/Lesson_6.html#local-spatial-autocorrelation-statistics",
    "title": "Notes 6",
    "section": "Local Spatial Autocorrelation Statistics",
    "text": "Local Spatial Autocorrelation Statistics\n\nto understand the distribution patterns.\nUses methods focusing on identifying how attribute values (eg. crime rates, disease incidence) are spatially related to each other across different locations, revealing spatial clusters/anomalies\nCommon methods:\n\nLocal Moran’s ILocal Geary’s cGetis-Ord Gi*\n\n\n\nIdentifies clusters of similar values (high-high or low-low) or spatial outliers (high-low or low-high).\nIndicates if a location has attribute values similar to its neighbors\n\n\nInterpretation of Local Moran\n\nOutlier: if it has low values while surrounding have high values\nCluster: You and surrounding areas have high values\nP-value need to be small enough for cluster/outlier to be considered Statistically Significant\nalpha-values are 0.1(90%), 0.05 (95%), 0.01 (99%), 0.001 (99.9%) confidence intervals\n\n\n\n\nSimilar to Local Moran’s I but focuses more on differences between adjacent locations\nUsed to detect local spatial heterogeneity\n\n\n\n\nIdentifies hot spots, cold spots Area Analysis (HCSA)\nUseful to detect areas with significantly high or low attribute values\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWith * consider observation itself\n\n\n\n\n\nUse case: Detect clusters/outliers, hot spot or cold spot, patterns in data that don’t change over distance"
  },
  {
    "objectID": "Notes/Lesson_6.html#local-indicator-of-spatial-association-lisa",
    "href": "Notes/Lesson_6.html#local-indicator-of-spatial-association-lisa",
    "title": "Notes 6",
    "section": "Local Indicator of Spatial Association (LISA)",
    "text": "Local Indicator of Spatial Association (LISA)\n\nhelp to find clusters/unusual areas in a specific area & ensure it align with the overall trend of the entire area -&gt; When you add up all the LISA values, it should reflect overall pattern of the entire area\nDetecting Spatial Clusters & Outliers:\n\ncalculate local statistic value, a Z-score, a P-value, a code representing cluster type for each statistically significance of the computed index values"
  },
  {
    "objectID": "Notes/Lesson_6.html#interpretation-of-local-moran",
    "href": "Notes/Lesson_6.html#interpretation-of-local-moran",
    "title": "Notes 6",
    "section": "Interpretation of Local Moran",
    "text": "Interpretation of Local Moran\n\nOutlier: if it has low values while surrounding have high values\nCluster: You and surrounding areas have high values\nP-value need to be small enough for cluster/outlier to be considered Statistically Significant\nalpha-values are 0.1(90%), 0.05 (95%), 0.01 (99%), 0.001 (99.9%) confidence intervals"
  },
  {
    "objectID": "Notes/Lesson_6.html#fixed-vs-adaptive-weighting-scheme",
    "href": "Notes/Lesson_6.html#fixed-vs-adaptive-weighting-scheme",
    "title": "Notes 6",
    "section": "Fixed VS Adaptive Weighting Scheme",
    "text": "Fixed VS Adaptive Weighting Scheme\n\nFixed Weighting SchemeAdaptive Weighting Scheme\n\n\n\n\nUses a set distance to determine neighbors for each feature.\nConsiderations:\n\nEvery feature should have at least one neighbor within this distance.\nNo feature should have all other features as neighbors (the distance shouldn’t be too large).\nIdeally, each feature should have around 8 neighbors to get reliable results.\nIssues:\n\nIn areas with few data points, estimates can be unreliable.\nIn dense areas, this scheme might miss small local patterns.\nIn very sparse areas, it might not work at all because there aren’t enough neighbors to analyze properly.\n\n\n\n\n\n\n\nAdjusts the distance based on data density.\nFeatures:\n\nIn dense areas, the “neighborhood” is smaller to capture local variations.\nIn sparse areas, the “neighborhood” is larger to include enough neighbors.\nOften, this scheme uses the nearest number of neighbors instead of a fixed distance. This makes it more flexible and accurate in varied data densities."
  },
  {
    "objectID": "Notes/Lesson_6.html#best-practice-guidelines",
    "href": "Notes/Lesson_6.html#best-practice-guidelines",
    "title": "Notes 6",
    "section": "Best Practice Guidelines",
    "text": "Best Practice Guidelines\n\nTo get Reliable ResultsChoosing a Spatial Weighting MethodChoosing a Fixed-Distance Band\n\n\n\nEnsure your dataset has at least 30 features.\nUse continuous numeric data (e.g., counts, rates). Avoid categorical data.\n\n\n\n\nPolygon Contiguity:\n\nGood for similar-sized polygons.\nWorks when spatial interaction is stronger between neighboring polygons.\nUse “row standardization” to balance the influence of polygons with different numbers of neighbors.\n\nFixed Distance:\n\nIdeal for point data or polygons with varying sizes.\nEnsures consistent analysis by maintaining the same distance for all points.\n\n\n\n\nInverse Distance:\n\nSuitable for continuous data or processes where closer features interact more.\nCan be computationally heavy because every feature can be a neighbor to every other feature.\n\nK-Nearest Neighbors:\n\nGuarantees a minimum number of neighbors for each feature.\nUseful when data values are skewed, ensuring context with at least eight neighbors.\nAdjusts for varying feature distribution, adapting to sparse or dense areas.\nFocuses on the number of neighbors, not fixed distance.\n\n\n\n\n\nSelect a distance based on the spatial scale of the phenomenon you’re studying.\nEnsure all features have at least one neighbor within this distance.\nDon’t worry about finding a single “correct” distance—multiple processes can influence clustering.\nAvoid making every feature a neighbor to all others.\nFor skewed data, aim for each feature to have about eight neighbors."
  },
  {
    "objectID": "Notes/Lesson_6.html#mann-kendall-test-for-trend",
    "href": "Notes/Lesson_6.html#mann-kendall-test-for-trend",
    "title": "Notes 6",
    "section": "Mann-Kendall Test for Trend",
    "text": "Mann-Kendall Test for Trend\n\nPurpose: Determines if a set of values is increasing, decreasing, or stable over time.\nNon-Parametric: Works for any data distribution (doesn’t need to be normal).\nNo Serial Correlation: Your data points should not be influenced by previous values in the series.\nHypotheses:\n\nNull Hypothesis: No trend exists (values are stable over time).\nAlternative Hypothesis: A trend exists (values are consistently increasing or decreasing).\n\nLimitations:\n\nIt detects the direction of the trend but not how big the change is.\nNeeds at least 8-10 data points for reliable results. Fewer points increase the risk of missing real trends.\n\nData Requirements for Mann-Kendall Test:\n\nNo Seasonal Data: Avoid data that has regular fluctuations (e.g., only collected in summer and winter).\nNo Covariates: Other factors shouldn’t influence your data. The test should only assess the trend of the specific variable you’re interested in.\nOne Data Point per Time Period: If you have multiple data points for the same time, use the median value."
  },
  {
    "objectID": "Notes/Lesson_6.html#ehsa-patterns",
    "href": "Notes/Lesson_6.html#ehsa-patterns",
    "title": "Notes 6",
    "section": "EHSA Patterns",
    "text": "EHSA Patterns\n\nNo pattern, New hot spot, Intensifying hot spot, Diminishing hot spot, Historical hot spot, Persistent hot spot\nConsecutive hot spot -&gt; A place that recently became a hot spot with consecutive periods showing significant hot spot activity\nSporadic hot spot -&gt; A location that is a significant hot spot in the most recent time period but has had a mixed history of being a hot spot in the past. (on & off)\nOscillating hot spot -&gt; A location that is a significant hot spot in the most recent time period but has previously been a significant cold spot."
  },
  {
    "objectID": "Notes/Lesson_6.html#spacetime-cube",
    "href": "Notes/Lesson_6.html#spacetime-cube",
    "title": "Notes 6",
    "section": "Spacetime Cube",
    "text": "Spacetime Cube\n\na structure where every location has a value for every point in time, meaning each location has a complete time series of data.\nKey Terms:\n\nBin: The basic unit of a spacetime cube, representing a specific combination of a location and a time point.\nTime Slice: The collection of all bins (locations) for a specific time point.\nBin Time-Series: The collection of all bins at a particular location across different time points."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Exercise 6 -Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "",
    "text": "1.0 Setup\n\n1.1 Installing R-Packages\nsfdep:\n\ncreates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep\nutilizes list columns extensively to make this interface possible.\n\n\npacman::p_load(sf, sfdep, spdep, tmap, tidyverse)\n\n\n\n1.2 Data Acquisition\nWe will be using 2 sets of data:\n\nHunan, a geospatial data set in ESRI shapefile format, and\nHunan_2012, an attribute data set in csv format.\n\n\n\n1.3 Importing Hunan data\n\nHunan shapefileHunan_2012 table\n\n\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\") \n\nReading layer `Hunan' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\In-class_Ex\\In-class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhunan2012\n\n# A tibble: 88 × 29\n   County    City   avg_wage deposite    FAI Gov_Rev Gov_Exp    GDP GDPPC    GIO\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Anhua     Yiyang    30544   10967   6832.    457.   2703  13225  14567  9277.\n 2 Anren     Chenz…    28058    4599.  6386.    221.   1455.  4941. 12761  4189.\n 3 Anxiang   Chang…    31935    5517.  3541     244.   1780. 12482  23667  5109.\n 4 Baojing   Hunan…    30843    2250   1005.    193.   1379.  4088. 14563  3624.\n 5 Chaling   Zhuzh…    31251    8241.  6508.    620.   1947  11585  20078  9158.\n 6 Changning Hengy…    28518   10860   7920     770.   2632. 19886  24418 37392 \n 7 Changsha  Chang…    54540   24332  33624    5350    7886. 88009  88656 51361 \n 8 Chengbu   Shaoy…    28597    2581.  1922.    161.   1192.  2570. 10132  1681.\n 9 Chenxi    Huaih…    33580    4990   5818.    460.   1724.  7755. 17026  6644.\n10 Cili      Zhang…    33099    8117.  4498.    500.   2306. 11378  18714  5843.\n# ℹ 78 more rows\n# ℹ 19 more variables: Loan &lt;dbl&gt;, NIPCR &lt;dbl&gt;, Bed &lt;dbl&gt;, Emp &lt;dbl&gt;,\n#   EmpR &lt;dbl&gt;, EmpRT &lt;dbl&gt;, Pri_Stu &lt;dbl&gt;, Sec_Stu &lt;dbl&gt;, Household &lt;dbl&gt;,\n#   Household_R &lt;dbl&gt;, NOIP &lt;dbl&gt;, Pop_R &lt;dbl&gt;, RSCG &lt;dbl&gt;, Pop_T &lt;dbl&gt;,\n#   Agri &lt;dbl&gt;, Service &lt;dbl&gt;, Disp_Inc &lt;dbl&gt;, RORP &lt;dbl&gt;, ROREmp &lt;dbl&gt;\n\n\n\n\n\n\n\n1.4 Data Preparation and Wrangling\n\nJoining Hunan and Hunan_2012\n\nhunan_GDPPC &lt;- left_join(hunan_sf,hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\nhunan_GDPPC\n\nSimple feature collection with 88 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\n\n1.5 Plot choropleth map\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by county, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.0,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\n\n2.0 Global Measures of Spatial Association\n\nStep 1: Deriving Queen’s Contiguity weights: sfdep methods\n\nwm_q &lt;- hunan_GDPPC %&gt;% \n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\nprint(wm_q)\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\n\n\n\n\nNote\n\n\n\nstyle:\n\ndefault ‘W’ (row standardized weights, sums over all links to n)\ncan be ‘B’ (basic binary coding)\n‘C’(globally standardised, sums over all links to n)\n‘U’ (equal C/no. of neighbours, sums over all all links to unity)\n‘minmax’\n‘S’ (variance-stabilizing coding)\n\nallow_zero: if true, assigns 0 as lagged value\n.before = 1 -&gt; place new data to front of table\nnb -&gt; a neighbor list object\n\n\n\n\nGlobal Moran’s I\n\nComputing Global Moran’ IPerforming Global Moran’s I test\n\n\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\n\n\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\nPerforming Global Moran’I permutation test\nUsing Monte carlo simulation\n\nStep 1Step 2\n\n\n\nset.seed(1234)\n\n\n\n\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\n\nNote\n\n\n\nP-value is smaller than alpha value of 0.05.\nHave enough statistical evidence to reject null hypo that the spatial distribution of GPD per capita are resemble random distribution (i.e. independent from spatial)\nBecause the Moran’s I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering.\n\n\n\n\n\n\n\n\n\n3.0 Local Measures of Spatial Association\nLISA map\n\nshows outliers & clusters.\n2 types of outliers (High-Low, Low-High)\n2 types of cluster (High-High, Low-Low)\nis an interpreted map combining Local Moran’s I & its respective P-value\n\n\nLocal Moran’s I, P value, LISA\n\nComputing Local Moran’s IVisualising Local Moran’s I VS P-valueVisualising LISA map\n\n\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n    .before = 1) %&gt;% \n  unnest(local_moran)\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHot Spot & Cold Spot Area Analysis\n\nComputing local Gi* statisticsVisualising Gi*Visualising p-value of HCSAVisualising Hot Spot & Cold Spot (HCSA)\n\n\n\nwm_idw &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wts = st_inverse_distance(nb, \n                              geometry, \n                              scale = 1,\n                              alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n    gi_star cluster     e_gi  var_gi std_dev p_value p_sim p_folded_sim skewness\n      &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.261   Low     0.00126  1.07e-7  0.283  7.78e-1  0.66         0.33    0.783\n 2 -0.276   Low     0.000969 4.76e-8 -0.123  9.02e-1  0.98         0.49    0.713\n 3  0.00573 High    0.00156  2.53e-7 -0.0571 9.54e-1  0.78         0.39    0.972\n 4  0.528   High    0.00155  2.97e-7  0.321  7.48e-1  0.56         0.28    0.942\n 5  0.466   High    0.00137  2.76e-7  0.386  7.00e-1  0.52         0.26    1.32 \n 6 -0.445   High    0.000992 7.08e-8 -0.588  5.57e-1  0.68         0.34    0.692\n 7  2.99    High    0.000700 4.05e-8  3.13   1.74e-3  0.04         0.02    0.975\n 8  2.04    High    0.00152  1.58e-7  1.77   7.59e-2  0.16         0.08    1.26 \n 9  4.42    High    0.00130  1.18e-7  4.22   2.39e-5  0.02         0.01    1.20 \n10  1.21    Low     0.00175  1.25e-7  1.49   1.36e-1  0.18         0.09    0.408\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualising hot spot and cold spot areas\n\nHCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#step-1-deriving-queens-contiguity-weights-sfdep-methods",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#step-1-deriving-queens-contiguity-weights-sfdep-methods",
    "title": "In-class Exercise 6 -Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "Step 1: Deriving Queen’s Contiguity weights: sfdep methods",
    "text": "Step 1: Deriving Queen’s Contiguity weights: sfdep methods\n\n\n\n\n\n\n\n\n\nComputing Global Moran’ IPerforming Global Moran’s I test\n\n\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\n\n\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\nPerforming Global Moran’I permutation test\nMonte carlo simulation should be used to perform statistical test\n\nStep 1Step 2\n\n\n\nset.seed(1234)\n\n\n\n\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "",
    "text": "Global Impact: Drug abuse has severe health, financial, and social consequences.\nPrevalence: In 2021, 1 in 17 people aged 15–64 worldwide used a drug in the past year.\nGrowth Trend: Drug users increased from 240 million in 2011 to 296 million in 2021.\n\n\n\n\n\nGeopolitical Context: Proximity to the Golden Triangle, a major drug production area, makes Thailand a key market and transit route for drug trafficking.\nYouth Drug Abuse:\n\nApproximately 2.7 million young people in Thailand use drugs.\nAround 300,000 youth aged 15-19 need drug treatment.\nVocational students are nearly twice as involved with drugs compared to secondary-school students.\n\n\nThis Geospatial Analytics will Focus on:\n\nObjective: Determine if drug abuse indicators in Thailand show spatial dependence.\nAnalysis Goals:\n\nIdentify clusters, outliers, and hotspots of drug abuse.\nExamine how these patterns change over time."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#installing-r-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#installing-r-packages",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "1.1 Installing R-Packages",
    "text": "1.1 Installing R-Packages\n\nImporting and Transforming DataDisplaying MapsSpatial AutocorrelationPrediction\n\n\n\nsf:\n\nFor handling spatial vector data and transforming it into simple features (sf) objects.\nFunctions like st_read() for importing spatial data and st_transform() for coordinate reference system transformations.\n\ntidyverse: For data manipulation and transformation, including functions for working with tibble data frames.\nreadr: For reading in CSV or other text-based data files if needed.\ndplyr: provide data manipulation capabilities (eg. to group and summarize the relationships between these columns)\narrow: To read parquet files\n\n\n\n\ntmap: For creating thematic maps and displaying KDE layers.\nggplot2: For additional custom visualizations if needed.\nscales: Transform the unit of measurement for coordinate\nanimation, png, magick: For animation work\n\n\n\n\nsfdep: For performing both local and global spatial autocorrelation analysis\n\n\n\n\nforecast: For trend prediction\n\n\n\n\n\npacman::p_load(tidyverse, sf, readr, ggplot2, tmap, dplyr, arrow, sfdep, scales, animation, png, magick, patchwork, Kendall, zoo, forecast)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-acquisition",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-acquisition",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "1.2 Data Acquisition",
    "text": "1.2 Data Acquisition\nWe will be using 2 sets of data:\n\nDrug offenses DataAdministrative Boundaries\n\n\n\nSource: Thailand Drug Offenses [2017-2022]\nStudy Period: 2017-2022\n\n\n\n\nSource: Thailand - Subnational Administrative Boundaries at HDX.\nProvince Boundaries: For understanding conflict distribution across larger administrative divisions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-geospatial-data-into-r",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-geospatial-data-into-r",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "1.3 Importing Geospatial Data into R",
    "text": "1.3 Importing Geospatial Data into R\n\nDrug Offenses DataAdministrative Boundaries\n\n\n\ndrug_offenses &lt;- read_parquet(\"data/drug_offense/thai_drug_offenses_2017_2022.parquet\")\n\n\ndrug_offenses &lt;- read_csv(\"data/drug_offense/thai_drug_offenses_2017_2022.csv\")\n\nRows: 7392 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): types_of_drug_offenses, province_th, province_en\ndbl (2): fiscal_year, no_cases\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\nNote\n\n\n\nSince the data in CSV and Parquet formats are identical, we only need to import one of these file types.\n\n\n\n\n\nprovince_boundaries &lt;- st_read(dsn = \"data/subnational_administrative_boundary\", layer=\"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex02\\data\\subnational_administrative_boundary' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#checking-geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#checking-geospatial-data",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "1.4 Checking Geospatial Data",
    "text": "1.4 Checking Geospatial Data\n\nDrug Offenses DataAdministrative Boundaries\n\n\n\nclass(drug_offenses)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\n\n\n\n\n\n\nNote\n\n\n\nSince\n\nSince the class of drug_offenses != sf object\n\nwe have to transform it.\n\n\n\n\n\nclass(province_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(province_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\n\n\n\n\nNote\n\n\n\nSince Coordinate Reference System of province_boundaries\nis in 4326 (unit of measurement = degree), we have to transform it"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-preparation-and-wrangling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-preparation-and-wrangling",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "1.6 Data Preparation and Wrangling",
    "text": "1.6 Data Preparation and Wrangling\n\nDrug Offenses DataAdministrative BoundariesUnderstanding the Data\n\n\n\n# Drop & Rename column\ndrug_offenses &lt;- drug_offenses %&gt;% \n  select(fiscal_year, types_of_drug_offenses, no_cases, province_en) %&gt;% \n  rename(\n    year = fiscal_year,\n    offense_type = types_of_drug_offenses,\n    case_count = no_cases,\n    province_name = province_en\n  )\n\n\n\n\nTransform the Coordinate Reference System of these:\n\nprovince_boundaries &lt;- province_boundaries %&gt;%\n  st_transform(crs = 4240)\n\n\n# Drop & Rename column\nprovince_boundaries &lt;- province_boundaries %&gt;% \n  select(Shape_Leng, Shape_Area, ADM1_EN, ADM1_PCODE, geometry) %&gt;% \n  rename(\n    province_name = ADM1_EN,\n    province_code = ADM1_PCODE\n  )\n\n\n\nSample plot\n\nggplot(data = province_boundaries) +\n  geom_sf() +\n  theme_minimal() +\n  labs(title = \"Map of Geometries\",\n       subtitle = \"Displaying multipolygon geometries\",\n       caption = \"Source: Example Data\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Filter for unmatched province_names between Drug Offenses & Province Boundaries data set\nunmatched_provinces &lt;- drug_offenses %&gt;%\n  left_join(province_boundaries, by = \"province_name\") %&gt;%\n  filter(is.na(Shape_Leng)) %&gt;%\n  select(province_name)\n\nunmatched_provinces &lt;- unique(unmatched_provinces) #Loburi, buogkan\n\n\n\n# Transform the province_name in the Drug Offenses dataset\ndrug_offenses &lt;- drug_offenses %&gt;%\n  mutate(province_name = case_when(\n    province_name == \"Loburi\" ~ \"Lop Buri\",\n    province_name == \"buogkan\" ~ \"Bueng Kan\",\n    TRUE ~ province_name  # Keep the original name if no match\n  ))\n\n\n# Assign each drug offense to a province\ndrug_offenses_by_province &lt;- drug_offenses %&gt;%\n  left_join(province_boundaries, by = \"province_name\")\n\n# Check for any empty attributes in the test dataset\nempty_attributes &lt;- sapply(drug_offenses_by_province, function(column) any(is.na(column)))\n\n# Identify columns with missing values\nmissing_columns &lt;- names(empty_attributes[empty_attributes]) # character(0) = No missing Column\n\n\n\n\n\n\n\nWarning\n\n\n\nThe Drug Offenses dataset has some naming issues with province_name.\nWe found two discrepancies: Loburi should be changed to Lop Buri, and buogkan should be updated to Bueng Kan to match the Province Boundaries dataset.\nWe will update the province_name entries in the Drug Offenses dataset accordingly."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#summary-statistics-for-case-counts-by-province",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#summary-statistics-for-case-counts-by-province",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Summary statistics for case counts by province",
    "text": "Summary statistics for case counts by province\n\nsummary_stats &lt;- drug_offenses_by_province %&gt;%\n  group_by(province_name) %&gt;%\n  summarise(total_cases = sum(case_count, na.rm = TRUE)) %&gt;%\n  arrange(desc(total_cases))\n\n\nTop 10 Drug Abuse ProvincesBottom10 Drug Abuse Provinces\n\n\n\ntop_10 &lt;- summary_stats %&gt;% slice(1:10)\n\nplot_top_10 &lt;- ggplot(top_10, aes(x = reorder(province_name, total_cases), y = total_cases)) +\n  geom_bar(stat = \"identity\", fill = \"salmon\") +\n  coord_flip() +\n  labs(title = \"Top 10 Provinces by Total Drug Abuse Cases\",\n       x = \"Province\",\n       y = \"Total Cases\") +\n  scale_y_continuous(labels = comma_format(accuracy = 1)) +\n  theme_minimal(base_size = 10)\n\nplot_top_10 \n\n\n\n\n\n\n\n\n\n\n\n# Bottom 10 provinces based on total cases\nbottom_10 &lt;- summary_stats %&gt;%\n  arrange(total_cases) %&gt;%  \n  slice(1:10)\n\nplot_bottom_10 &lt;- ggplot(bottom_10, aes(x = reorder(province_name, -total_cases), y = total_cases)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  coord_flip() +\n  labs(title = \"Bottom 10 Provinces by Total Drug Abuse Cases\",\n       x = \"Province\",\n       y = \"Total Cases\") +\n  scale_y_continuous(labels = comma_format(accuracy = 1)) +\n  theme_minimal(base_size = 10)\n\nplot_bottom_10"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#trends-over-time-for-the-entire-country",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#trends-over-time-for-the-entire-country",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Trends over time for the entire country",
    "text": "Trends over time for the entire country\n\ndrug_trends &lt;- drug_offenses_by_province %&gt;%\n  group_by(year) %&gt;%\n  summarise(total_cases = sum(case_count))\n\n# Plot trend over time with formatted y-axis labels\nggplot(drug_trends, aes(x = year, y = total_cases)) +\n  geom_line(color = \"blue\") +\n  geom_point(size = 3, color = \"red\") +  \n  labs(title = \"Drug Abuse Cases Over Time\",\n       x = \"Year\", y = \"Total Cases\") +\n  scale_y_continuous(labels = comma)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#summary-statistics",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#summary-statistics",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Summary statistics",
    "text": "Summary statistics\n\nsummary_stats &lt;- drug_offenses_by_province %&gt;%\n  group_by(province_name, year) %&gt;%\n  summarise(\n    total_cases = sum(case_count, na.rm = TRUE),\n    geometry = first(geometry)\n    )\n\nwrite_rds(summary_stats, \"data/rds/summary_stats.rds\")\n\n\nsummary_stats &lt;- read_rds(\"data/rds/summary_stats.rds\")\nsummary_stats\n\n# A tibble: 462 × 4\n# Groups:   province_name [77]\n   province_name  year total_cases                                      geometry\n   &lt;chr&gt;         &lt;dbl&gt;       &lt;dbl&gt;                            &lt;MULTIPOLYGON [°]&gt;\n 1 Amnat Charoen  2017        5076 (((104.9654 16.28154, 104.9654 16.28148, 104…\n 2 Amnat Charoen  2018        5651 (((104.9654 16.28154, 104.9654 16.28148, 104…\n 3 Amnat Charoen  2019        7339 (((104.9654 16.28154, 104.9654 16.28148, 104…\n 4 Amnat Charoen  2020        3949 (((104.9654 16.28154, 104.9654 16.28148, 104…\n 5 Amnat Charoen  2021        8961 (((104.9654 16.28154, 104.9654 16.28148, 104…\n 6 Amnat Charoen  2022        4459 (((104.9654 16.28154, 104.9654 16.28148, 104…\n 7 Ang Thong      2017        1614 (((100.3381 14.79649, 100.3384 14.79607, 100…\n 8 Ang Thong      2018        2717 (((100.3381 14.79649, 100.3384 14.79607, 100…\n 9 Ang Thong      2019        2781 (((100.3381 14.79649, 100.3384 14.79607, 100…\n10 Ang Thong      2020        2636 (((100.3381 14.79649, 100.3384 14.79607, 100…\n# ℹ 452 more rows"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#drug-abuse-cases-by-province",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#drug-abuse-cases-by-province",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Drug Abuse Cases By Province",
    "text": "Drug Abuse Cases By Province\n\n# Create a summary of total cases by province and year\ntotal_cases_by_province_year &lt;- drug_offenses_by_province %&gt;%\n  group_by(province_name, year) %&gt;%\n  summarise(total_cases = sum(case_count, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'province_name'. You can override using the\n`.groups` argument.\n\n\n\n# Define the years to plot\nyears_to_plot &lt;- unique(total_cases_by_province_year$year)\n\n# Set tmap mode for plotting\ntmap_mode(\"plot\")\n\n# Create a directory to store the images\ndir.create(\"maps\", showWarnings = FALSE)\n\n# Create a list to store maps for each year\nmap_list &lt;- list()\n\nfor (year in years_to_plot) {\n  # Filter for the specific year\n  total_cases_year &lt;- total_cases_by_province_year %&gt;%\n    filter(year == year)\n  \n  # Join the total cases with province boundaries\n  province_cases_year &lt;- province_boundaries %&gt;%\n    left_join(total_cases_year, by = \"province_name\")\n  \n  # Create a sequential color palette\n  palette &lt;- brewer.pal(n = 9, name = \"Reds\")\n  \n  # Create the map for the specific year\n  map_list[[as.character(year)]] &lt;- tm_shape(province_cases_year) +\n    tm_polygons(\"total_cases\", \n                palette = palette, \n                title = paste(\"Drug Abuse Cases (\", year, \")\", sep = \"\"), \n                style = \"cont\",  # Use continuous color scale\n                n = 9) +  # Number of classes\n    tm_borders() +\n    tm_layout(title = paste(\"Drug Abuse Cases by Province (\", year, \")\", sep = \"\"), \n              legend.outside = TRUE)\n  \n  # Save the map as a PNG file\n  tmap_save(map_list[[as.character(year)]], \n            filename = paste0(\"maps/drug_cases_\", year, \".png\"), \n            width = 800, height = 600, units = \"px\", dpi = 300)\n  \n  # Optionally, print the map\n  print(map_list[[as.character(year)]])\n}\n\n\n# Create an animated GIF from the saved images\nimg_list &lt;- list.files(\"maps\", pattern = \"*.png\", full.names = TRUE)\n\n# Use magick to create the animation\nanimation &lt;- image_read(img_list) %&gt;%\n  image_animate(fps = 1)  # Adjust fps for speed of animation\n\n# Save the animation\nimage_write(animation, path = \"drug_cases_animation.gif\")\n\n# Print confirmation that the GIF was saved\nprint(\"Spatio-temporal KDE animation saved as spatio_temporal_kde_animation.gif\")\n\n\n# Display the GIF using magick\ngif_image &lt;- image_read(\"drug_cases_animation.gif\")\nprint(gif_image) \n\n\n# Plot each map in the list\nfor (year in years_to_plot) {\n  print(map_list[[as.character(year)]])\n}"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#top-bottom-10-drug-abuse-provinces",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#top-bottom-10-drug-abuse-provinces",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Top /Bottom 10 Drug Abuse Provinces",
    "text": "Top /Bottom 10 Drug Abuse Provinces\n\n# Loop through each year and plot top 10 provinces\nyears_to_plot &lt;- unique(summary_stats$year)\n\n\nTop 10 Drug Abuse ProvincesBottom 10 Drug Abuse Provinces\n\n\n\ntop_10_plot_list &lt;- list()\n\n# Loop through each year and create the plots for top 10\nfor (current_year in years_to_plot) {\n  # Filter and sort the data for the specific year\n  top_10_year_data &lt;- summary_stats %&gt;%\n    filter(year == current_year) %&gt;%\n    arrange(desc(total_cases)) %&gt;%\n    head(10)\n  \n  # Create the plot for the current year\n  top_10_plot &lt;- ggplot(top_10_year_data, aes(x = reorder(province_name, total_cases), y = total_cases)) +\n    geom_bar(stat = \"identity\", fill = \"pink\", width = 0.8) +\n    coord_flip() +\n    labs(x = NULL, y = NULL, subtitle = paste(\"Year:\", current_year)) +\n    scale_y_continuous(labels = scales::comma_format(accuracy = 1)) +\n    theme_minimal(base_size = 10) +\n    geom_text(aes(label = total_cases),\n              position = position_stack(vjust = 0.5),   \n              color = \"black\", \n              size = 3) +\n    theme(axis.text.x = element_blank(),   # Hide the y-axis text\n          axis.ticks.x = element_blank())  # Hide the y-axis ticks\n  \n  # Add the plot to the list\n  top_10_plot_list[[as.character(current_year)]] &lt;- top_10_plot\n}\n\n# Combine the top 10 plots into a grid\ncombined_top_10_plot &lt;- wrap_plots(top_10_plot_list)\n\n# Add a single title to the combined plot\ncombined_top_10_plot_with_title &lt;- combined_top_10_plot +\n  plot_annotation(title = \"Top 10 Provinces by Total Drug Abuse Cases Over the Years\")\n\n# Print the combined plot\nprint(combined_top_10_plot_with_title)\n\n\n\n\n\n\n\n\n\n\n\n# Create a list to store the bottom 10 plots\nbottom_10_plot_list &lt;- list()\n\n# Loop through each year and create the plots for bottom 10\nfor (current_year in years_to_plot) {\n  # Filter and sort the data for the specific year to get the bottom 10\n  bottom_10_year_data &lt;- summary_stats %&gt;%\n    filter(year == current_year) %&gt;%\n    arrange(total_cases) %&gt;%   # Ascending order to get bottom cases\n    head(10)\n  \n  # Create the plot for the current year\n  bottom_10_plot &lt;- ggplot(bottom_10_year_data, aes(x = reorder(province_name, -total_cases), y = total_cases)) +\n    geom_bar(stat = \"identity\", fill = \"steelblue\", width = 0.8) +\n    coord_flip() +\n    labs(x = NULL, y = NULL, subtitle = paste(\"Year:\", current_year)) +  # Subtitle to display year\n    scale_y_continuous(labels = scales::comma_format(accuracy = 1)) +\n    theme_minimal(base_size = 10) +\n    geom_text(aes(label = total_cases),\n              position = position_stack(vjust = 0.5),   \n              color = \"black\", \n              size = 3) +\n    theme(axis.text.x = element_blank(),   # Hide the y-axis text\n          axis.ticks.x = element_blank())  # Hide the y-axis ticks\n  \n  # Add the plot to the list\n  bottom_10_plot_list[[as.character(current_year)]] &lt;- bottom_10_plot\n}\n\n# Combine the bottom 10 plots into a grid\ncombined_bottom_10_plot &lt;- wrap_plots(bottom_10_plot_list)\n\n# Add a single title to the combined plot\ncombined_bottom_10_plot_with_title &lt;- combined_bottom_10_plot +\n  plot_annotation(title = \"Bottom 10 Provinces by Total Drug Abuse Cases Over the Years\")\n\n# Print the combined plot\nprint(combined_bottom_10_plot_with_title)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#top-bottom-10-related-drug-incidents-provinces",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#top-bottom-10-related-drug-incidents-provinces",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Top /Bottom 10 Related-Drug Incidents Provinces",
    "text": "Top /Bottom 10 Related-Drug Incidents Provinces\n\n# Loop through each year and plot top 10 provinces\nyears_to_plot &lt;- unique(summary_stats$year)\n\n\nTop 10 Drug Abuse ProvincesBottom 10 Drug Abuse Provinces\n\n\n\ntop_10_plot_list &lt;- list()\n\n# Loop through each year and create the plots for top 10\nfor (current_year in years_to_plot) {\n  # Filter and sort the data for the specific year\n  top_10_year_data &lt;- summary_stats %&gt;%\n    filter(year == current_year) %&gt;%\n    arrange(desc(total_cases)) %&gt;%\n    head(10)\n  \n  # Create the plot for the current year\n  top_10_plot &lt;- ggplot(top_10_year_data, aes(x = reorder(province_name, total_cases), y = total_cases)) +\n    geom_bar(stat = \"identity\", fill = \"pink\", width = 0.8) +\n    coord_flip() +\n    labs(x = NULL, y = NULL, subtitle = paste(\"Year:\", current_year)) +\n    scale_y_continuous(labels = scales::comma_format(accuracy = 1)) +\n    theme_minimal(base_size = 10) +\n    geom_text(aes(label = total_cases),\n              position = position_stack(vjust = 0.5),   \n              color = \"black\", \n              size = 3) +\n    theme(axis.text.x = element_blank(),   # Hide the y-axis text\n          axis.ticks.x = element_blank())  # Hide the y-axis ticks\n  \n  # Add the plot to the list\n  top_10_plot_list[[as.character(current_year)]] &lt;- top_10_plot\n}\n\n# Combine the top 10 plots into a grid\ntop_10_plot_list &lt;- wrap_plots(top_10_plot_list)\n\n# Add a single title to the combined plot\ntop_10_plot_list &lt;- top_10_plot_list +\n  plot_annotation(title = \"Top 10 Provinces by Total Drug Abuse Cases Over the Years\")\n\nwrite_rds(top_10_plot_list, \"data/rds/top_10_plot_list.rds\")\n\n\nprint(read_rds(\"data/rds/top_10_plot_list.rds\"))\n\n\n\n\n\n\n\n\n\n\n\n# Create a list to store the bottom 10 plots\nbottom_10_plot_list &lt;- list()\n\n# Loop through each year and create the plots for bottom 10\nfor (current_year in years_to_plot) {\n  # Filter and sort the data for the specific year to get the bottom 10\n  bottom_10_year_data &lt;- summary_stats %&gt;%\n    filter(year == current_year) %&gt;%\n    arrange(total_cases) %&gt;%   # Ascending order to get bottom cases\n    head(10)\n  \n  # Create the plot for the current year\n  bottom_10_plot &lt;- ggplot(bottom_10_year_data, aes(x = reorder(province_name, -total_cases), y = total_cases)) +\n    geom_bar(stat = \"identity\", fill = \"steelblue\", width = 0.8) +\n    coord_flip() +\n    labs(x = NULL, y = NULL, subtitle = paste(\"Year:\", current_year)) +  # Subtitle to display year\n    scale_y_continuous(labels = scales::comma_format(accuracy = 1)) +\n    theme_minimal(base_size = 10) +\n    geom_text(aes(label = total_cases),\n              position = position_stack(vjust = 0.5),   \n              color = \"black\", \n              size = 3) +\n    theme(axis.text.x = element_blank(),   # Hide the y-axis text\n          axis.ticks.x = element_blank())  # Hide the y-axis ticks\n  \n  # Add the plot to the list\n  bottom_10_plot_list[[as.character(current_year)]] &lt;- bottom_10_plot\n}\n\n# Combine the bottom 10 plots into a grid\nbottom_10_plot_list &lt;- wrap_plots(bottom_10_plot_list)\n\n# Add a single title to the combined plot\nbottom_10_plot_list &lt;- bottom_10_plot_list +\n  plot_annotation(title = \"Bottom 10 Provinces by Total Drug Abuse Cases Over the Years\")\n\nwrite_rds(bottom_10_plot_list, \"data/rds/bottom_10_plot_list.rds\")\n\n\nprint(read_rds(\"data/rds/bottom_10_plot_list.rds\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#an-initial-overview",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#an-initial-overview",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2017: An Initial Overview",
    "text": "2017: An Initial Overview\n\nGlobal Moran’ I\n\nComputing Global Moran’ IPerforming Global Moran’s I testPerforming Global Moran’s I permutation test (Monte Carlo)\n\n\n\nmoranI_2017 &lt;- global_moran(wm_q_2017$total_cases,\n                       wm_q_2017$nb,\n                       wm_q_2017$wt)\n\nWarning in lag.listw(listw, z, zero.policy = zero.policy, NAOK = NAOK): NAs in\nlagged values\n\nglimpse(moranI_2017)\n\nList of 2\n $ I: num NA\n $ K: num 31.4\n\n\n\n\n\nglobal_moran_test(wm_q_2017$total_cases,\n                  wm_q_2017$nb,\n                  wm_q_2017$wt,\n                  zero.policy = TRUE)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 2.4598, p-value = 0.006951\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.133140650      -0.013333333       0.003545946 \n\n\n\n\n\n\n\n\nNote\n\n\n\nMoran I statistic (0.133140650) -&gt; indicates a positive correlation in the variable of interest (e.g., total cases).\nSD of 2.4598 -&gt; suggests that Moran’s I is greater than the expected value under the null hypothesis.\nP-value of 0.006951 -&gt; is &lt; 0.05, indicating strong statistical significance.\nExpectation of -0.013333333 -&gt; suggests we would expect slight negative autocorrelation if there were no spatial structure.\nSince the p-value &lt; 0.05, we reject the null hypothesis of no spatial autocorrelation. This strongly suggests there is significant positive spatial clustering of the variable in the study area (regions with high values are near areas with high values).\n\n\n\n\n\nset.seed(1234)\n\nglobal_moran_perm_result_2017 &lt;- global_moran_perm(wm_q_2017$total_cases,\n                                              wm_q_2017$nb,\n                                              wm_q_2017$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2017\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.13314, observed rank = 98, p-value = 0.04\nalternative hypothesis: two.sided\n\n\n\nsummary(global_moran_perm_result_2017$res)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-0.151935 -0.056539 -0.030537 -0.018749  0.008258  0.162326 \n\n\n\npng(\"data/rds/global_moran_perm_result_2017.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values &lt;- global_moran_perm_result_2017$res\n\nglobal_moran_perm_hist_2017 &lt;- hist(simulated_values, \n                                    freq=TRUE, \n                                    breaks=20, \n                                    xlab=\"Simulated Moran's I in 2017\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/global_moran_perm_result_2017.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo ensure our results are accurate, we’ll perform a Monte Carlo (permutation) test on Moran’s I statistic. This method helps us understand if the observed clustering of values is statistically significant.\nFirst, we set the seed using set.seed(1234). This step is crucial because it guarantees that our simulation results will be reproducible. Every time we run the simulation, we should get the same outcomes, which is important for consistency in our analysis.\nNow, looking at the results from our permutation test:\n\nMoran’s I statistic: 0.13314\nObserved rank: 98\nP-value: 0.04\n\nThe p-value being less than 0.05 tells us that there’s strong statistical evidence against the null hypothesis of no spatial autocorrelation. This means we can conclude there’s significant positive spatial clustering in our data—areas with high values are near other areas with high values.\nLooking at the summary of the simulated statistics, with the maximum being 0.162326 and the minimum at -0.151935. The distribution of these values helps us understand the expected behavior of our statistic under the null hypothesis.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt’s important to note that some areas may have no neighboring regions, which results in null weights. To address this, we use zero.policy = TRUE in our analysis, allowing regions with no neighbors to be included without causing errors in calculations.\nHowever, it’s essential to understand that Global Moran’s I does not accommodate regions without neighbors in its calculations, meaning that these regions, even when included, will not contribute to the overall assessment of spatial autocorrelation.\nConsequently, regions with null weights may still affect the results, leading to potential skewing of the analysis and limiting its interpretability. Therefore, careful consideration of how to handle such regions is crucial for ensuring accurate spatial analysis."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-across-time-span-2017-2022",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-across-time-span-2017-2022",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Visualising across time span (2017-2022)",
    "text": "Visualising across time span (2017-2022)\n\n2018 Global Moran’ I2019 Global Moran’ I2020 Global Moran’ I2021 Global Moran’ I2022 Global Moran’ I\n\n\n\nPerforming Global Moran’s I permutation test (Monte Carlo)\n\nset.seed(1234)\n\nglobal_moran_perm_result_2018 &lt;- global_moran_perm(wm_q_2018$total_cases,\n                                              wm_q_2018$nb,\n                                              wm_q_2018$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2018\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.11637, observed rank = 96, p-value = 0.08\nalternative hypothesis: two.sided\n\n\n\nsummary(global_moran_perm_result_2018$res)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.13864 -0.06366 -0.02856 -0.01870  0.02001  0.17737 \n\n\n\npng(\"data/rds/global_moran_perm_result_2018.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values &lt;- global_moran_perm_result_2018$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2018\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/global_moran_perm_result_2018.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nPerforming Global Moran’s I permutation test (Monte Carlo)\n\nset.seed(1234)\n\nglobal_moran_perm_result_2019 &lt;- global_moran_perm(wm_q_2019$total_cases,\n                                              wm_q_2019$nb,\n                                              wm_q_2019$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2019\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.15541, observed rank = 98, p-value = 0.04\nalternative hypothesis: two.sided\n\n\n\nsummary(global_moran_perm_result_2019$res)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.14482 -0.06808 -0.02675 -0.01963  0.01235  0.19844 \n\n\n\npng(\"data/rds/global_moran_perm_result_2019.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values &lt;- global_moran_perm_result_2019$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2019\")\nabline(v=0, \n       col=\"red\") \n\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/global_moran_perm_result_2019.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nPerforming Global Moran’s I permutation test (Monte Carlo)\n\nset.seed(1234)\n\nglobal_moran_perm_result_2020 &lt;- global_moran_perm(wm_q_2020$total_cases,\n                                              wm_q_2020$nb,\n                                              wm_q_2020$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2020\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.1296, observed rank = 97, p-value = 0.06\nalternative hypothesis: two.sided\n\n\n\nsummary(global_moran_perm_result_2020$res)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-0.152560 -0.076142 -0.031856 -0.026822  0.006521  0.194366 \n\n\n\npng(\"data/rds/global_moran_perm_result_2020.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values &lt;- global_moran_perm_result_2020$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2020\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/global_moran_perm_result_2020.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nPerforming Global Moran’s I permutation test (Monte Carlo)\n\nset.seed(1234)\n\nglobal_moran_perm_result_2021 &lt;- global_moran_perm(wm_q_2021$total_cases,\n                                              wm_q_2021$nb,\n                                              wm_q_2021$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2021\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.19889, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\nsummary(global_moran_perm_result_2021$res)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.17499 -0.08997 -0.02457 -0.02653  0.02894  0.19889 \n\n\n\npng(\"data/rds/global_moran_perm_result_2021.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values &lt;- global_moran_perm_result_2021$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2021\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off() \n\n\nimage_read(\"data/rds/global_moran_perm_result_2021.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nPerforming Global Moran’s I permutation test (Monte Carlo)\n\nset.seed(1234)\n\nglobal_moran_perm_result_2022 &lt;- global_moran_perm(wm_q_2022$total_cases,\n                                              wm_q_2022$nb,\n                                              wm_q_2022$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2022\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.20113, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\nsummary(global_moran_perm_result_2022$res)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.17928 -0.09257 -0.03519 -0.02521  0.03933  0.20113 \n\n\n\npng(\"data/rds/global_moran_perm_result_2022.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values &lt;- global_moran_perm_result_2022$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2022\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/global_moran_perm_result_2022.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe results indicate a general trend of positive spatial autocorrelation from 2017 to 2022, with significant clustering observed in 2021 and 2022.\nThe years 2017, 2019, 2021, and 2022 show statistically significant evidence of clustering, while 2018 and 2020 have lower evidence of spatial correlation.\nThis trend suggests that the variable of interest tends to cluster in certain areas, particularly from 2021 onwards, which may warrant further investigation into the factors driving this clustering.\n\n\n\n\n# Get a list of image files in the specified directory\nglobal_moran_perm_result_files &lt;- list.files(\"data/rds/\", pattern = \"\\\\.png$\", full.names = TRUE)\n\n# Load saved images and combine them into an animated GIF\nglobal_moran_images &lt;- lapply(global_moran_perm_result_files, image_read)\n\n# Create an animation from the Global Moran's images\nglobal_moran_animation &lt;- image_animate(image_join(global_moran_images), fps = 1)\n\n# Save the animation as a GIF file\nimage_write(global_moran_animation, path = \"data/rds/global_moran_animation.gif\")\n\n\nimage_read(\"data/rds/global_moran_animation.gif\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-local-morans-i",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-local-morans-i",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Computing Local Moran’s I",
    "text": "Computing Local Moran’s I\n\nlisa_2017 &lt;- wm_q_2017 %&gt;% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %&gt;% \n  unnest(local_moran)\n\nlisa_2018 &lt;- wm_q_2018 %&gt;% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %&gt;% \n  unnest(local_moran)\n\nlisa_2019 &lt;- wm_q_2019 %&gt;% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %&gt;% \n  unnest(local_moran)\n\nlisa_2020 &lt;- wm_q_2020 %&gt;% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %&gt;% \n  unnest(local_moran)\n\nlisa_2021 &lt;- wm_q_2021 %&gt;% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %&gt;% \n  unnest(local_moran)\n\nlisa_2022 &lt;- wm_q_2022 %&gt;% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %&gt;% \n  unnest(local_moran)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-local-morans-i-vs-p-value",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-local-morans-i-vs-p-value",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Visualising Local Moran’s I VS P-Value",
    "text": "Visualising Local Moran’s I VS P-Value\n\n201720182019202020212022\n\n\n\npng(\"data/rds/local_moran_vs_pvalue_map_2017.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2017 &lt;- tm_shape(lisa_2017) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2017\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2017 &lt;- tm_shape(lisa_2017) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2017\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2017, local_moran_pvalue_map_2017, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2017.png\")\n\n\n\n\n\n\n\n\n\n\n\npng(\"data/rds/local_moran_vs_pvalue_map_2018.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2018 &lt;- tm_shape(lisa_2018) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2018\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2018 &lt;- tm_shape(lisa_2018) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2018\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2018, local_moran_pvalue_map_2018, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2018.png\")\n\n\n\n\n\n\n\n\n\n\n\npng(\"data/rds/local_moran_vs_pvalue_map_2019.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2019 &lt;- tm_shape(lisa_2019) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2019\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2019 &lt;- tm_shape(lisa_2019) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2019\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2019, local_moran_pvalue_map_2019, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2019.png\")\n\n\n\n\n\n\n\n\n\n\n\npng(\"data/rds/local_moran_vs_pvalue_map_2020.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2020 &lt;- tm_shape(lisa_2020) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2020\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2020 &lt;- tm_shape(lisa_2020) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2020\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2020, local_moran_pvalue_map_2020, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2020.png\")\n\n\n\n\n\n\n\n\n\n\n\npng(\"data/rds/local_moran_vs_pvalue_map_2021.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2021 &lt;- tm_shape(lisa_2021) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2021\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2021 &lt;- tm_shape(lisa_2021) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2021\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2021, local_moran_pvalue_map_2021, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2021.png\")\n\n\n\n\n\n\n\n\n\n\n\npng(\"data/rds/local_moran_vs_pvalue_map_2022.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2022 &lt;- tm_shape(lisa_2022) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2022\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2022 &lt;- tm_shape(lisa_2022) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2022\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2022, local_moran_pvalue_map_2022, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2022.png\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-lisa-map",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-lisa-map",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Visualising LISA Map",
    "text": "Visualising LISA Map\n\n201720182019202020212022\n\n\n\nComputing Local Moran’s I\n\nlisa_2017 &lt;- wm_q_2017 %&gt;% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %&gt;% \n  unnest(local_moran)\n\n\n\nLocal Moran’s I VS P-Value\n\npng(\"data/rds/local_moran_vs_pvalue_map_2017.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2017 &lt;- tm_shape(lisa_2017) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2017\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2017 &lt;- tm_shape(lisa_2017) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (&lt; 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (&gt; 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2017\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2017, local_moran_pvalue_map_2017, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2017.png\")\n\n\n\n\n\n\n\n\n\n\nPutting together\n\npng(\"data/rds/lisa_map_2017.png\", width = 1600, height = 1200)\n\nlisa_sig_2017 &lt;- lisa_2017  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2017) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2017) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2017\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/lisa_map_2017.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nComputing Local Moran’s I\n\nlisa_2018 &lt;- wm_q_2018 %&gt;% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %&gt;% \n  unnest(local_moran)\n\n\n\nLocal Moran’s I VS P-Value\n\npng(\"data/rds/local_moran_vs_pvalue_map_2018.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2018 &lt;- tm_shape(lisa_2018) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2018\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2018 &lt;- tm_shape(lisa_2018) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (&lt; 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (&gt; 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2018\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2018, local_moran_pvalue_map_2018, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2018.png\")\n\n\n\n\n\n\n\n\n\n\nPutting together\n\npng(\"data/rds/lisa_map_2018.png\", width = 1600, height = 1200)\n\nlisa_sig_2018 &lt;- lisa_2018  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2018) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2018) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2018\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/lisa_map_2018.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nComputing Local Moran’s I\n\nlisa_2019 &lt;- wm_q_2019 %&gt;% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %&gt;% \n  unnest(local_moran)\n\n\n\nLocal Moran’s I VS P-Value\n\npng(\"data/rds/local_moran_vs_pvalue_map_2019.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2019 &lt;- tm_shape(lisa_2019) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2019\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2019 &lt;- tm_shape(lisa_2019) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (&lt; 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (&gt; 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2019\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2019, local_moran_pvalue_map_2019, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2019.png\")\n\n\n\n\n\n\n\n\n\n\nPutting together\n\npng(\"data/rds/lisa_map_2019.png\", width = 1600, height = 1200)\n\nlisa_sig_2019 &lt;- lisa_2019  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2019) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2019) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2019\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/lisa_map_2019.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nComputing Local Moran’s I\n\nlisa_2020 &lt;- wm_q_2020 %&gt;% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %&gt;% \n  unnest(local_moran)\n\n\n\nLocal Moran’s I VS P-Value\n\npng(\"data/rds/local_moran_vs_pvalue_map_2020.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2020 &lt;- tm_shape(lisa_2020) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2020\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2020 &lt;- tm_shape(lisa_2020) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (&lt; 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (&gt; 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2020\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2020, local_moran_pvalue_map_2020, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2020.png\")\n\n\n\n\n\n\n\n\n\n\nPutting together\n\npng(\"data/rds/lisa_map_2020.png\", width = 1600, height = 1200)\n\nlisa_sig_2020 &lt;- lisa_2020  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2020) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2020) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2020\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/lisa_map_2020.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nComputing Local Moran’s I\n\nlisa_2021 &lt;- wm_q_2021 %&gt;% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %&gt;% \n  unnest(local_moran)\n\n\n\nLocal Moran’s I VS P-Value\n\npng(\"data/rds/local_moran_vs_pvalue_map_2021.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2021 &lt;- tm_shape(lisa_2021) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2021\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2021 &lt;- tm_shape(lisa_2021) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (&lt; 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (&gt; 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2021\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2021, local_moran_pvalue_map_2021, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2021.png\")\n\n\n\n\n\n\n\n\n\n\nPutting together\n\npng(\"data/rds/lisa_map_2021.png\", width = 1600, height = 1200)\n\nlisa_sig_2021 &lt;- lisa_2021  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2021) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2021) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2021\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/lisa_map_2021.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nComputing Local Moran’s I\n\nlisa_2022 &lt;- wm_q_2022 %&gt;% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %&gt;% \n  unnest(local_moran)\n\n\n\nLocal Moran’s I VS P-Value\n\npng(\"data/rds/local_moran_vs_pvalue_map_2022.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2022 &lt;- tm_shape(lisa_2022) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2022\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2022 &lt;- tm_shape(lisa_2022) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (&lt; 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (&gt; 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2022\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2022, local_moran_pvalue_map_2022, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2022.png\")\n\n\n\n\n\n\n\n\n\n\nPutting together\n\npng(\"data/rds/lisa_map_2022.png\", width = 1600, height = 1200)\n\nlisa_sig_2022 &lt;- lisa_2022  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2022) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2022) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2022\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/lisa_map_2022.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nComputing Local Moran’s I\nadd new column [local_moran] -&gt; stores the calculated Local Moran’s I values\nzero.policy = TRUE option allows the method to handle regions without neighbors appropriately.\nunnest(local_moran) -&gt; flatten the results, simplifying further analysis of the output.\nLocal Moran’s I VS P-Value Visualization\nThis segment creates visualizations for the Local Moran’s I statistic and its associated p-values for the year 2017\nLocal Moran’s I values (color-coded) indicating spatial clustering: Ranges from -1.0 (cold spots) to 3.0 (strong hot spots). Provides insights into areas of similar or dissimilar values in case distribution.\nP-Value Map:\nIllustrates the statistical significance of Local Moran’s I: Breaks defined for p-values (&lt; 0.001, 0.001-0.01, 0.01-0.05, &gt; 0.05).\nPutting Together Significant LISA Results\nThis segment visualizes the significant clusters identified by the Local Moran’s I analysis.\nThe visualization includes both all regions and the significant clusters, with the latter highlighted based on their mean Local Moran’s I values.\n\nLow-Low (LL)\n\n\nDefinition: Areas with low values surrounded by other low-value areas.\nInterpretation: Indicates regions that are underperforming or stable and may not need immediate intervention.\n\n\nHigh-Low (HL)\n\n\nDefinition: Areas with high values surrounded by low-value areas.\nInterpretation: Highlights potential hotspots that require further investigation or targeted intervention.\n\n\nLow-High (LH)\n\n\nDefinition: Areas with low values surrounded by high-value areas.\nInterpretation: Suggests vulnerability to spillover effects from neighboring high-value regions, requiring monitoring.\n\n\nHigh-High (HH)\n\n\nDefinition: Areas with high values surrounded by other high-value areas.\nInterpretation: Identifies significant hotspots that may need immediate attention and indicate systemic issues."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-across-time-span-2017-2022-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-across-time-span-2017-2022-1",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Visualising across time span (2017-2022)",
    "text": "Visualising across time span (2017-2022)\n\n# Get a list of image files in the specified directory for LISA maps\nlisa_map_files &lt;- list.files(\"data/rds/\", pattern = \"lisa_map_\\\\d{4}\\\\.png$\", full.names = TRUE)\n\n# Load saved images and combine them into an animated GIF\nlisa_images &lt;- lapply(lisa_map_files, image_read)\n\n# Create an animation from the LISA map images\nlisa_animation &lt;- image_animate(image_join(lisa_images), fps = 1)\n\n# Save the animation as a GIF file\nimage_write(lisa_animation, path = \"data/rds/lisa_animation.gif\")\n\n\nimage_read(\"data/rds/lisa_animation.gif\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#hot-spot-cold-spot-area-analysis-hcsa",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#hot-spot-cold-spot-area-analysis-hcsa",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Hot Spot & Cold Spot Area Analysis (HCSA)",
    "text": "Hot Spot & Cold Spot Area Analysis (HCSA)\n\n201720182019202020212022\n\n\n\nComputing local Gi* statistics\n\nHCSA_2017 &lt;- wm_q_2017 %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\n\nGi* VS P-Value\n\npng(\"data/rds/gistar_vs_pvalue_map_2017.png\", width = 1600, height = 1200)\n\ngi_star_2017 &lt;- tm_shape(HCSA_2017) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2017\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2017 &lt;- tm_shape(HCSA_2017) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2017\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2017, gi_star_pvalue_2017, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/gistar_vs_pvalue_map_2017.png\")\n\n\n\n\n\n\n\n\n\n\nPutting together\n\npng(\"data/rds/hcsa_map_2017.png\", width = 1600, height = 1200)\n\nHCSA_sig_2017 &lt;- HCSA_2017  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2017) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2017) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2017\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/hcsa_map_2017.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nComputing local Gi* statistics\n\nHCSA_2018 &lt;- wm_q_2018 %&gt;%    \n  mutate(local_Gi = local_gstar_perm(     \n    total_cases, nb, wts, nsim = 99),          \n    .before = 1) %&gt;%   \n  unnest(local_Gi)\n\n\n\nVisualising Hot Spot & Cold Spot (HCSA)\n\npng(\"data/rds/gistar_vs_pvalue_map_2018.png\", width = 1600, height = 1200)\n\ngi_star_2018 &lt;- tm_shape(HCSA_2018) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2018\",\n            main.title.size = 0.8)\n\ngi_star_pvalue_2018 &lt;- tm_shape(HCSA_2018) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2018\",\n            main.title.size = 0.8)\n\ntmap_arrange(gi_star_2018, gi_star_pvalue_2018, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/gistar_vs_pvalue_map_2018.png\")\n\n\n\n\n\n\n\n\n\n\nPutting together\n\npng(\"data/rds/hcsa_map_2018.png\", width = 1600, height = 1200)\n\nHCSA_sig_2018 &lt;- HCSA_2018  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2018) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2018) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2018\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/hcsa_map_2018.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nComputing local Gi* statistics\n\nHCSA_2019 &lt;- wm_q_2019 %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\n\nGi* VS P-Value\n\npng(\"data/rds/gistar_vs_pvalue_map_2019.png\", width = 1600, height = 1200)\n\ngi_star_2019 &lt;- tm_shape(HCSA_2019) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2019\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2019 &lt;- tm_shape(HCSA_2019) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2019\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2019, gi_star_pvalue_2019, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/gistar_vs_pvalue_map_2019.png\")\n\n\n\n\n\n\n\n\n\n\nPutting together\n\npng(\"data/rds/hcsa_map_2019.png\", width = 1600, height = 1200)\n\nHCSA_sig_2019 &lt;- HCSA_2019  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2019) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2019) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2019\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/hcsa_map_2019.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nComputing local Gi* statistics\n\nHCSA_2020 &lt;- wm_q_2020 %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\n\nGi* VS P-Value\n\npng(\"data/rds/gistar_vs_pvalue_map_2020.png\", width = 1600, height = 1200)\n\ngi_star_2020 &lt;- tm_shape(HCSA_2020) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2020\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2020 &lt;- tm_shape(HCSA_2020) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2020\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2020, gi_star_pvalue_2020, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/gistar_vs_pvalue_map_2020.png\")\n\n\n\n\n\n\n\n\n\n\nPutting together\n\npng(\"data/rds/hcsa_map_2020.png\", width = 1600, height = 1200)\n\nHCSA_sig_2020 &lt;- HCSA_2020  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2020) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2020) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2020\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/hcsa_map_2020.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nComputing local Gi* statistics\n\nHCSA_2021 &lt;- wm_q_2021 %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\n\nGi* VS P-Value\n\npng(\"data/rds/gistar_vs_pvalue_map_2021.png\", width = 1600, height = 1200)\n\ngi_star_2021 &lt;- tm_shape(HCSA_2021) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2021\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2021 &lt;- tm_shape(HCSA_2021) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2021\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2021, gi_star_pvalue_2021, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/gistar_vs_pvalue_map_2021.png\")\n\n\n\n\n\n\n\n\n\n\nPutting together\n\npng(\"data/rds/hcsa_map_2021.png\", width = 1600, height = 1200)\n\nHCSA_sig_2021 &lt;- HCSA_2021  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2021) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2021) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2021\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/hcsa_map_2021.png\")\n\n\n\n\n\n\n\n\n\n\n\n\nComputing local Gi* statistics\n\nHCSA_2022 &lt;- wm_q_2022 %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\n\n\nGi* VS P-Value\n\npng(\"data/rds/gistar_vs_pvalue_map_2022.png\", width = 1600, height = 1200)\n\ngi_star_2022 &lt;- tm_shape(HCSA_2022) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2022\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2022 &lt;- tm_shape(HCSA_2022) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2022\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2022, gi_star_pvalue_2022, ncol = 2)\n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/gistar_vs_pvalue_map_2022.png\")\n\n\n\n\n\n\n\n\n\n\nPutting together\n\npng(\"data/rds/hcsa_map_2022.png\", width = 1600, height = 1200)\n\nHCSA_sig_2022 &lt;- HCSA_2022  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2022) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2022) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2022\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n\n\nimage_read(\"data/rds/hcsa_map_2022.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary of Gi* and P-Value Analysis\n\n\n\n\nGi Statistic (Hot Spot & Cold Spot Analysis)*\n\nThe Gi statistic* is calculated to identify clusters of high or low values of total cases in a given area.\nIt measures whether the number of cases in a location is significantly higher (hot spot) or lower (cold spot) than would be expected by random distribution.\n\nP-Value of Gi Statistic*\n\nThe p-value determines the statistical significance of the observed clusters (hot or cold spots).\nA low p-value (&lt; 0.05) suggests that the cluster is unlikely to have occurred by chance, while a higher p-value indicates randomness in the observed pattern.\n\nPurpose of Both Analyses\n\nGi of Total Cases* map visually displays the clustering of total cases.\nP-Value of Gi* map helps verify whether the identified clusters are statistically significant or if they might be due to random variation.\n\n\nThese two analyses together provide a clear picture of where significant hot or cold spots are and how reliable these findings are. This ensures any conclusions drawn about spatial patterns are both visualized and statistically validated."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-lisa-map-across-time-span-2017-2022",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-lisa-map-across-time-span-2017-2022",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Visualising LISA map across time span (2017-2022)",
    "text": "Visualising LISA map across time span (2017-2022)\n\n# Get a list of image files in the specified directory for LISA maps\nlisa_map_files &lt;- list.files(\"data/rds/\", pattern = \"lisa_map_\\\\d{4}\\\\.png$\", full.names = TRUE)\n\n# Load saved images and combine them into an animated GIF\nlisa_images &lt;- lapply(lisa_map_files, image_read)\n\n# Create an animation from the LISA map images\nlisa_animation &lt;- image_animate(image_join(lisa_images), fps = 1)\n\n# Save the animation as a GIF file\nimage_write(lisa_animation, path = \"data/rds/lisa_animation.gif\")\n\n\nimage_read(\"data/rds/lisa_animation.gif\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-hcsa-map-across-time-span-2017-2022",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-hcsa-map-across-time-span-2017-2022",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Visualising HCSA map across time span (2017-2022)",
    "text": "Visualising HCSA map across time span (2017-2022)\n\n# Get a list of image files in the specified directory for HCSA maps\nhcsa_map_files &lt;- list.files(\"data/rds/\", pattern = \"hcsa_map_\\\\d{4}\\\\.png$\", full.names = TRUE)\n\n# Load saved images and combine them into an animated GIF\nhcsa_images &lt;- lapply(hcsa_map_files, image_read)\n\n# Create an animation from the HCSA map images\nhcsa_animation &lt;- image_animate(image_join(hcsa_images), fps = 1)\n\n# Save the animation as a GIF file\nimage_write(hcsa_animation, path = \"data/rds/hcsa_animation.gif\")\n\n\nimage_read(\"data/rds/hcsa_animation.gif\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#province-trends",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#province-trends",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Province Trends",
    "text": "Province Trends\n\nIncreasing TrendsDecreasing TrendsStable\n\n\n\nincreasing_trends &lt;- trend_results %&gt;%\n  filter(trend_status == \"Increasing\") %&gt;%\n  pull(province_name)\n\nwrite_rds(increasing_trends, \"data/rds/increasing_trends.rds\")\n\n\nincreasing_trends &lt;- read_rds(\"data/rds/increasing_trends.rds\")\n\n# Check if increasing_trends is null or empty and set a default message\nif (is.null(increasing_trends) || length(increasing_trends) == 0) {\n  result &lt;- \"NIL\"\n} else {\n  result &lt;- paste(increasing_trends, collapse = \", \")\n}\n\n# Print the result\ncat(result, \"\\n\")\n\nBueng Kan, Lampang, Mae Hong Son, Maha Sarakham, Roi Et, Sakon Nakhon, Udon Thani \n\n\n\n\n\ndecreasing_trends &lt;- trend_results %&gt;%\n  filter(trend_status == \"Decreasing\") %&gt;%\n  pull(province_name)\n\nwrite_rds(decreasing_trends, \"data/rds/decreasing_trends.rds\")\n\n\ndecreasing_trends &lt;- read_rds(\"data/rds/decreasing_trends.rds\")\n\n# Check if decreasing_trends is null or empty and set a default message\nif (is.null(decreasing_trends) || length(decreasing_trends) == 0) {\n  result &lt;- \"NIL\"\n} else {\n  result &lt;- paste(decreasing_trends, collapse = \", \")\n}\n\n# Print the result\ncat(result, \"\\n\")\n\nNIL"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#provincial-trends",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#provincial-trends",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Provincial Trends",
    "text": "Provincial Trends\n\nIncreasing TrendsDecreasing TrendsStable\n\n\n\nincreasing_trends &lt;- trend_results %&gt;%\n  filter(trend_status == \"Increasing\") %&gt;%\n  pull(province_name)\n\nwrite_rds(increasing_trends, \"data/rds/increasing_trends.rds\")\n\n\nincreasing_trends &lt;- read_rds(\"data/rds/increasing_trends.rds\")\n\n# Check if increasing_trends is null or empty and set a default message\nif (is.null(increasing_trends) || length(increasing_trends) == 0) {\n  result &lt;- \"NIL\"\n} else {\n  result &lt;- paste(increasing_trends, collapse = \", \")\n}\n\ncat(result, \"\\n\")\n\nBueng Kan, Lampang, Mae Hong Son, Maha Sarakham, Roi Et, Sakon Nakhon, Udon Thani \n\n\n\n\n\ndecreasing_trends &lt;- trend_results %&gt;%\n  filter(trend_status == \"Decreasing\") %&gt;%\n  pull(province_name)\n\nwrite_rds(decreasing_trends, \"data/rds/decreasing_trends.rds\")\n\n\ndecreasing_trends &lt;- read_rds(\"data/rds/decreasing_trends.rds\")\n\n# Check if decreasing_trends is null or empty and set a default message\nif (is.null(decreasing_trends) || length(decreasing_trends) == 0) {\n  result &lt;- \"NIL\"\n} else {\n  result &lt;- paste(decreasing_trends, collapse = \", \")\n}\n\ncat(result, \"\\n\")\n\nNIL \n\n\n\n\n\nstable_trends &lt;- trend_results %&gt;%\n  filter(trend_status == \"Stable\") %&gt;%\n  pull(province_name)\n\nwrite_rds(stable_trends, \"data/rds/stable_trends.rds\")\n\n\nstable_trends &lt;- read_rds(\"data/rds/stable_trends.rds\")\n\n# Check if stable_trends is null or empty and set a default message\nif (is.null(stable_trends) || length(stable_trends) == 0) {\n  result &lt;- \"NIL\"\n} else {\n  result &lt;- paste(stable_trends, collapse = \", \")\n}\n\ncat(result, \"\\n\")\n\nAmnat Charoen, Ang Thong, Bangkok, Buri Ram, Chachoengsao, Chai Nat, Chaiyaphum, Chanthaburi, Chiang Mai, Chiang Rai, Chon Buri, Chumphon, Kalasin, Kamphaeng Phet, Kanchanaburi, Khon Kaen, Krabi, Lamphun, Loei, Lop Buri, Mukdahan, Nakhon Nayok, Nakhon Pathom, Nakhon Phanom, Nakhon Ratchasima, Nakhon Sawan, Nakhon Si Thammarat, Nan, Narathiwat, Nong Bua Lam Phu, Nong Khai, Nonthaburi, Pathum Thani, Pattani, Phangnga, Phatthalung, Phayao, Phetchabun, Phetchaburi, Phichit, Phitsanulok, Phra Nakhon Si Ayutthaya, Phrae, Phuket, Prachin Buri, Prachuap Khiri Khan, Ranong, Ratchaburi, Rayong, Sa Kaeo, Samut Prakan, Samut Sakhon, Samut Songkhram, Saraburi, Satun, Si Sa Ket, Sing Buri, Songkhla, Sukhothai, Suphan Buri, Surat Thani, Surin, Tak, Trang, Trat, Ubon Ratchathani, Uthai Thani, Uttaradit, Yala, Yasothon"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#summarize-local-morans-i-values",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#summarize-local-morans-i-values",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Summarize Local Moran’s I values",
    "text": "Summarize Local Moran’s I values\n\nsummarize_local_moran &lt;- function(data) {\n  data %&gt;%\n    summarise(\n      mean_local_moran = mean(ii, na.rm = TRUE),\n      min_local_moran = min(ii, na.rm = TRUE),\n      max_local_moran = max(ii, na.rm = TRUE),\n      sd_local_moran = sd(ii, na.rm = TRUE),\n      mean_p_value = mean(p_ii_sim, na.rm = TRUE),\n      min_p_value = min(p_ii_sim, na.rm = TRUE),\n      max_p_value = max(p_ii_sim, na.rm = TRUE),\n      count_high_high = sum(ii &gt; 0 & p_ii_sim &lt; 0.05),\n      count_low_low = sum(ii &lt; 0 & p_ii_sim &lt; 0.05),\n      count_high_low = sum(ii &gt; 0 & p_ii_sim &gt;= 0.05),\n      count_low_high = sum(ii &lt; 0 & p_ii_sim &gt;= 0.05)\n    )\n}\n\n# Apply the function to each year's dataset\nlocal_moran_summary_2017 &lt;- summarize_local_moran(lisa_2017)\nlocal_moran_summary_2018 &lt;- summarize_local_moran(lisa_2018)\nlocal_moran_summary_2019 &lt;- summarize_local_moran(lisa_2019)\nlocal_moran_summary_2020 &lt;- summarize_local_moran(lisa_2020)\nlocal_moran_summary_2021 &lt;- summarize_local_moran(lisa_2021)\nlocal_moran_summary_2022 &lt;- summarize_local_moran(lisa_2022)\n\n# Combine summaries into a single data frame\nlocal_moran_summary_all_years &lt;- bind_rows(\n  mutate(local_moran_summary_2017, year = 2017),\n  mutate(local_moran_summary_2018, year = 2018),\n  mutate(local_moran_summary_2019, year = 2019),\n  mutate(local_moran_summary_2020, year = 2020),\n  mutate(local_moran_summary_2021, year = 2021),\n  mutate(local_moran_summary_2022, year = 2022)\n)\n\nwrite_rds(local_moran_summary_all_years, \"data/rds/local_moran_summary_all_years.rds\")\n\n\nlocal_moran_summary_all_years &lt;- read_rds(\"data/rds/local_moran_summary_all_years.rds\")\n\n# Show all rows and columns\nprint(local_moran_summary_all_years, n = Inf, width = Inf)\n\nSimple feature collection with 6 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34804 ymin: 5.610305 xmax: 105.6426 ymax: 20.46352\nGeodetic CRS:  Indian 1975\n# A tibble: 6 × 13\n  mean_local_moran min_local_moran max_local_moran sd_local_moran mean_p_value\n*            &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n1            0.133          -0.706            2.56          0.384        0.425\n2            0.116          -0.854            3.40          0.447        0.442\n3            0.155          -0.845            4.73          0.608        0.428\n4            0.130          -0.768            2.48          0.493        0.455\n5            0.199          -0.943            2.62          0.505        0.412\n6            0.201          -1.37             2.14          0.540        0.454\n  min_p_value max_p_value count_high_high count_low_low count_high_low\n*       &lt;dbl&gt;       &lt;dbl&gt;           &lt;int&gt;         &lt;int&gt;          &lt;int&gt;\n1        0.02        1                  7             1             50\n2        0.02        1                  4             2             42\n3        0.02        1                  2             1             45\n4        0.02        0.94               4             0             44\n5        0.02        1                  8             1             43\n6        0.02        1                  6             3             46\n  count_low_high\n*          &lt;int&gt;\n1             18\n2             28\n3             28\n4             28\n5             24\n6             21\n                                                                        geometry\n*                                                             &lt;MULTIPOLYGON [°]&gt;\n1 (((99.56788 11.08298, 99.56778 11.08326, 99.56765 11.08338, 99.56753 11.08346…\n2 (((99.56788 11.08298, 99.56778 11.08326, 99.56765 11.08338, 99.56753 11.08346…\n3 (((99.56788 11.08298, 99.56778 11.08326, 99.56765 11.08338, 99.56753 11.08346…\n4 (((99.56788 11.08298, 99.56778 11.08326, 99.56765 11.08338, 99.56753 11.08346…\n5 (((99.56788 11.08298, 99.56778 11.08326, 99.56765 11.08338, 99.56753 11.08346…\n6 (((99.56788 11.08298, 99.56778 11.08326, 99.56765 11.08338, 99.56753 11.08346…\n   year\n* &lt;dbl&gt;\n1  2017\n2  2018\n3  2019\n4  2020\n5  2021\n6  2022\n\n\n\n\n\n\n\n\nSummary of Findings:\n\n\n\n\nMean Local Moran’s I Values:\n\nRanged from 0.116 to 0.201, indicating increasing clustering of values over time.\n\nMin/Max Local Moran’s I:\n\nMinimum values: -1.37 to -0.943 (low-value clusters).\nMaximum values: 2.14 to 4.73 (significant high-value clusters).\n\nStandard Deviation:\n\nVaried from 0.384 to 0.608, indicating differences in clustering variability across years.\n\nP-Values:\n\nMean p-values consistent at 0.412 to 0.455, with a minimum p-value of 0.02, suggesting significant clustering.\n\nCluster Counts:\n\nHigh-high clusters decreased from 7 in 2017 to 2 in 2019 but increased in later years.\nLow-low clusters remained relatively low, peaking at 3 in 2022.\n\nYearly Trends:\n\n2022 exhibited the highest mean Local Moran’s I value (0.201), indicating stronger clustering effects."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#summary-of-hcsa-value",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#summary-of-hcsa-value",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Summary of HCSA value",
    "text": "Summary of HCSA value\n\n# Function to summarize HCSA values for a given year\nsummarize_hcsa &lt;- function(data) {\n  data %&gt;%\n    summarise(\n      mean_gi_star = mean(gi_star, na.rm = TRUE),\n      min_gi_star = min(gi_star, na.rm = TRUE),\n      max_gi_star = max(gi_star, na.rm = TRUE),\n      sd_gi_star = sd(gi_star, na.rm = TRUE),\n      mean_p_value = mean(p_value, na.rm = TRUE),\n      min_p_value = min(p_value, na.rm = TRUE),\n      max_p_value = max(p_value, na.rm = TRUE),\n      count_hot_spots = sum(gi_star &gt; 0 & p_value &lt; 0.05),\n      count_cold_spots = sum(gi_star &lt; 0 & p_value &lt; 0.05),\n      count_non_significant = sum(p_value &gt;= 0.05),\n      geometry = st_union(geometry)  # Combine geometries\n    )\n}\n\n# Summarizing HCSA for each year\nhcsa_summary_2017 &lt;- summarize_hcsa(HCSA_2017)\nhcsa_summary_2018 &lt;- summarize_hcsa(HCSA_2018)\nhcsa_summary_2019 &lt;- summarize_hcsa(HCSA_2019)\nhcsa_summary_2020 &lt;- summarize_hcsa(HCSA_2020)\nhcsa_summary_2021 &lt;- summarize_hcsa(HCSA_2021)\nhcsa_summary_2022 &lt;- summarize_hcsa(HCSA_2022)\n\n\nhcsa_summary_all &lt;- bind_rows(\n  mutate(hcsa_summary_2017, year = 2017),\n  mutate(hcsa_summary_2018, year = 2018),\n  mutate(hcsa_summary_2019, year = 2019),\n  mutate(hcsa_summary_2020, year = 2020),\n  mutate(hcsa_summary_2021, year = 2021),\n  mutate(hcsa_summary_2022, year = 2022)\n)\n\nwrite_rds(hcsa_summary_all, \"data/rds/hcsa_summary_all.rds\")\n\n\nhcsa_summary_all &lt;- read_rds(\"data/rds/hcsa_summary_all.rds\")\n\n# Show all rows and columns\nprint(hcsa_summary_all, n = Inf, width = Inf)\n\nSimple feature collection with 6 features and 11 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34804 ymin: 5.610305 xmax: 105.6426 ymax: 20.46352\nGeodetic CRS:  Indian 1975\n# A tibble: 6 × 12\n  mean_gi_star min_gi_star max_gi_star sd_gi_star mean_p_value min_p_value\n*        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n1       0.0838       -1.71        4.67       1.29        0.500    7.95e-13\n2       0.0948       -1.47        4.61       1.23        0.529    6.28e-11\n3       0.0924       -1.62        4.44       1.23        0.473    3.69e- 7\n4       0.103        -1.90        3.63       1.20        0.475    1.02e- 6\n5       0.126        -2.41        3.06       1.30        0.393    7.44e- 3\n6       0.199        -2.61        3.41       1.36        0.422    1.76e- 4\n  max_p_value count_hot_spots count_cold_spots count_non_significant\n*       &lt;dbl&gt;           &lt;int&gt;            &lt;int&gt;                 &lt;int&gt;\n1       0.996              NA                0                    NA\n2       1.00               NA                0                    NA\n3       0.966              NA                0                    NA\n4       0.970              NA                0                    NA\n5       0.974              NA                3                    NA\n6       0.985               7               NA                    NA\n                                                                        geometry\n*                                                             &lt;MULTIPOLYGON [°]&gt;\n1 (((99.56788 11.08298, 99.56778 11.08326, 99.56765 11.08338, 99.56753 11.08346…\n2 (((99.56788 11.08298, 99.56778 11.08326, 99.56765 11.08338, 99.56753 11.08346…\n3 (((99.56788 11.08298, 99.56778 11.08326, 99.56765 11.08338, 99.56753 11.08346…\n4 (((99.56788 11.08298, 99.56778 11.08326, 99.56765 11.08338, 99.56753 11.08346…\n5 (((99.56788 11.08298, 99.56778 11.08326, 99.56765 11.08338, 99.56753 11.08346…\n6 (((99.56788 11.08298, 99.56778 11.08326, 99.56765 11.08338, 99.56753 11.08346…\n   year\n* &lt;dbl&gt;\n1  2017\n2  2018\n3  2019\n4  2020\n5  2021\n6  2022\n\n\n\n\n\n\n\n\nSummary of Findings:\n\n\n\n\nMean Gi Values*:\n\nIncreased from 0.0838 (2017) to 0.199 (2022), indicating more hot spots over time.\n\nGi Range*:\n\nMinimum values between -2.61 to -1.47 (cold spots) and maximum values from 3.06 to 4.67 (significant hot spots).\n\nStandard Deviation:\n\nStable variability in Gi* scores, ranging from 1.20 to 1.36.\n\nP-Values:\n\nAverage p-values between 0.393 to 0.529, suggesting many Gi* values are not statistically significant.\nMinimum p-values as low as 7.95e-13 indicate some significant hot spots.\n\nCount of Hot Spots and Cold Spots:\n\nUp to 7 hot spots in 2022; several years reported NA for cold spots, indicating few or no significant cold spots.\n\nOverall Trends:\n\nAn overall trend of increasing hot spot concentration from 2017 to 2022, suggesting growing areas affected by the phenomena studied (e.g., drug abuse, crime).\n\n\n\nConclusion\nThe HCSA findings highlight a significant rise in hot spot areas over the years, which may require targeted interventions and further investigation into the factors influencing these changes.\n\n\n\n\nlisa_animation &lt;- image_read(\"data/rds/lisa_animation.gif\")\nhcsa_animation &lt;- image_read(\"data/rds/hcsa_animation.gif\")\n\n# Ensure both animations have the same number of frames by replicating frames if needed\nlisa_frames &lt;- length(lisa_animation)\nhcsa_frames &lt;- length(hcsa_animation)\n\nif (lisa_frames != hcsa_frames) {\n  if (lisa_frames &gt; hcsa_frames) {\n    hcsa_animation &lt;- image_cycle(hcsa_animation, lisa_frames)\n  } else {\n    lisa_animation &lt;- image_cycle(lisa_animation, hcsa_frames)\n  }\n}\n\n# Convert each animation into a list of individual frames\nlisa_frames_list &lt;- as.list(lisa_animation)\nhcsa_frames_list &lt;- as.list(hcsa_animation)\n\n# Resize each frame to ensure no margins and same height\nlisa_frames_resized &lt;- lapply(lisa_frames_list, function(frame) {\n  image_scale(frame, \"800x\")  \n})\n\nhcsa_frames_resized &lt;- lapply(hcsa_frames_list, function(frame) {\n  image_scale(frame, \"800x\")  \n})\n\n# Combine corresponding frames side by side with no gaps\nside_by_side_frames &lt;- mapply(function(lisa_frame, hcsa_frame) {\n  # Use `image_append` with `stack = FALSE` for horizontal stacking\n  image_append(c(lisa_frame, hcsa_frame), stack = FALSE)\n}, lisa_frames_resized, hcsa_frames_resized, SIMPLIFY = FALSE)\n\n# Create a new animation from the combined frames\nside_by_side_animation &lt;- image_animate(image_join(side_by_side_frames), fps = 1)\n\n# Save the final combined animation\nimage_write(side_by_side_animation, path = \"data/rds/lisa_hcsa_side_by_side_animation.gif\")\n\nside_by_side_animation"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#forecast-future-values",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#forecast-future-values",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Forecast Future Values",
    "text": "Forecast Future Values\n\nlibrary(forecast)\n\n\n# Forecast case counts for each province using ARIMA for the next 5 years\narima_forecasts &lt;- list()\n\nfor (province in unique(drug_offenses_by_province$province_name)) {\n  # Filter data for the province\n  province_data &lt;- drug_offenses_by_province %&gt;%\n    filter(province_name == province) %&gt;%\n    arrange(year)\n  \n  # Create time series object for case count\n  ts_data &lt;- ts(province_data$case_count, start = min(province_data$year), frequency = 1)\n  \n  # Fit ARIMA model\n  fit &lt;- auto.arima(ts_data)\n  \n  # Forecast for the next 5 years (2023 to 2027)\n  forecasted_values &lt;- forecast(fit, h = 5)\n  \n  # Store forecast results for each year\n  arima_forecasts[[province]] &lt;- data.frame(\n    province_name = province,\n    year = 2023:2027,\n    predicted_cases = as.numeric(forecasted_values$mean)\n  )\n}\n\n# Combine forecast results for all provinces\nfuture_predictions &lt;- bind_rows(arima_forecasts)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#hotcold-spot-classification",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#hotcold-spot-classification",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Hot/Cold Spot Classification",
    "text": "Hot/Cold Spot Classification\n\n# Set thresholds for hot and cold spots (adjust based on your data)\nhot_spot_threshold &lt;- quantile(drug_offenses_by_province$case_count, 0.75)\ncold_spot_threshold &lt;- quantile(drug_offenses_by_province$case_count, 0.25)\n\n# Classify hot/cold spots based on predicted cases for each year\nfuture_predictions &lt;- future_predictions %&gt;%\n  mutate(hot_cold_label = case_when(\n    predicted_cases &gt; hot_spot_threshold ~ \"Hot Spot\",\n    predicted_cases &lt; cold_spot_threshold ~ \"Cold Spot\",\n    TRUE ~ \"Neutral\"\n  ))\n\n# Preview classified hot/cold spots\nprint(future_predictions)\n\n               province_name year predicted_cases hot_cold_label\n1                    Bangkok 2023         0.00000      Cold Spot\n2                    Bangkok 2024         0.00000      Cold Spot\n3                    Bangkok 2025         0.00000      Cold Spot\n4                    Bangkok 2026         0.00000      Cold Spot\n5                    Bangkok 2027         0.00000      Cold Spot\n6                   Chai Nat 2023       121.95164        Neutral\n7                   Chai Nat 2024       158.61225        Neutral\n8                   Chai Nat 2025       158.61225        Neutral\n9                   Chai Nat 2026       158.61225        Neutral\n10                  Chai Nat 2027       158.61225        Neutral\n11                Nonthaburi 2023       445.56122        Neutral\n12                Nonthaburi 2024       770.69906       Hot Spot\n13                Nonthaburi 2025       971.02793       Hot Spot\n14                Nonthaburi 2026      1085.64477       Hot Spot\n15                Nonthaburi 2027      1044.22187       Hot Spot\n16              Pathum Thani 2023       444.93144        Neutral\n17              Pathum Thani 2024       745.38727       Hot Spot\n18              Pathum Thani 2025       974.66979       Hot Spot\n19              Pathum Thani 2026      1108.45103       Hot Spot\n20              Pathum Thani 2027      1140.99565       Hot Spot\n21  Phra Nakhon Si Ayutthaya 2023       433.96887        Neutral\n22  Phra Nakhon Si Ayutthaya 2024       734.24699       Hot Spot\n23  Phra Nakhon Si Ayutthaya 2025       934.85736       Hot Spot\n24  Phra Nakhon Si Ayutthaya 2026      1025.35557       Hot Spot\n25  Phra Nakhon Si Ayutthaya 2027      1019.24844       Hot Spot\n26                  Lop Buri 2023        73.42092        Neutral\n27                  Lop Buri 2024       -13.05389      Cold Spot\n28                  Lop Buri 2025        61.22385        Neutral\n29                  Lop Buri 2026       -14.51496      Cold Spot\n30                  Lop Buri 2027        30.78899        Neutral\n31              Samut Prakan 2023       375.17550        Neutral\n32              Samut Prakan 2024       541.24572        Neutral\n33              Samut Prakan 2025       790.09928       Hot Spot\n34              Samut Prakan 2026       905.81670       Hot Spot\n35              Samut Prakan 2027       905.81670       Hot Spot\n36                  Saraburi 2023       156.28755        Neutral\n37                  Saraburi 2024       276.62499        Neutral\n38                  Saraburi 2025       410.66607        Neutral\n39                  Saraburi 2026       345.65633        Neutral\n40                  Saraburi 2027       323.05549        Neutral\n41                 Sing Buri 2023        77.82750        Neutral\n42                 Sing Buri 2024        91.55917        Neutral\n43                 Sing Buri 2025       117.63052        Neutral\n44                 Sing Buri 2026       120.66955        Neutral\n45                 Sing Buri 2027       129.50619        Neutral\n46                 Ang Thong 2023        94.64097        Neutral\n47                 Ang Thong 2024       102.49061        Neutral\n48                 Ang Thong 2025       141.69769        Neutral\n49                 Ang Thong 2026       141.45184        Neutral\n50                 Ang Thong 2027       158.01154        Neutral\n51               Chanthaburi 2023       272.65223        Neutral\n52               Chanthaburi 2024       326.70195        Neutral\n53               Chanthaburi 2025       326.70195        Neutral\n54               Chanthaburi 2026       326.70195        Neutral\n55               Chanthaburi 2027       326.70195        Neutral\n56              Chachoengsao 2023       405.88506        Neutral\n57              Chachoengsao 2024       556.61584        Neutral\n58              Chachoengsao 2025       556.61584        Neutral\n59              Chachoengsao 2026       556.61584        Neutral\n60              Chachoengsao 2027       556.61584        Neutral\n61                 Chon Buri 2023       941.06750       Hot Spot\n62                 Chon Buri 2024      1259.21802       Hot Spot\n63                 Chon Buri 2025      1259.21802       Hot Spot\n64                 Chon Buri 2026      1259.21802       Hot Spot\n65                 Chon Buri 2027      1259.21802       Hot Spot\n66                      Trat 2023       110.88123        Neutral\n67                      Trat 2024       139.82447        Neutral\n68                      Trat 2025       139.82447        Neutral\n69                      Trat 2026       139.82447        Neutral\n70                      Trat 2027       139.82447        Neutral\n71              Nakhon Nayok 2023       226.80350        Neutral\n72              Nakhon Nayok 2024       293.07455        Neutral\n73              Nakhon Nayok 2025       293.07455        Neutral\n74              Nakhon Nayok 2026       293.07455        Neutral\n75              Nakhon Nayok 2027       293.07455        Neutral\n76              Prachin Buri 2023       274.71493        Neutral\n77              Prachin Buri 2024       374.77267        Neutral\n78              Prachin Buri 2025       374.77267        Neutral\n79              Prachin Buri 2026       374.77267        Neutral\n80              Prachin Buri 2027       374.77267        Neutral\n81                    Rayong 2023       656.57920       Hot Spot\n82                    Rayong 2024       846.06450       Hot Spot\n83                    Rayong 2025       846.06450       Hot Spot\n84                    Rayong 2026       846.06450       Hot Spot\n85                    Rayong 2027       846.06450       Hot Spot\n86                   Sa Kaeo 2023       227.53179        Neutral\n87                   Sa Kaeo 2024       329.99615        Neutral\n88                   Sa Kaeo 2025       329.99615        Neutral\n89                   Sa Kaeo 2026       329.99615        Neutral\n90                   Sa Kaeo 2027       329.99615        Neutral\n91                Chaiyaphum 2023       574.76971        Neutral\n92                Chaiyaphum 2024       669.53688       Hot Spot\n93                Chaiyaphum 2025       669.53688       Hot Spot\n94                Chaiyaphum 2026       669.53688       Hot Spot\n95                Chaiyaphum 2027       669.53688       Hot Spot\n96         Nakhon Ratchasima 2023       792.99239       Hot Spot\n97         Nakhon Ratchasima 2024      1013.51653       Hot Spot\n98         Nakhon Ratchasima 2025      1013.51653       Hot Spot\n99         Nakhon Ratchasima 2026      1013.51653       Hot Spot\n100        Nakhon Ratchasima 2027      1013.51653       Hot Spot\n101                 Buri Ram 2023       455.31164        Neutral\n102                 Buri Ram 2024       595.14582        Neutral\n103                 Buri Ram 2025       595.14582        Neutral\n104                 Buri Ram 2026       595.14582        Neutral\n105                 Buri Ram 2027       595.14582        Neutral\n106                 Yasothon 2023       404.57270        Neutral\n107                 Yasothon 2024       442.14877        Neutral\n108                 Yasothon 2025       442.14877        Neutral\n109                 Yasothon 2026       442.14877        Neutral\n110                 Yasothon 2027       442.14877        Neutral\n111                Si Sa Ket 2023       648.68659       Hot Spot\n112                Si Sa Ket 2024       804.53952       Hot Spot\n113                Si Sa Ket 2025       804.53952       Hot Spot\n114                Si Sa Ket 2026       804.53952       Hot Spot\n115                Si Sa Ket 2027       804.53952       Hot Spot\n116                    Surin 2023       340.39047        Neutral\n117                    Surin 2024       465.10676        Neutral\n118                    Surin 2025       465.10676        Neutral\n119                    Surin 2026       465.10676        Neutral\n120                    Surin 2027       465.10676        Neutral\n121            Amnat Charoen 2023       309.37088        Neutral\n122            Amnat Charoen 2024       368.68462        Neutral\n123            Amnat Charoen 2025       368.68462        Neutral\n124            Amnat Charoen 2026       368.68462        Neutral\n125            Amnat Charoen 2027       368.68462        Neutral\n126         Ubon Ratchathani 2023       963.58992       Hot Spot\n127         Ubon Ratchathani 2024      1184.15202       Hot Spot\n128         Ubon Ratchathani 2025      1184.15202       Hot Spot\n129         Ubon Ratchathani 2026      1184.15202       Hot Spot\n130         Ubon Ratchathani 2027      1184.15202       Hot Spot\n131                  Kalasin 2023       523.82305        Neutral\n132                  Kalasin 2024       617.81681        Neutral\n133                  Kalasin 2025       833.20013       Hot Spot\n134                  Kalasin 2026       820.92124       Hot Spot\n135                  Kalasin 2027       859.35567       Hot Spot\n136                Khon Kaen 2023       705.88583       Hot Spot\n137                Khon Kaen 2024       694.86365       Hot Spot\n138                Khon Kaen 2025       910.47965       Hot Spot\n139                Khon Kaen 2026       896.19125       Hot Spot\n140                Khon Kaen 2027       962.60579       Hot Spot\n141            Nakhon Phanom 2023       272.33236        Neutral\n142            Nakhon Phanom 2024       346.37847        Neutral\n143            Nakhon Phanom 2025       346.37847        Neutral\n144            Nakhon Phanom 2026       346.37847        Neutral\n145            Nakhon Phanom 2027       346.37847        Neutral\n146                Bueng Kan 2023       340.66167        Neutral\n147                Bueng Kan 2024       463.89491        Neutral\n148                Bueng Kan 2025       581.50795        Neutral\n149                Bueng Kan 2026       587.37437        Neutral\n150                Bueng Kan 2027       588.34525        Neutral\n151            Maha Sarakham 2023       322.76105        Neutral\n152            Maha Sarakham 2024       541.66137        Neutral\n153            Maha Sarakham 2025       702.74837       Hot Spot\n154            Maha Sarakham 2026       792.21502       Hot Spot\n155            Maha Sarakham 2027       809.35105       Hot Spot\n156                 Mukdahan 2023       347.46424        Neutral\n157                 Mukdahan 2024       381.15692        Neutral\n158                 Mukdahan 2025       381.15692        Neutral\n159                 Mukdahan 2026       381.15692        Neutral\n160                 Mukdahan 2027       381.15692        Neutral\n161                   Roi Et 2023       460.04874        Neutral\n162                   Roi Et 2024       406.74608        Neutral\n163                   Roi Et 2025       534.37317        Neutral\n164                   Roi Et 2026       513.27423        Neutral\n165                   Roi Et 2027       549.00865        Neutral\n166                     Loei 2023       372.22320        Neutral\n167                     Loei 2024       478.74224        Neutral\n168                     Loei 2025       653.88396       Hot Spot\n169                     Loei 2026       705.60846       Hot Spot\n170                     Loei 2027       720.21339       Hot Spot\n171             Sakon Nakhon 2023       270.81527        Neutral\n172             Sakon Nakhon 2024       261.27038        Neutral\n173             Sakon Nakhon 2025       371.75413        Neutral\n174             Sakon Nakhon 2026       360.67424        Neutral\n175             Sakon Nakhon 2027       406.21679        Neutral\n176                Nong Khai 2023       365.44722        Neutral\n177                Nong Khai 2024       444.63562        Neutral\n178                Nong Khai 2025       444.63562        Neutral\n179                Nong Khai 2026       444.63562        Neutral\n180                Nong Khai 2027       444.63562        Neutral\n181         Nong Bua Lam Phu 2023        97.96556        Neutral\n182         Nong Bua Lam Phu 2024        97.38559        Neutral\n183         Nong Bua Lam Phu 2025       135.67981        Neutral\n184         Nong Bua Lam Phu 2026       133.09628        Neutral\n185         Nong Bua Lam Phu 2027       148.21035        Neutral\n186               Udon Thani 2023       560.87453        Neutral\n187               Udon Thani 2024       502.57923        Neutral\n188               Udon Thani 2025       667.68487       Hot Spot\n189               Udon Thani 2026       643.74121       Hot Spot\n190               Udon Thani 2027       692.63295       Hot Spot\n191               Chiang Rai 2023       552.88373        Neutral\n192               Chiang Rai 2024       781.08315       Hot Spot\n193               Chiang Rai 2025       781.08315       Hot Spot\n194               Chiang Rai 2026       781.08315       Hot Spot\n195               Chiang Rai 2027       781.08315       Hot Spot\n196               Chiang Mai 2023       896.20515       Hot Spot\n197               Chiang Mai 2024      1263.40637       Hot Spot\n198               Chiang Mai 2025      1263.40637       Hot Spot\n199               Chiang Mai 2026      1263.40637       Hot Spot\n200               Chiang Mai 2027      1263.40637       Hot Spot\n201                      Nan 2023       296.41229        Neutral\n202                      Nan 2024       349.12970        Neutral\n203                      Nan 2025       349.12970        Neutral\n204                      Nan 2026       349.12970        Neutral\n205                      Nan 2027       349.12970        Neutral\n206                   Phayao 2023       285.56858        Neutral\n207                   Phayao 2024       339.30987        Neutral\n208                   Phayao 2025       339.30987        Neutral\n209                   Phayao 2026       339.30987        Neutral\n210                   Phayao 2027       339.30987        Neutral\n211                    Phrae 2023       380.78755        Neutral\n212                    Phrae 2024       390.83041        Neutral\n213                    Phrae 2025       390.83041        Neutral\n214                    Phrae 2026       390.83041        Neutral\n215                    Phrae 2027       390.83041        Neutral\n216             Mae Hong Son 2023        49.99958        Neutral\n217             Mae Hong Son 2024        57.75518        Neutral\n218             Mae Hong Son 2025        74.56834        Neutral\n219             Mae Hong Son 2026        75.80713        Neutral\n220             Mae Hong Son 2027        81.58090        Neutral\n221                  Lampang 2023       453.32522        Neutral\n222                  Lampang 2024       521.25600        Neutral\n223                  Lampang 2025       521.25600        Neutral\n224                  Lampang 2026       521.25600        Neutral\n225                  Lampang 2027       521.25600        Neutral\n226                  Lamphun 2023       339.14296        Neutral\n227                  Lamphun 2024       379.74319        Neutral\n228                  Lamphun 2025       379.74319        Neutral\n229                  Lamphun 2026       379.74319        Neutral\n230                  Lamphun 2027       379.74319        Neutral\n231           Kamphaeng Phet 2023       196.47710        Neutral\n232           Kamphaeng Phet 2024       303.37231        Neutral\n233           Kamphaeng Phet 2025       303.37231        Neutral\n234           Kamphaeng Phet 2026       303.37231        Neutral\n235           Kamphaeng Phet 2027       303.37231        Neutral\n236                      Tak 2023       161.86546        Neutral\n237                      Tak 2024       244.01662        Neutral\n238                      Tak 2025       244.01662        Neutral\n239                      Tak 2026       244.01662        Neutral\n240                      Tak 2027       244.01662        Neutral\n241             Nakhon Sawan 2023       136.50688        Neutral\n242             Nakhon Sawan 2024       175.40399        Neutral\n243             Nakhon Sawan 2025       238.58111        Neutral\n244             Nakhon Sawan 2026       251.45816        Neutral\n245             Nakhon Sawan 2027       281.20155        Neutral\n246                  Phichit 2023       131.05482        Neutral\n247                  Phichit 2024       212.23742        Neutral\n248                  Phichit 2025       212.23742        Neutral\n249                  Phichit 2026       212.23742        Neutral\n250                  Phichit 2027       212.23742        Neutral\n251              Phitsanulok 2023       155.65360        Neutral\n252              Phitsanulok 2024       271.22834        Neutral\n253              Phitsanulok 2025       303.93993        Neutral\n254              Phitsanulok 2026       313.19843        Neutral\n255              Phitsanulok 2027       315.81889        Neutral\n256               Phetchabun 2023       221.68122        Neutral\n257               Phetchabun 2024       291.15973        Neutral\n258               Phetchabun 2025       357.68944        Neutral\n259               Phetchabun 2026       374.81113        Neutral\n260               Phetchabun 2027       395.08849        Neutral\n261                Sukhothai 2023       241.34378        Neutral\n262                Sukhothai 2024       300.84863        Neutral\n263                Sukhothai 2025       344.53911        Neutral\n264                Sukhothai 2026       366.19521        Neutral\n265                Sukhothai 2027       363.11644        Neutral\n266                Uttaradit 2023       118.22115        Neutral\n267                Uttaradit 2024       209.21378        Neutral\n268                Uttaradit 2025       248.11678        Neutral\n269                Uttaradit 2026       264.74938        Neutral\n270                Uttaradit 2027       271.86048        Neutral\n271              Uthai Thani 2023        97.45097        Neutral\n272              Uthai Thani 2024       128.06367        Neutral\n273              Uthai Thani 2025       128.06367        Neutral\n274              Uthai Thani 2026       128.06367        Neutral\n275              Uthai Thani 2027       128.06367        Neutral\n276             Kanchanaburi 2023       403.66211        Neutral\n277             Kanchanaburi 2024       594.20084        Neutral\n278             Kanchanaburi 2025       779.61462       Hot Spot\n279             Kanchanaburi 2026       871.02073       Hot Spot\n280             Kanchanaburi 2027       880.35025       Hot Spot\n281            Nakhon Pathom 2023       326.31478        Neutral\n282            Nakhon Pathom 2024       477.63712        Neutral\n283            Nakhon Pathom 2025       477.63712        Neutral\n284            Nakhon Pathom 2026       477.63712        Neutral\n285            Nakhon Pathom 2027       477.63712        Neutral\n286      Prachuap Khiri Khan 2023       267.83800        Neutral\n287      Prachuap Khiri Khan 2024       474.80600        Neutral\n288      Prachuap Khiri Khan 2025       607.37035        Neutral\n289      Prachuap Khiri Khan 2026       665.46209       Hot Spot\n290      Prachuap Khiri Khan 2027       659.21701       Hot Spot\n291              Phetchaburi 2023       342.47703        Neutral\n292              Phetchaburi 2024       568.68425        Neutral\n293              Phetchaburi 2025       656.94812       Hot Spot\n294              Phetchaburi 2026       665.69717       Hot Spot\n295              Phetchaburi 2027       607.90321        Neutral\n296               Ratchaburi 2023       460.03729        Neutral\n297               Ratchaburi 2024       584.56236        Neutral\n298               Ratchaburi 2025       584.56236        Neutral\n299               Ratchaburi 2026       584.56236        Neutral\n300               Ratchaburi 2027       584.56236        Neutral\n301          Samut Songkhram 2023        76.30650        Neutral\n302          Samut Songkhram 2024       120.26764        Neutral\n303          Samut Songkhram 2025       147.13499        Neutral\n304          Samut Songkhram 2026       153.43014        Neutral\n305          Samut Songkhram 2027       150.57259        Neutral\n306             Samut Sakhon 2023        81.87036        Neutral\n307             Samut Sakhon 2024       158.44357        Neutral\n308             Samut Sakhon 2025       273.54406        Neutral\n309             Samut Sakhon 2026       316.86129        Neutral\n310             Samut Sakhon 2027       330.63369        Neutral\n311              Suphan Buri 2023       435.53079        Neutral\n312              Suphan Buri 2024       645.01305       Hot Spot\n313              Suphan Buri 2025       837.17651       Hot Spot\n314              Suphan Buri 2026       939.71474       Hot Spot\n315              Suphan Buri 2027       927.00394       Hot Spot\n316                    Krabi 2023       239.48163        Neutral\n317                    Krabi 2024       338.06991        Neutral\n318                    Krabi 2025       416.06659        Neutral\n319                    Krabi 2026       444.48590        Neutral\n320                    Krabi 2027       470.25255        Neutral\n321                 Chumphon 2023       266.37220        Neutral\n322                 Chumphon 2024       336.53238        Neutral\n323                 Chumphon 2025       449.78627        Neutral\n324                 Chumphon 2026       470.75982        Neutral\n325                 Chumphon 2027       519.73980        Neutral\n326      Nakhon Si Thammarat 2023       873.57177       Hot Spot\n327      Nakhon Si Thammarat 2024      1107.81056       Hot Spot\n328      Nakhon Si Thammarat 2025      1395.35146       Hot Spot\n329      Nakhon Si Thammarat 2026      1457.70530       Hot Spot\n330      Nakhon Si Thammarat 2027      1553.31867       Hot Spot\n331                 Phangnga 2023       287.99713        Neutral\n332                 Phangnga 2024       493.81763        Neutral\n333                 Phangnga 2025       628.86052       Hot Spot\n334                 Phangnga 2026       695.65030       Hot Spot\n335                 Phangnga 2027       696.69975       Hot Spot\n336                   Phuket 2023       466.46431        Neutral\n337                   Phuket 2024       781.86130       Hot Spot\n338                   Phuket 2025       781.86130       Hot Spot\n339                   Phuket 2026       781.86130       Hot Spot\n340                   Phuket 2027       781.86130       Hot Spot\n341                   Ranong 2023       152.80096        Neutral\n342                   Ranong 2024       175.09006        Neutral\n343                   Ranong 2025       231.90182        Neutral\n344                   Ranong 2026       236.80697        Neutral\n345                   Ranong 2027       258.14327        Neutral\n346              Surat Thani 2023       610.96897        Neutral\n347              Surat Thani 2024       911.56069       Hot Spot\n348              Surat Thani 2025      1110.68598       Hot Spot\n349              Surat Thani 2026      1203.86861       Hot Spot\n350              Surat Thani 2027      1269.21391       Hot Spot\n351                    Trang 2023       262.70161        Neutral\n352                    Trang 2024       311.49759        Neutral\n353                    Trang 2025       270.62038        Neutral\n354                    Trang 2026       378.39517        Neutral\n355                    Trang 2027       496.52719        Neutral\n356               Narathiwat 2023       171.77751        Neutral\n357               Narathiwat 2024       253.48050        Neutral\n358               Narathiwat 2025       418.17847        Neutral\n359               Narathiwat 2026       530.21478        Neutral\n360               Narathiwat 2027       530.21478        Neutral\n361                  Pattani 2023       194.96926        Neutral\n362                  Pattani 2024       298.61454        Neutral\n363                  Pattani 2025       446.29248        Neutral\n364                  Pattani 2026       529.67746        Neutral\n365                  Pattani 2027       529.67746        Neutral\n366              Phatthalung 2023       118.68252        Neutral\n367              Phatthalung 2024       195.62916        Neutral\n368              Phatthalung 2025       245.51676        Neutral\n369              Phatthalung 2026       277.86090        Neutral\n370              Phatthalung 2027       298.83090        Neutral\n371                     Yala 2023       249.57731        Neutral\n372                     Yala 2024       413.50934        Neutral\n373                     Yala 2025       413.50934        Neutral\n374                     Yala 2026       413.50934        Neutral\n375                     Yala 2027       413.50934        Neutral\n376                 Songkhla 2023       487.34873        Neutral\n377                 Songkhla 2024       806.72011       Hot Spot\n378                 Songkhla 2025      1016.01187       Hot Spot\n379                 Songkhla 2026      1153.16581       Hot Spot\n380                 Songkhla 2027      1243.04609       Hot Spot\n381                    Satun 2023       469.36891        Neutral\n382                    Satun 2024       729.24674       Hot Spot\n383                    Satun 2025       873.52819       Hot Spot\n384                    Satun 2026       955.64227       Hot Spot\n385                    Satun 2027       894.15579       Hot Spot"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualization-of-predictions",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualization-of-predictions",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Visualization of Predictions",
    "text": "Visualization of Predictions\n\nlibrary(tmap)\n\n# Merge predictions with spatial data\nfuture_spatial &lt;- province_boundaries %&gt;%\n  left_join(future_predictions, by = \"province_name\")\n\n# Visualize predicted hot/cold spots for 2023-2027\ntm_shape(future_spatial) +\n  tm_polygons(\"hot_cold_label\", palette = c(\"blue\", \"red\", \"gray\"), \n              title = \"Predicted Hot/Cold Spots (2023-2027)\") +\n  tm_borders() +\n  tm_layout(title = \"Predicted Drug Abuse Hot/Cold Spots in Thailand (2023-2027)\")\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nARIMA (AutoRegressive Integrated Moving Average) model is used for our time series forecasting.\nAlso it offers,\n\nFlexibility: in various time series patterns, suitable for non-stationary data.\nAutomatic Parameter Selection (auto.arima): simplifies model fitting by automatically selecting optimal parameters.\nRobustness: in capturing fluctuations in historical data."
  }
]