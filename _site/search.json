[
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "Introduction\nThe Rise of Armed Conflict and the Potential of Geospatial Analytics\n\nImpact: Millions of lives are shattered by armed conflict each year.\nTrend: Armed conflict has been on the rise since around 2012, reversing the decline from the 1990s and early 2000s.\n\nRecent Major Conflicts:\n\nLibya, Syria, and Yemen (post-2011): Instabilities following the Arab uprisings.\nSahel Region: Crisis exacerbated by Libya’s instability.\nAzerbaijan-Armenian War (2020): Conflict over the Nagorno-Karabakh enclave.\nEthiopia’s Tigray Conflict (2020): Severe fighting in the northern region.\nMyanmar (2021): Conflict following the military’s power grab.\nRussia-Ukraine War (2022): Major assault by Russia on Ukraine.\nSudan and Gaza (2023): New devastating conflicts.\n\n\nCurrent Situation: The number of people affected—through death, displacement, or need for humanitarian aid—is higher than in decades.\n\nThis Geospatial Analytics will Focus on:\n\nObjective: This study will use spatial point patterns analysis to explore the spatial and spatio-temporal distribution of armed conflict in Myanmar.\nPotential: Geospatial analytics offer tremendous potential to address complex societal problems, providing insights into the patterns and dynamics of conflict.\n\nSource: 10 Conflicts to Watch in 2024\n\n\n\n1.0 Setup\n\n1.1 Installing R-Packages\n\nImporting and Transforming DataMapping displayDeriving Quarterly KDE LayersPerforming 2nd-Order Spatial Point Patterns AnalysisDeriving Quarterly Spatio-Temporal KDE LayersPerforming 2nd-Order Spatio-Temporal Point Patterns AnalysisDisplaying Maps with KDE and Spatio-temporal KDE Layers\n\n\n\nsf:\n\nFor handling spatial vector data and transforming it into simple features (sf) objects.\nFunctions like st_read() for importing spatial data and st_transform() for coordinate reference system transformations.\n\ntidyverse: For data manipulation and transformation, including functions for working with tibble data frames.\nreadr: For reading in CSV or other text-based data files if needed.\ndplyr: provide data manipulation capabilities (eg. to group and summarize the relationships between these columns)\n\n\n\n\npatchwork: To arrange map layout\n\n\n\n\nspatstat: For kernel density estimation (KDE) and spatial point pattern analysis.\nstars: For working with raster data and creating raster-based KDE layers.\nraster: Additional functions for raster operations, if necessary.\n\n\n\n\nspatstat: For analyzing second-order spatial point patterns, such as pair correlation functions.\nggplot2: For visualizing the results of spatial analysis.\nanimation, png, magick: For animation work\n\n\n\n\nspatstat: For spatio-temporal point pattern analysis and creating spatio-temporal KDE layers.\nstars: For handling spatio-temporal raster data.\n\n\n\n\nspatstat: For advanced spatio-temporal analysis, including the study of second-order effects over time.\n\n\n\n\ntmap: For creating thematic maps and displaying KDE layers.\nggplot2: For additional custom visualizations if needed.\nleaflet: For interactive maps, if required.\nosmdata: To fetch and integrate OpenStreetMap data for background maps.\n\n\n\n\n\npacman::p_load(tidyverse, sf, readr, spatstat, raster, ggstatsplot, ggplot2, tmap, osmdata, dplyr, patchwork, animation, png, magick)\n\n\n\n\n1.2 Data Acquisition\nWe will be using 2 sets of data:\n\nArmed Conflict DataAdministrative Boundary Data\n\n\n\nSource: Armed Conflict Location & Event Data (ACLED). ACLED is an independent, impartial international non-profit organization that collects data on violent conflict and protests worldwide.\nCoverage: Myanmar, from January 2021 to June 2024.\nEvent Types: Focus on at least four main event types:\n\nBattles\nExplosion/Remote Violence\nStrategic Developments\nViolence Against Civilians\n\nStudy Period: Quarterly armed conflict events from January 2021 to June 2024.\n\n\n\n\nSource: Myanmar Information Management Unit (MIMU).\nFor Broad Analysis:\n\nNational Boundaries: To get an overview of conflict patterns across the entire country.\nState and Region with Sub-region Boundaries: For understanding conflict distribution across larger administrative divisions.\n\nFor Detailed Local Analysis:\n\nDistrict Boundaries: Useful for a more detailed view of conflict distribution within specific districts.\nTownship and Ward Boundaries: For very granular analysis, especially useful if you’re interested in the impact at the community level.\n\nSelf-Administered Region Boundaries: For Analyzing Conflict Dynamics in Self-Administered Regions (SARs) Relative to Administrative Autonomy\n\n\n\n\n\n\n\n1.3 Importing Geospatial Data into R\n\nArmed Conflict DataAdministrative Boundaries\n\n\n\nacled_sf &lt;- read_csv(\"data/ACLED_Myanmar.csv\")\n\nRows: 51553 Columns: 31\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): event_id_cnty, event_date, disorder_type, event_type, sub_event_ty...\ndbl (11): year, time_precision, inter1, inter2, interaction, iso, latitude, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nFor Broad Analysis:\n\n\nnational_boundaries &lt;- st_read(dsn = \"data/National_Boundaries\", layer=\"mmr_polbnda_adm0_250k_mimu_1\")\n\nReading layer `mmr_polbnda_adm0_250k_mimu_1' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex01\\data\\National_Boundaries' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nstate_region_subregion_boundaries &lt;- st_read(dsn = \"data/State_And_Region_With_Sub-regions_Boundaries\", layer=\"mmr_polbnda2_adm1_250k_mimu_1\")\n\nReading layer `mmr_polbnda2_adm1_250k_mimu_1' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex01\\data\\State_And_Region_With_Sub-regions_Boundaries' \n  using driver `ESRI Shapefile'\nSimple feature collection with 18 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\n\nFor Detailed Local Analysis:\n\n\ndistrict_boundaries &lt;- st_read(dsn = \"data/District_Boundaries\", layer=\"mmr_polbnda_adm2_250k_mimu\")\n\nReading layer `mmr_polbnda_adm2_250k_mimu' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex01\\data\\District_Boundaries' \n  using driver `ESRI Shapefile'\nSimple feature collection with 80 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\ntownship_boundaries &lt;- st_read(dsn = \"data/Township_Boundaries\", layer=\"mmr_polbnda_adm3_250k_mimu_1\")\n\nReading layer `mmr_polbnda_adm3_250k_mimu_1' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex01\\data\\Township_Boundaries' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nward_boundaries &lt;- st_read(dsn = \"data/Ward_Boundaries\", layer=\"mmr_polbnda_adm5_mimu_v9_4\")\n\nReading layer `mmr_polbnda_adm5_mimu_v9_4' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex01\\data\\Ward_Boundaries' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1999 features and 15 fields (with 1 geometry empty)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.34521 ymin: 9.974381 xmax: 100.3662 ymax: 27.29535\nGeodetic CRS:  WGS 84\n\n\n\nSelf-Administered region Boundaries\n\n\nself_administered_boundaries &lt;- st_read(dsn = \"data/Self_Administered_Region_Boundaries\", layer=\"mmr_polbnda_self_administered_zones_1\")\n\nReading layer `mmr_polbnda_self_administered_zones_1' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Take-home_Ex\\Take-home_Ex01\\data\\Self_Administered_Region_Boundaries' \n  using driver `ESRI Shapefile'\nSimple feature collection with 6 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 94.5777 ymin: 19.74308 xmax: 99.56572 ymax: 27.37205\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\n1.4 Checking Geospatial Data\n\nArmed Conflict DataAdministrative Boundaries\n\n\n\nclass(acled_sf)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\nst_crs(acled_sf)\n\nCoordinate Reference System: NA\n\n\n\n\n\n\n\n\nNote\n\n\n\nSince\n\nSince the class of acled_sf != sf object\n\n\n\nCoordinate Reference System of acled_sf = NA\n\nwe have to transform it.\n\n\n\n\n\nclass(national_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(national_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\nclass(state_region_subregion_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(state_region_subregion_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\nclass(district_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(district_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\nclass(township_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(township_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\nclass(ward_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(ward_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\nclass(self_administered_boundaries)\n\n[1] \"sf\"         \"data.frame\"\n\nst_crs(self_administered_boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\n\n\n\n\nNote\n\n\n\nSince Coordinate Reference System of\n\nnational_boundaries\nstate_region_subregion_boundaries\ndistrict_boundaries\ntownship_boundaries\nward_boundaries\nself_administered_boundaries\n\nis in 4326 (unit of measurement = degree), we have to transform it\n\n\n\n\n\n\n\n\n1.5 Understanding the data\n\n# Select relevant columns and group by disorder_type, event_type, sub_event_type\ntype_of_conflict &lt;- acled_sf %&gt;%\n  dplyr::select(disorder_type, event_type, sub_event_type) %&gt;%\n  group_by(disorder_type, event_type, sub_event_type) %&gt;%\n  summarize(count = n(), .groups = 'drop')  # Count occurrences of each combination\nprint(type_of_conflict, n = Inf)\n\n# A tibble: 25 × 4\n   disorder_type                      event_type            sub_event_type count\n   &lt;chr&gt;                              &lt;chr&gt;                 &lt;chr&gt;          &lt;int&gt;\n 1 Demonstrations                     Protests              Peaceful prot…  8132\n 2 Demonstrations                     Protests              Protest with …   463\n 3 Demonstrations                     Riots                 Violent demon…    94\n 4 Political violence                 Battles               Armed clash    11770\n 5 Political violence                 Battles               Government re…     5\n 6 Political violence                 Battles               Non-state act…   274\n 7 Political violence                 Explosions/Remote vi… Air/drone str…  2646\n 8 Political violence                 Explosions/Remote vi… Chemical weap…     1\n 9 Political violence                 Explosions/Remote vi… Grenade          393\n10 Political violence                 Explosions/Remote vi… Remote explos…  5511\n11 Political violence                 Explosions/Remote vi… Shelling/arti…  3655\n12 Political violence                 Explosions/Remote vi… Suicide bomb       2\n13 Political violence                 Riots                 Mob violence      22\n14 Political violence                 Violence against civ… Abduction/for…   905\n15 Political violence                 Violence against civ… Attack          5257\n16 Political violence                 Violence against civ… Sexual violen…    63\n17 Political violence; Demonstrations Protests              Excessive for…   234\n18 Strategic developments             Strategic developmen… Agreement         10\n19 Strategic developments             Strategic developmen… Arrests         4833\n20 Strategic developments             Strategic developmen… Change to gro…  1346\n21 Strategic developments             Strategic developmen… Disrupted wea…   325\n22 Strategic developments             Strategic developmen… Headquarters …    67\n23 Strategic developments             Strategic developmen… Looting/prope…  4042\n24 Strategic developments             Strategic developmen… Non-violent t…    28\n25 Strategic developments             Strategic developmen… Other           1475\n\n\n\n\n\n\n\n\nNote!\n\n\n\nThe dataset includes non-conflict events such as:\n\n“Change to group/activity”\n“Agreement”\n“Headquarters or base established”\n\nAdditionally, it contains a sub-event category labeled “Other”. Including these non-conflict events under the general category of “conflict nature” may lead to biased or misleading interpretations. To ensure accurate and meaningful analysis, I recommend removing these non-conflict events from the dataset.\n\n\n\n\n\n1.6 Data Preparation and Wrangling\n\nArmed Conflict DataAdministrative Boundaries\n\n\n\nConvert Data Frame to sf Object\n\nacled_sf &lt;- acled_sf %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\nclass(acled_sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\nTransform Coordinate Reference System\n\nacled_sf &lt;- acled_sf %&gt;%\n  st_transform(crs = 32647)\n\n\n\nConvert Date Column to Date Format\n\nacled_sf &lt;- acled_sf %&gt;%\n  mutate(event_date = dmy(event_date))\n\n\n\nEliminating Columns not used for analysis\n\nacled_sf &lt;- acled_sf[, !(names(acled_sf) %in% c(\"event_id_cnty\", \"time_precision\", \"inter1\", \"inter2\", \"notes\", \"tags\"))]\n\n\n\nPreparing Data for Quarterly KDE Analysis\n\nCreate a Quarter Column\n\n\nacled_sf &lt;- acled_sf %&gt;%\n  mutate(quarter = paste0(\"Q\", quarter(event_date), \"-\", year(event_date)))\n\n\nRemove non-conflict data\n\n\nnon_conflict_events &lt;- c(\n  \"Change to group/activity\",\n  \"Agreement\",\n  \"Headquarters or base established\",\n  \"Other\"\n)\n\n# Filter out the non-conflict events from the dataset\nconflict_acled_sf_data &lt;- acled_sf %&gt;%\n  filter(!sub_event_type %in% non_conflict_events)\n\n\n\nAdding a new analysis dimension: month\n\nconflict_acled_sf_data &lt;- conflict_acled_sf_data %&gt;%\n  mutate(month = month(event_date))\n\n\n\n\n\nTransform the Coordinate Reference System of these:\n\nnational_boundaries &lt;- national_boundaries %&gt;%\n  st_transform(crs = 32647)\n\nstate_region_subregion_boundaries &lt;- state_region_subregion_boundaries %&gt;%\n  st_transform(crs = 32647)\n\ndistrict_boundaries &lt;- district_boundaries %&gt;%\n  st_transform(crs = 32647)\n\ntownship_boundaries &lt;- township_boundaries %&gt;%\n  st_transform(crs = 32647)\n\nward_boundaries &lt;- ward_boundaries %&gt;%\n  st_transform(crs = 32647)\n\nself_administered_boundaries &lt;- self_administered_boundaries %&gt;%\n  st_transform(crs = 32647)\n\n\n\nSample plot\n\nggplot(data = state_region_subregion_boundaries) +\n  geom_sf() +\n  theme_minimal() +\n  labs(title = \"Map of Geometries\",\n       subtitle = \"Displaying multipolygon geometries\",\n       caption = \"Source: Example Data\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.0 Exploratory Data Analysis\n\n2.1 Temporal Analysis: Frequency of Conflict Events Over Time\n\nggplot(conflict_acled_sf_data, aes(x = event_date)) +\n  geom_histogram(binwidth = 30, fill = \"steelblue\", color = \"black\") +\n  labs(title = \"Conflict Events Over Time\", x = \"Date\", y = \"Number of Events\")\n\n\n\n\n\n\n\n\n\n\n2.2 Event Type Distribution\n\nggplot(conflict_acled_sf_data, aes(x = event_date, fill = event_type)) +\n  geom_histogram(binwidth = 30) +\n  labs(title = \"Event Types Over Time\", x = \"Date\", y = \"Number of Events\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n2.3 Spatial Analysis\n\n# Plot a choropleth of the conflict events by year using ggplot2\nggplot() +\n  geom_sf(data = national_boundaries, fill = \"lightgrey\") +\n  geom_sf(data = conflict_acled_sf_data, aes(color = event_type), size = 0.1, alpha = 0.6) +\n  facet_wrap(~year, ncol = 4) +  # Facet by year with 4 columns\n  labs(title = \"Spatial Distribution of Conflict Events by Year\", color = \"Event Type\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") + \n  guides(color = guide_legend(override.aes = list(size = 1)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nFrom 2021 to 2024, the conflicts in Myanmar have escalated significantly, evolving from largely peaceful protests to increasingly violent confrontations and armed battles.\n\n\n\n\n2.4 Conflict Hotspots by state & region\n\n2.4.1 Preparing the hotspots\n\n# Ensure the CRS of both datasets match\nconflict_acled_sf_data &lt;- st_transform(conflict_acled_sf_data, crs = st_crs(state_region_subregion_boundaries))\n\n# Perform spatial join to add state/region information to the conflict dataset\nacled_with_state_region &lt;- st_join(conflict_acled_sf_data, state_region_subregion_boundaries, join = st_intersects)\n\n# Filter out rows where ST is NA before summarizing\nacled_with_state_region &lt;- acled_with_state_region %&gt;%\n  filter(!is.na(ST))\n\n# Group by state/region and summarize conflict data\nconflict_summary_by_state_region &lt;- acled_with_state_region %&gt;%\n  group_by(ST, event_type, year) %&gt;%\n  summarise(\n    total_conflicts = n(),\n    total_fatalities = sum(fatalities, na.rm = TRUE),\n    .groups = 'drop'\n  )\n\n# Convert district boundaries to a regular data frame (non-spatial)\nstate_region_boundaries_df &lt;- as.data.frame(state_region_subregion_boundaries)\n\n# Merge the summary data with the district boundaries data frame\nstate_region_boundaries_summary &lt;- state_region_boundaries_df %&gt;%\n  left_join(conflict_summary_by_state_region, by = c(\"ST\" = \"ST\"))\n\n# Convert back to an sf object with geometry\nstate_region_boundaries_summary &lt;- st_as_sf(state_region_boundaries_summary, crs = st_crs(state_region_subregion_boundaries))\n\n\n\n2.4.2 Plot the Hotspots\n\n# Base map with state/region boundaries\nstate_region_hotspot_tm &lt;- tm_shape(state_region_boundaries_summary) +\n  tm_polygons(col = \"lightgrey\", border.col = \"black\") +\n  \n  # Overlay conflict data\n  tm_shape(conflict_summary_by_state_region) +\n  tm_dots(\n    col = \"event_type\", \n    palette = \"viridis\", \n    size = \"total_conflicts\", \n    alpha = 0.6)  +\n  \n  # Layout adjustments\n  tm_layout(\n    frame = FALSE,  # Remove the frame around the plot\n    legend.outside = TRUE,  # Keep the legend outside\n    legend.outside.position = \"bottom\",  # Position the legend outside at the bottom\n    legend.outside.size = 0.1,  # Adjust the size of the outside legend (reduce if too large)\n  ) +\n  \n  # Faceting by state/region\n  tm_facets(\n    by = c(\"ST\"),\n    free.scales = FALSE  # Use a common scale across all facets\n  )\n\nprint(state_region_hotspot_tm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nThis map illustrates conflict patterns across a four-year period, revealing significant regional variations. It highlights that certain states and regions experience relatively lower levels of conflict, indicating greater overall peace.\nConversely, other areas show higher concentrations of specific types of conflicts. This distribution helps identify regions with frequent conflict events and those more prone to particular conflict types, offering valuable insights into the geographical and thematic spread of conflicts.\n\n\n\n\n2.4.3 Visualize by Event Type\n\n# Define the conflict types\nconflict_types &lt;- c(\"Battles\", \"Protests\", \"Strategic developments\", \"Explosions/Remote violence\", \"Riots\", \"Violence against civilians\")\n\n# Initialize an empty list to store summaries\nconflict_summaries &lt;- list()\n\n# Loop through each conflict type and summarize the data\nfor (type in conflict_types) {\n  summary &lt;- acled_with_state_region %&gt;%\n    filter(event_type == type) %&gt;%\n    group_by(ST) %&gt;%\n    summarise(\n      total_events = n(),\n      .groups = 'drop'\n    )\n  \n  # Store the summary in the list with the conflict type as the key\n  conflict_summaries[[type]] &lt;- summary\n}\n\n# Convert district boundaries to a regular data frame (non-spatial)\nstate_region_subregion_boundaries_df &lt;- as.data.frame(state_region_subregion_boundaries)\n\n# Merge each summary with the district boundaries data frame\nregion_conflict_summaries &lt;- lapply(conflict_summaries, function(summary) {\n  region_summary &lt;- state_region_subregion_boundaries_df %&gt;%\n    left_join(summary, by = \"ST\")\n  \n  # Convert back to an sf object with geometry\n  st_as_sf(region_summary, crs = st_crs(state_region_subregion_boundaries))\n})\n\n# Rename the list elements for clarity\nnames(region_conflict_summaries) &lt;- conflict_types\n\n\n# Create a list to store plots\nplots &lt;- list()\n\n# Loop through each conflict type to create a plot\nfor (type in conflict_types) {\n  plots[[type]] &lt;- tm_shape(region_conflict_summaries[[type]]) +\n    tm_polygons(\n      col = \"total_events\", \n      palette = \"Reds\", \n      title = paste(\"Number of\", type),\n      border.col = \"black\",\n      style = \"quantile\"  # This divides the data into quantiles for better visualization\n    ) +\n    \n    tm_text(\n      text = \"ST\",  # Use the column name that contains the region names\n      size = 0.6,        # Adjust the size as needed\n      col = \"black\",     # Text color\n      shadow = TRUE,    # Optional: Add shadow to make text more readable\n      remove.overlap = TRUE  # Avoid text overlapping\n    ) +\n    \n    tm_layout(\n      frame = FALSE,  # Remove the frame around the plot\n      legend.outside = TRUE,  # Keep the legend outside\n      legend.outside.position = \"right\",  # Position the legend outside at the bottom\n      legend.outside.size = 0.4  # Adjust the size of the outside legend (reduce if too large)\n    ) +\n    \n    tm_legend(\n      position = c(\"right\", \"bottom\")  # Position the legend outside at the bottom\n    )\n}\n\n\n# Arrange all plots in a single view using tm_arrange\ncombined_plot &lt;- tmap_arrange(plots, ncol = 2, nrow = 3, \n                             legend.position = c(\"right\", \"bottom\"), \n                             legend.outside = TRUE)\n\n# Print the combined plot\nprint(combined_plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.0 Deriving Quarterly KDE layers\nKernel Density Estimation (KDE) provides a comprehensive view of where conflicts are occurring by visualizing the density of events across different quarters. By analyzing KDE on a quarterly basis, we can identify areas with high conflict intensity and gain insights into how the distribution of conflicts evolves over time. This approach helps in understanding temporal patterns and hotspots, offering a more detailed perspective on conflict dynamics.\nFor quarterly KDE layers:\n\nSubset data by quarter and compute KDE for each subset using spatstat\n\n\n\n\n\n\n\nNote on Handling Duplicate Points\n\n\n\nDuplicate points are removed in the analysis to avoid artificially inflating the density estimate. Including duplicates could lead to an exaggerated representation of conflict hotspots, as each duplicate would incorrectly suggest multiple occurrences of the same event. By removing duplicates, we ensure that the Kernel Density Estimation (KDE) reflects the true intensity and distribution of distinct armed conflict events, providing a more accurate and reliable identification of hotspots.\n\n\n\n1. Create a list to store KDE for each quarter\n\nkde_list &lt;- list()\n\n\n\n2. Get Unique Quarters\n\nquarters &lt;- unique(conflict_acled_sf_data$quarter)\n\n\n\n3. Perform Kernel Density Estimation (KDE)\n\nboundary_window &lt;- as.owin(national_boundaries)\n\n# Loop over each quarter to process data\nfor (q in quarters) {\n  \n  # Filter the dataset for the current quarter\n  quarter_data &lt;- conflict_acled_sf_data %&gt;%\n    filter(quarter == q)\n  \n  # Remove duplicates\n  coords &lt;- st_coordinates(st_geometry(quarter_data))\n  if (any(duplicated(coords))) {\n    quarter_data &lt;- quarter_data %&gt;%\n      distinct(st_coordinates(st_geometry(.)), .keep_all = TRUE)\n  }\n  \n  # Convert the filtered data to a spatial point pattern (ppp object)\n  quarter_ppp &lt;- as.ppp(st_geometry(quarter_data), W = boundary_window)\n  \n  # Perform Kernel Density Estimation (KDE)\n  kde &lt;- density(quarter_ppp, sigma = 0.1)  # Adjust sigma as needed for smoothness\n  \n  # Store KDE in the list\n  kde_list[[q]] &lt;- kde\n}\n\nWarning: 2 points were rejected as lying outside the specified window\n\n\nWarning: 1 point was rejected as lying outside the specified window\nWarning: 1 point was rejected as lying outside the specified window\nWarning: 1 point was rejected as lying outside the specified window\n\n\n\n\n4. Plot the KDE for Each Quarter\n\npar(mfcol=c(5, 3))\n# Plot the KDEs for all quarters\nfor (q in quarters) {\n  if (!is.null(kde_list[[q]])) {\n    plot(kde_list[[q]], main = paste(\"KDE for\", q))\n  } else {\n    print(paste(\"No KDE available for quarter:\", q))\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n3.0 Performing 2nd-Order Spatial Point Patterns Analysis\nNow, we will explore how armed conflict events are distributed and related.\nRipley’s K-function is a useful tool for detecting whether events are clustered or spread out. It measures how the density of events changes with distance, helping to identify clustering or dispersion.\nWhereas G-Function examine the nearest-neighbor distances and understand how far apart the nearest events are.\nF-Function analyze the distribution of distances from a randomly chosen location to the nearest event\n\nComputing K-Function Estimation\n\n# Initialize list to store K-function results\nkfunction_list &lt;- list()\n\n# Get unique quarters from the dataset\nquarters &lt;- unique(conflict_acled_sf_data$quarter)\n\n# Loop over each quarter to compute K-function\nfor (q in quarters) {\n  \n  # Filter the dataset for the current quarter\n  quarter_data &lt;- conflict_acled_sf_data %&gt;%\n    filter(quarter == q)\n  \n  # Remove duplicates\n  coords &lt;- st_coordinates(st_geometry(quarter_data))\n  if (any(duplicated(coords))) {\n    quarter_data &lt;- quarter_data %&gt;%\n      distinct(st_coordinates(st_geometry(.)), .keep_all = TRUE)\n  }\n  \n  # Convert the filtered data to a spatial point pattern (ppp object)\n  quarter_ppp &lt;- as.ppp(st_geometry(quarter_data), W = as.owin(national_boundaries))\n  \n  # Compute the K-function\n  kfunction &lt;- Kest(quarter_ppp, correction = \"border\")\n  \n  # Store the K-function in the list\n  kfunction_list[[q]] &lt;- kfunction\n}\n\nWarning: 2 points were rejected as lying outside the specified window\n\n\nWarning: 1 point was rejected as lying outside the specified window\nWarning: 1 point was rejected as lying outside the specified window\nWarning: 1 point was rejected as lying outside the specified window\n\n\n\n\n\n\n\n\nNote\n\n\n\nRipley’s Correction: Provides a more sophisticated adjustment for edge effects by modifying the expected K-function, leading to potentially more accurate results in large areas. Border Correction: Simplifies the adjustment by extending the study area and is less computationally intensive but might be less accurate in areas with significant boundary effects.\nWe use correction = “border” rather than correction = “Ripley” for our analysis. Our primary goal is to observe the general distribution of conflict hotspots, which will guide more detailed follow-up studies. Given that our focus is on broad patterns rather than precise details, the simpler and less computationally intensive border correction is sufficient. While Ripley’s correction offers more accuracy by adjusting for edge effects, it requires more computational resources and time, which we can afford to forego for this preliminary analysis.\n\n\n\n\nPlotting K-Function\nInterpretation:\n\nAbove the theoretical line: Indicates clustering of points.\nBelow the theoretical line: Suggests dispersion or regularity.\nClose to the line: Implies a random distribution.\n\n\npar(mfcol=c(5, 3))\n# Plot the K-functions for all quarters\nfor (q in quarters) {\n  if (!is.null(kfunction_list[[q]])) {\n    # Plot K-function\n    plot(kfunction_list[[q]], . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\", main = paste(\"K-function for Quarter\", q))\n  } else {\n    print(paste(\"No K-function available for quarter:\", q))\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n4.0 Deriving Quarterly spatio-temporal KDE layers\n\n# Define the output directory for saving KDE plots\noutput_dir &lt;- \"quarterly_kde_images\"\ndir.create(output_dir, showWarnings = FALSE)\n\n# Define a list to hold filenames of saved KDE plots\nsaved_files &lt;- list()\n\n# Define a function to create and save KDE plots for each quarter\nsave_kde_plot &lt;- function(kde, quarter, output_dir) {\n  # Create a file path for the KDE image\n  file_name &lt;- file.path(output_dir, paste0(\"quarterly_kde_\", gsub(\" \", \"_\", quarter), \".png\"))\n  \n  # Open a PNG device to save the plot\n  png(file_name, width = 800, height = 800)\n  \n  # Plot KDE\n  plot(kde, main = paste(\"Spatio-Temporal KDE for\", quarter))\n  \n  # Close the PNG device\n  dev.off()\n  \n  # Print confirmation message\n  print(paste(\"Saved:\", file_name))\n  \n  # Return the filename of the saved plot\n  return(file_name)\n}\n\n# Generate and save KDE plots for each quarter in reverse chronological order\nfor (q in rev(quarters)) {\n  if (!is.null(kde_list[[q]])) {\n    file_name &lt;- save_kde_plot(kde_list[[q]], q, output_dir)\n    saved_files &lt;- append(saved_files, file_name)\n  } else {\n    print(paste(\"No KDE data available for quarter:\", q))\n  }\n}\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q1-2021.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q2-2021.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q3-2021.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q4-2021.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q1-2022.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q2-2022.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q3-2022.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q4-2022.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q1-2023.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q2-2023.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q3-2023.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q4-2023.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q1-2024.png\"\n\n\n[1] \"Saved: quarterly_kde_images/quarterly_kde_Q2-2024.png\"\n\n\n\n# Load saved images and combine them into an animated GIF\nimages &lt;- lapply(saved_files, image_read)\n\n# Create an animation from the KDE images\nanimation &lt;- image_animate(image_join(images), fps = 1)\n\n# Define the path for the GIF animation\ngif_path &lt;- \"spatio_temporal_kde_animation.gif\"\n\n# Save the animation as a GIF file\nimage_write(animation, path = gif_path)\n\n# Print confirmation that the GIF was saved\nprint(\"Spatio-temporal KDE animation saved as spatio_temporal_kde_animation.gif\")\n\n[1] \"Spatio-temporal KDE animation saved as spatio_temporal_kde_animation.gif\"\n\n# Display the GIF using magick\ngif_image &lt;- image_read(gif_path)\nprint(gif_image) \n\n# A tibble: 14 × 7\n   format width height colorspace matte filesize density\n   &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n 1 GIF      800    800 sRGB       FALSE        0 72x72  \n 2 GIF      800    800 sRGB       FALSE        0 72x72  \n 3 GIF      800    800 sRGB       FALSE        0 72x72  \n 4 GIF      800    800 sRGB       FALSE        0 72x72  \n 5 GIF      800    800 sRGB       FALSE        0 72x72  \n 6 GIF      800    800 sRGB       FALSE        0 72x72  \n 7 GIF      800    800 sRGB       FALSE        0 72x72  \n 8 GIF      800    800 sRGB       FALSE        0 72x72  \n 9 GIF      800    800 sRGB       FALSE        0 72x72  \n10 GIF      800    800 sRGB       FALSE        0 72x72  \n11 GIF      800    800 sRGB       FALSE        0 72x72  \n12 GIF      800    800 sRGB       FALSE        0 72x72  \n13 GIF      800    800 sRGB       FALSE        0 72x72  \n14 GIF      800    800 sRGB       FALSE        0 72x72  \n\n\n\n\n\n\n\n\n\n\n\n5.0 Performing 2nd-Order Spatio-temporal Point Patterns\n\n# Define the output directory for saving K-function plots\nkfunction_output_dir &lt;- \"quarterly_kfunction_images\"\ndir.create(kfunction_output_dir, showWarnings = FALSE)\n\n# Define a list to hold filenames of saved K-function plots\nkfunction_files &lt;- list()\n\n# Define a function to create and save K-function plots for each quarter\nsave_kfunction_plot &lt;- function(kfunction, quarter, output_dir) {\n  # Create a file path for the K-function image\n  file_name &lt;- file.path(output_dir, paste0(\"quarterly_kfunction_\", gsub(\" \", \"_\", quarter), \".png\"))\n  \n  # Open a PNG device to save the plot\n  png(file_name, width = 800, height = 800)\n  \n  # Plot K-function\n  plot(kfunction, . -r ~ r, ylab = \"K(d) - d\", xlab = \"d (m)\", main = paste(\"Ripley's K-function for Quarter\", quarter))\n  \n  # Close the PNG device\n  dev.off()\n  \n  # Print confirmation message\n  print(paste(\"Saved:\", file_name))\n  \n  # Return the filename of the saved plot\n  return(file_name)\n}\n\n# Save K-function plots for each quarter\nfor (q in rev(quarters)) {\n  if (!is.null(kfunction_list[[q]])) {\n    file_name &lt;- save_kfunction_plot(kfunction_list[[q]], q, kfunction_output_dir)\n    kfunction_files &lt;- append(kfunction_files, file_name)\n  } else {\n    print(paste(\"No K-function data available for quarter:\", q))\n  }\n}\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q1-2021.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q2-2021.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q3-2021.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q4-2021.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q1-2022.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q2-2022.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q3-2022.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q4-2022.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q1-2023.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q2-2023.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q3-2023.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q4-2023.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q1-2024.png\"\n\n\n[1] \"Saved: quarterly_kfunction_images/quarterly_kfunction_Q2-2024.png\"\n\n\n\n# Load saved images and combine them into an animated GIF\nkfunction_images &lt;- lapply(kfunction_files, image_read)\n\n# Create an animation from the K-function images\nkfunction_animation &lt;- image_animate(image_join(kfunction_images), fps = 1)\n\n# Define the path for the GIF animation\nkfunction_gif_path &lt;- \"spatio_temporal_kfunction_animation.gif\"\n\n# Save the animation as a GIF file\nimage_write(kfunction_animation, path = kfunction_gif_path)\n\n# Print confirmation that the GIF was saved\nprint(\"Ripley's K-function animation saved as spatio_temporal_kfunction_animation.gif\")\n\n[1] \"Ripley's K-function animation saved as spatio_temporal_kfunction_animation.gif\"\n\n# Display the GIF using magick\nkfunction_gif_image &lt;- image_read(kfunction_gif_path)\nprint(kfunction_gif_image)\n\n# A tibble: 14 × 7\n   format width height colorspace matte filesize density\n   &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n 1 GIF      800    800 sRGB       FALSE        0 72x72  \n 2 GIF      800    800 sRGB       FALSE        0 72x72  \n 3 GIF      800    800 sRGB       FALSE        0 72x72  \n 4 GIF      800    800 sRGB       FALSE        0 72x72  \n 5 GIF      800    800 sRGB       FALSE        0 72x72  \n 6 GIF      800    800 sRGB       FALSE        0 72x72  \n 7 GIF      800    800 sRGB       FALSE        0 72x72  \n 8 GIF      800    800 sRGB       FALSE        0 72x72  \n 9 GIF      800    800 sRGB       FALSE        0 72x72  \n10 GIF      800    800 sRGB       FALSE        0 72x72  \n11 GIF      800    800 sRGB       FALSE        0 72x72  \n12 GIF      800    800 sRGB       FALSE        0 72x72  \n13 GIF      800    800 sRGB       FALSE        0 72x72  \n14 GIF      800    800 sRGB       FALSE        0 72x72  \n\n\n\n\n\n\n\n\n\n\n\n6.0 KDE and Spatio-temporal KDE layers on openstreetmap of Myanmar\n\n6.1 Download OSM Data for Mynmar\n\n# Get bounding box for Myanmar\nbbox_myanmar &lt;- getbb(\"Yangon\")\n\n# Create Overpass query\nquery &lt;- opq(bbox = bbox_myanmar) \n\n# Download data\nosm_data &lt;- osmdata_sf(query)\n\n\n# Create a basic plot of the OSM data using tmap\ntm_shape(osm_data$osm_points) +\n  tm_dots( # Using tm_dots instead of tm_lines for point data\n    col = \"blue\", # Color of the dots\n    size = 0.01, # Size of the dots (adjust as needed)\n    alpha = 0.7 # Transparency of the dots\n  ) +\n  tm_layout(\n    frame = FALSE, # Remove the frame around the plot\n    legend.outside = TRUE, # Place the legend outside the plot\n    legend.outside.position = \"bottom\", # Position the legend outside at the bottom\n    legend.outside.size = 0.1 # Adjust the size of the outside legend (reduce if too large)\n  ) +\n  tm_scale_bar() # Add a scale bar to the map\n\n\n\n6.2 Extract Points and Prepare Data for KDE\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nacled_sf %&gt;% \n  filter(year == 2024 |\n           event_type == \"Polticial Violence\") %&gt;% \n  tm_shape() +\n  tm_dots()\n\n\n\n\n\n\n\n\n\n# Prepare a list to store tmap objects for each quarter\ntmap_list &lt;- list()\n\n# Loop through each quarter\nfor (q in quarters) {\n  \n  # Filter the dataset for the current quarter\n  quarter_data &lt;- conflict_acled_sf_data %&gt;%\n    filter(quarter == q)\n  \n  # Remove duplicates\n  coords &lt;- st_coordinates(st_geometry(quarter_data))\n  if (any(duplicated(coords))) {\n    quarter_data &lt;- quarter_data %&gt;%\n      distinct(st_coordinates(st_geometry(.)), .keep_all = TRUE)\n  }\n  \n  # Create a tmap visualization\n  tmap_plot &lt;- tm_shape(state_region_subregion_boundaries) +\n    tm_polygons() +\n    tm_shape(quarter_data) +\n    tm_dots(size = 0.01, col = \"event_type\", title = \"Conflicts\") +\n    tm_layout(title = paste(\"Conflicts for\", q),\n              title.size = 1.2,\n              legend.outside = TRUE)\n  \n  # Store the tmap object in the list\n  tmap_list[[q]] &lt;- tmap_plot\n}\n\n# Print all tmap plots\nfor (q in quarters) {\n  if (!is.null(tmap_list[[q]])) {\n    print(tmap_list[[q]])\n  } else {\n    print(paste(\"No data available for quarter:\", q))\n  }\n}"
  },
  {
    "objectID": "Notes/Lesson_5.html",
    "href": "Notes/Lesson_5.html",
    "title": "Notes 5",
    "section": "",
    "text": "A way to define spatial neighbourhood\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt measure from centroid!\nNeed to clean data properly. EG. If we only need to find the childcare in SG, we should remove the outer island, else u might see centroid being not in the center of where you expect it"
  },
  {
    "objectID": "Notes/Lesson_5.html#spatial-weights-wij",
    "href": "Notes/Lesson_5.html#spatial-weights-wij",
    "title": "Notes 5",
    "section": "",
    "text": "A way to define spatial neighbourhood\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt measure from centroid!\nNeed to clean data properly. EG. If we only need to find the childcare in SG, we should remove the outer island, else u might see centroid being not in the center of where you expect it"
  },
  {
    "objectID": "Notes/Lesson_2.html",
    "href": "Notes/Lesson_2.html",
    "title": "Notes 2",
    "section": "",
    "text": "A type of thematic map, areas shaded, values aggregated into geographical layer (eg. subzone)\nThe shading is the things we want to map (eg. Dependency ratio)\n\n\n\n\n\n\ncombines areal units into small no. of groups (10 methods eg. ‘equal’, ‘quantile’)\n\nNo. of Classes\n\nif &lt;4, overly generalized map [Can use depending on context, eg. USA election, red camp VS blue camp]\nkeep &lt;= 12, 7/8 shades of the same color\nif too many, our eyes cannot differentiate them wel\n\n\nequal = divide into same range (not suitable for highly skewed data set)\nquantile -&gt; into different percentage\nnatural breaks (a.k.a. jenks) -&gt; fuse between equal & quantile method\nstandard deviation -&gt; if data is normal distribution only\n\n\n\n\nmap it to the color, spectrum (the value) (eg. 0 -&gt; 223)\n\n\n\n\n\n\n* Nominal Color Scheme -&gt; Only for categorical data\n\n\n\n\n\n\n\nColor Scheme\nRemarks\n\n\n\n\n\nOnly for categorical data\n\n\n\nFor continuous\n+\nAll value +/-\n\n\n\nFor continuous\n+\nValue have both +/- only"
  },
  {
    "objectID": "Notes/Lesson_2.html#types-of-choropleth-map",
    "href": "Notes/Lesson_2.html#types-of-choropleth-map",
    "title": "Notes 2",
    "section": "",
    "text": "combines areal units into small no. of groups (10 methods eg. ‘equal’, ‘quantile’)\n\nNo. of Classes\n\nif &lt;4, overly generalized map [Can use depending on context, eg. USA election, red camp VS blue camp]\nkeep &lt;= 12, 7/8 shades of the same color\nif too many, our eyes cannot differentiate them wel\n\n\nequal = divide into same range (not suitable for highly skewed data set)\nquantile -&gt; into different percentage\nnatural breaks (a.k.a. jenks) -&gt; fuse between equal & quantile method\nstandard deviation -&gt; if data is normal distribution only\n\n\n\n\nmap it to the color, spectrum (the value) (eg. 0 -&gt; 223)"
  },
  {
    "objectID": "Notes/Lesson_2.html#colour-scheme--colorbrewer",
    "href": "Notes/Lesson_2.html#colour-scheme--colorbrewer",
    "title": "Notes 2",
    "section": "",
    "text": "* Nominal Color Scheme -&gt; Only for categorical data\n\n\n\n\n\n\n\nColor Scheme\nRemarks\n\n\n\n\n\nOnly for categorical data\n\n\n\nFor continuous\n+\nAll value +/-\n\n\n\nFor continuous\n+\nValue have both +/- only"
  },
  {
    "objectID": "Notes/Lesson_2.html#shape-objects",
    "href": "Notes/Lesson_2.html#shape-objects",
    "title": "Notes 2",
    "section": "Shape objects",
    "text": "Shape objects\n\n\ntmap element\n-&gt; always start with tm_shape()\n* Put plus(+) sign to indicate it is a continuous code (Put it at the back)\n\n-&gt; can later add\n\n-&gt;can choose from this list\n\n\n\n\ntm_polygons()\n\ndefault classes = 5bins\ndefault classification method = “pretty”\ndefault color scheme = “YIOrRd” (yellow-orange)\nmissing value = gray\n\n\n\n\ntm_border()\n\ndefault lwd (border line width) = 1\nalpha = between 0 (totally transparent) and 1 (not transparent)\n\nDefault alpha = 1\n\ncol (border color)\ndefault lty (border line type) = “solid”"
  },
  {
    "objectID": "Notes/Lesson_2.html#map-geographical-data",
    "href": "Notes/Lesson_2.html#map-geographical-data",
    "title": "Notes 2",
    "section": "Map & Geographical Data",
    "text": "Map & Geographical Data"
  },
  {
    "objectID": "Notes/Lesson_2.html#geo-vs-aspatial-data",
    "href": "Notes/Lesson_2.html#geo-vs-aspatial-data",
    "title": "Notes 2",
    "section": "Geo VS Aspatial Data",
    "text": "Geo VS Aspatial Data\n\n\n\n\n\n\n\n\n\nReference Maps\nshow buildings, roads, vegetation, rivers\neg. topo map like Google Map\n\n\nThematic Map\n\nemphasize the spatial pattern of geographic attributes or statistics about places and relationships between places such as Life in Los Angeles."
  },
  {
    "objectID": "Notes/Lesson_2.html#qualitative-thematic-map",
    "href": "Notes/Lesson_2.html#qualitative-thematic-map",
    "title": "Notes 2",
    "section": "Qualitative Thematic Map",
    "text": "Qualitative Thematic Map\n\n\n\n\n\n\n\nPoint symbol map\nUse point to represent school types\n\n\n\nLine symbol map\nShow road network\nDifferent color intensity and thickness are used to differentiate hierarchy of roads\n\n\n\nArea Map\ndifferent colors to represent different land use types"
  },
  {
    "objectID": "Notes/Lesson_2.html#proportional-symbol-map",
    "href": "Notes/Lesson_2.html#proportional-symbol-map",
    "title": "Notes 2",
    "section": "Proportional Symbol Map",
    "text": "Proportional Symbol Map\nUse symbols of different sizes to represent data associated with different areas\n\nGo for this kind:"
  },
  {
    "objectID": "Notes/Lesson_2.html#proportional-symbol-map--bar-chart-map",
    "href": "Notes/Lesson_2.html#proportional-symbol-map--bar-chart-map",
    "title": "Notes 2",
    "section": "Proportional Symbol Map -Bar Chart Map",
    "text": "Proportional Symbol Map -Bar Chart Map"
  },
  {
    "objectID": "Notes/Lesson_2.html#proportional-symbol-map--pie-chart-map",
    "href": "Notes/Lesson_2.html#proportional-symbol-map--pie-chart-map",
    "title": "Notes 2",
    "section": "Proportional Symbol Map -Pie Chart Map",
    "text": "Proportional Symbol Map -Pie Chart Map"
  },
  {
    "objectID": "Notes/Lesson_2.html#proportional-symbol-map--junk-map",
    "href": "Notes/Lesson_2.html#proportional-symbol-map--junk-map",
    "title": "Notes 2",
    "section": "Proportional Symbol Map -Junk Map",
    "text": "Proportional Symbol Map -Junk Map\n\n* ensure geographical lvl used is same"
  },
  {
    "objectID": "Notes/Lesson_2.html#brick-map",
    "href": "Notes/Lesson_2.html#brick-map",
    "title": "Notes 2",
    "section": "Brick Map",
    "text": "Brick Map\n\nbetter to encode quantitative info graphically"
  },
  {
    "objectID": "Notes/Lesson_2.html#bricks-vs-proportional-symbol-map",
    "href": "Notes/Lesson_2.html#bricks-vs-proportional-symbol-map",
    "title": "Notes 2",
    "section": "Bricks VS Proportional Symbol Map",
    "text": "Bricks VS Proportional Symbol Map\n\n\nProportional Symbol map can be more difficult to distinguish than brick"
  },
  {
    "objectID": "Notes/Lesson_2.html#dot-density-map",
    "href": "Notes/Lesson_2.html#dot-density-map",
    "title": "Notes 2",
    "section": "Dot Density Map",
    "text": "Dot Density Map\n\na type of thematic map -&gt; use dot/symbols to show the values of &gt;= 1 numeric value\neach dot represent some amt of data"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS455",
    "section": "",
    "text": "Welcome to IS455 Geospatial Analytics and Application. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "Overview\nSpatio-Temporal Point Pattern: A random collection of points representing time and location of events (eg. disease incidences, species sightings, fires, earthquakes, lightning strikes, tsunamis, volcanic eruptions.)\nImportance: Increasingly necessary due to growth in geographically and temporally indexed data across various fields.\nApplication Example:\n\nAnalysis of forest fire events in Kepulauan Bangka Belitung, Indonesia (1 Jan 2023 - 31 Dec 2023).\n\nWe want to find out\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?\n\n\n\n1.0 Setup\n\n1.1 Installing R-Packages\nsf: provides functions for importing processing and wrangling geospatial data\nraster: for handling raster data in R\nspatstat: for performing Spatial Point Patterns Analysis such as kcross, Lcross, etc.\nsparr: provides functions to estimate fixed and adaptive kernel-smoothed spatial relative risk surfaces via the density-ratio method and perform subsequent inference. Fixed-bandwidth spatiotemporal density and relative risk estimation is also supported\ntmap: provides functions to produce cartographic quality thematic maps\ntidyverser: provide functions to perform common data science tasks including and not limited to data import, data transformation, data wrangling and data visualisation\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, sparr)\n\n\n\n1.2 Data Acquisition\nWe will be using 2 sets of data:\n\nforestfires (CSV file):\n\nContains locations of forest fires from MODIS sensor data.\nDownloaded from the Fire Information for Resource Management System.\nFocus: Only forest fires in Kepulauan Bangka Belitung.\n\nKepulauan_Bangka_Belitung (ESRI shapefile):\n\nShows sub-district boundaries (kelurahan) of Kepulauan Bangka Belitung.\nDownloaded from the Indonesia Geospatial Portal.\nFocus: Only sub-districts within Kepulauan Bangka Belitung (original data covers all of Indonesia).\n\n\n\n\n1.3 Importing And Preparing Study Area/Forest Fire data\n\nStudy AreaForest Fire Data\n\n\n\nImporting study area\n\nkbb &lt;- st_read(dsn = \"data/rawdata\",        \n               layer = \"Kepulauan_Bangka_Belitung\")\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\In-class_Ex\\In-class_Ex04\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nTo dissolve\n\nkbb_sf &lt;- kbb %&gt;% \n  st_union()\n\nst_as_s2(): dropping Z and/or M coordinate\n\n\nDrop the Z value in geometry so it become polygon\n\nkbb_sf &lt;- kbb_sf %&gt;% \n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 32748)\n\n\n\n\n\nImporting Fire Data\n\nfire_sf &lt;- read_csv(\"data/rawdata/forestfires.csv\") %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n           crs = 4326) %&gt;% \n  st_transform(crs = 32748)\n\nRows: 741 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): satellite, instrument, daynight\ndbl  (11): latitude, longitude, brightness, scan, track, acq_time, confidenc...\ndate  (1): acq_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nBecause ppp object only accept numerical or character as mark, we need to convert data type of acq_date to numeric.\n\nfire_sf &lt;- fire_sf %&gt;% \n  mutate(DayOfYear = yday(acq_date)) %&gt;% \n  mutate(Month_num = month(acq_date)) %&gt;% \n  mutate(Month_fac = month(acq_date,\n                           label = TRUE,\n                           abbr = FALSE))\n\n\n\n\n\n\n\n\n2.0 Creating owin\n\nkbb_owin &lt;- as.owin(kbb_sf)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\n\nclass(kbb_owin)\n\n[1] \"owin\"\n\n\n\n\n3.0 Visualising the Fire Points\n\n3.1 Overall plot\n\ntm_shape(kbb_sf)+\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\n\n3.2 Visualizing geographic distribution of forest fires by month\n\ntm_shape(kbb_sf) +\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots(size = 0.1) +\n  tm_facets(by=\"Month_fac\",\n            free.coords = FALSE, #if change to true, the zoom lvl will be to where the data is\n            drop.units = TRUE)\n\n\n\n\n\n\n\n\n\n\n3.3 Computing STKDE by Month\nusing spattemp.density()\n\n3.3.1 Extracting forest fires by month\n* This will create a new dataset with only the month & geometry data\n\nfire_month &lt;- fire_sf %&gt;% \n  select(Month_num)\n\n\n\n3.3.2 Creating ppp\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\nsummary(fire_month_ppp)\n\nMarked planar point pattern:  741 points\nAverage intensity 2.49258e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n                    (174200 x 170600 units)\nWindow area = 29728200000 square units\n\n\n\n\nCheck for duplicated point events\n\nany(duplicated(fire_month_ppp))\n\n[1] FALSE\n\n\n\n\n3.3.3 Including Owin Object\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nsummary(fire_month_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\n\nplot(fire_month_owin)\n\n\n\n\n\n\n\n\n\n\n\n\n4.0 Computing Spatio-temporal KDE\n\nst_kde &lt;- spattemp.density(fire_month_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]\n\n\n\nPlotting the spatio-temporal KDE object\n\ntims &lt;- c(7,8,9,10,11,12)\npar(mfcol=c(2,3))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at month\",i))\n}\n\n\n\n\n\n\n\n\n\n\n\n5.0 Computing STKDE by Day of Year\n\n5.1 Creating ppp object\n\nfire_yday_ppp &lt;- fire_sf %&gt;% \n  select(DayOfYear) %&gt;%\n  as.ppp()\n\n\n\n5.2 Including Owin object\n\nfire_yday_owin &lt;- fire_yday_ppp[kbb_owin]\nsummary(fire_yday_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   10.0   213.0   258.0   245.9   287.0   352.0 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\n\n\n5.3\n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 6.3198 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [3.959516e-27, 2.751287e-12]\n\n\n\nplot(kde_yday)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "Installing R-Packages\n\npacman::p_load(tidyverse, sf, ggstatsplot, tmap, spatstat, raster)\n\n\n\nInstalling Maptools\neval: false = avoid maptools being download and install repetitively every time the Quarto document been rendered.\n\ninstall.packages(\"maptools\",\n                 repos=\"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\n\nImporting Geospatial Data\n\nmpsz_sf &lt;- st_read(dsn = \"data/MasterPlan2014SubzoneBoundaryWebSHP\",                 \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\In-class_Ex\\In-class_Ex03\\data\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;% \n  st_transform(crs=3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\In-class_Ex\\In-class_Ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\nCreating coastal outline\nst_union() to derive the coastal outline sf tibble data.frame\n\nsg_sf &lt;- mpsz_sf %&gt;% \n  st_union()\n\nplot(sg_sf)\n\n\n\n\n\n\n\n\n\n\nCreating ppp objects from sf data.frame\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\nCreating owin object from sf data.frame\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n80 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            14650  6.97996e+08      8.93e-01\npolygon 2 (hole)         3 -2.21090e+00     -2.83e-09\npolygon 3              285  1.61128e+06      2.06e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.63e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.13e-11\npolygon 6              668  5.40368e+07      6.91e-02\npolygon 7               44  2.26577e+03      2.90e-06\npolygon 8               27  1.50315e+04      1.92e-05\npolygon 9              711  1.28815e+07      1.65e-02\npolygon 10 (hole)       36 -4.01660e+04     -5.14e-05\npolygon 11 (hole)      317 -5.11280e+04     -6.54e-05\npolygon 12 (hole)        3 -3.41405e-01     -4.37e-10\npolygon 13 (hole)        3 -2.89050e-05     -3.70e-14\npolygon 14              77  3.29939e+05      4.22e-04\npolygon 15              30  2.80002e+04      3.58e-05\npolygon 16 (hole)        3 -2.83151e-01     -3.62e-10\npolygon 17              71  8.18750e+03      1.05e-05\npolygon 18 (hole)        3 -1.68316e-04     -2.15e-13\npolygon 19 (hole)       36 -7.79904e+03     -9.97e-06\npolygon 20 (hole)        4 -2.05611e-02     -2.63e-11\npolygon 21 (hole)        3 -2.18000e-06     -2.79e-15\npolygon 22 (hole)        3 -3.65501e-03     -4.67e-12\npolygon 23 (hole)        3 -4.95057e-02     -6.33e-11\npolygon 24 (hole)        3 -3.99521e-02     -5.11e-11\npolygon 25 (hole)        3 -6.62377e-01     -8.47e-10\npolygon 26 (hole)        3 -2.09065e-03     -2.67e-12\npolygon 27              91  1.49663e+04      1.91e-05\npolygon 28 (hole)       26 -1.25665e+03     -1.61e-06\npolygon 29 (hole)      349 -1.21433e+03     -1.55e-06\npolygon 30 (hole)       20 -4.39069e+00     -5.62e-09\npolygon 31 (hole)       48 -1.38338e+02     -1.77e-07\npolygon 32 (hole)       28 -1.99862e+01     -2.56e-08\npolygon 33              40  1.38607e+04      1.77e-05\npolygon 34 (hole)       40 -6.00381e+03     -7.68e-06\npolygon 35 (hole)        7 -1.40545e-01     -1.80e-10\npolygon 36 (hole)       12 -8.36709e+01     -1.07e-07\npolygon 37              45  2.51218e+03      3.21e-06\npolygon 38             142  3.22293e+03      4.12e-06\npolygon 39             148  3.10395e+03      3.97e-06\npolygon 40              75  1.73526e+04      2.22e-05\npolygon 41              83  5.28920e+03      6.76e-06\npolygon 42             211  4.70521e+05      6.02e-04\npolygon 43             106  3.04104e+03      3.89e-06\npolygon 44             266  1.50631e+06      1.93e-03\npolygon 45              71  5.63061e+03      7.20e-06\npolygon 46              10  1.99717e+02      2.55e-07\npolygon 47             478  2.06120e+06      2.64e-03\npolygon 48             155  2.67502e+05      3.42e-04\npolygon 49            1027  1.27782e+06      1.63e-03\npolygon 50 (hole)        3 -1.16959e-03     -1.50e-12\npolygon 51              65  8.42861e+04      1.08e-04\npolygon 52              47  3.82087e+04      4.89e-05\npolygon 53               6  4.50259e+02      5.76e-07\npolygon 54             132  9.53357e+04      1.22e-04\npolygon 55 (hole)        3 -3.23310e-04     -4.13e-13\npolygon 56               4  2.69313e+02      3.44e-07\npolygon 57 (hole)        3 -1.46474e-03     -1.87e-12\npolygon 58            1045  4.44510e+06      5.68e-03\npolygon 59              22  6.74651e+03      8.63e-06\npolygon 60              64  3.43149e+04      4.39e-05\npolygon 61 (hole)        3 -1.98390e-03     -2.54e-12\npolygon 62 (hole)        4 -1.13774e-02     -1.46e-11\npolygon 63              14  5.86546e+03      7.50e-06\npolygon 64              95  5.96187e+04      7.62e-05\npolygon 65 (hole)        4 -1.86410e-02     -2.38e-11\npolygon 66 (hole)        3 -5.12482e-03     -6.55e-12\npolygon 67 (hole)        3 -1.96410e-03     -2.51e-12\npolygon 68 (hole)        3 -5.55856e-03     -7.11e-12\npolygon 69             234  2.08755e+06      2.67e-03\npolygon 70              10  4.90942e+02      6.28e-07\npolygon 71             234  4.72886e+05      6.05e-04\npolygon 72 (hole)       13 -3.91907e+02     -5.01e-07\npolygon 73              15  4.03300e+04      5.16e-05\npolygon 74             227  1.10308e+06      1.41e-03\npolygon 75              10  6.60195e+03      8.44e-06\npolygon 76              19  3.09221e+04      3.95e-05\npolygon 77             145  9.61782e+05      1.23e-03\npolygon 78              30  4.28933e+03      5.49e-06\npolygon 79              37  1.29481e+04      1.66e-05\npolygon 80               4  9.47108e+01      1.21e-07\nenclosing rectangle: [2667.54, 56396.44] x [15748.72, 50256.33] units\n                     (53730 x 34510 units)\nWindow area = 781945000 square units\nFraction of frame area: 0.422\n\n\n\n\nCombining point events object and owin object\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\nKernel Density Estimation of Spatial Point Event\nre-scale the unit of measurement to km before performing KDE\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, \n                                  1000, \n                                  \"km\")\n\nkde_childcareSG_adaptive &lt;- adaptive.density(\n  childcareSG_ppp.km, \n  method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\n\nconvert KDE output into grid object\nmaptools method\n\npar(bg = '#E4D5C9')\n\ngridded_kde_childcareSG_ad &lt;- maptools::as.SpatialGridDataFrame.im(\n  kde_childcareSG_adaptive)\n\nPlease note that 'maptools' will be retired during October 2023,\nplan transition at your earliest convenience (see\nhttps://r-spatial.org/r/2023/05/15/evolution4.html and earlier blogs\nfor guidance);some functionality will be moved to 'sp'.\n Checking rgeos availability: FALSE\n\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\nspatstat.geom method\n\ngridded_kde_childcareSG_ad &lt;- as(\n  kde_childcareSG_adaptive,\n  \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\n\n\n\nExtracting study area using sf objects\n\npg_owin &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\") %&gt;%\n  as.owin()\n\nchildcare_pg = childcare_ppp[pg_owin]\n\nplot(childcare_pg)  \n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, ggstatsplot, tmap)\n\n\nmpsz2014_shp = st_read(dsn = \"data/MasterPlan2014SubzoneBoundaryWebSHP\",                 \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\In-class_Ex\\In-class_Ex02\\data\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nTo know the data type:\n\nclass(mpsz2014_shp)\n\n[1] \"sf\"         \"data.frame\"\n\n\n\nmpsz2014_kml = st_read(\"data/MasterPlan2014SubzoneBoundaryWebKML.kml\")\n\n\nst_write(mpsz2014_shp,\n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n         delete_dsn = TRUE)\n\n\nmpsz2014_kml = st_read(\"data/MP14_SUBZONE_WEB_PL.kml\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\In-class_Ex\\In-class_Ex02\\data\\MP14_SUBZONE_WEB_PL.kml' \n  using driver `KML'\nSimple feature collection with 323 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz2019_shp = st_read(dsn = \"data/MPSZ-2019\",                 \n               layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\In-class_Ex\\In-class_Ex02\\data\\MPSZ-2019' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz2019_kml = st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\In-class_Ex\\In-class_Ex02\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\npopdata &lt;- read.csv(\"data/respopagesextod2023/respopagesextod2023.csv\")\n\n\npopdata2023 &lt;- popdata %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP`=sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG,\n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\n\npopdata2023 &lt;- popdata %&gt;%\n  filter(Time == 2023) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nTo standardize data of mpsz2019_shp and popdata2023, is case sensitive:\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\nmpsz_pop2023 &lt;- left_join(mpsz2019_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "Objective of spatial policy: Ensure equal distribution of development in the province.\nStudy Purpose: Use spatial statistics to check for even distribution of development.\nIf Not Even:\n\nInvestigate signs of spatial clustering (areas where development is grouped).\nIdentify where these clusters are located.\n\nFocus: Analyze the spatial pattern of GDP per capita in Hunan Province, China."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "Objective of spatial policy: Ensure equal distribution of development in the province.\nStudy Purpose: Use spatial statistics to check for even distribution of development.\nIf Not Even:\n\nInvestigate signs of spatial clustering (areas where development is grouped).\nIdentify where these clusters are located.\n\nFocus: Analyze the spatial pattern of GDP per capita in Hunan Province, China."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#setup",
    "title": "Hands-on Exercise 6",
    "section": "2.0 Setup",
    "text": "2.0 Setup\n\n2.1 Installing R-Packages\n\nsf: Importing and handling geospatial data in R\nspdep: Compute spatial weights, global and local spatial autocorrelation statistics\ntmap: Trepare cartographic quality chropleth map\ntidyverse: For wrangling attribute data in R\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)\n\n\n\n\n2.2 Data Acquisition\nTwo data sets will be used:\n\nHunan county boundary layer: a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: contains selected Hunan’s local development indicators in 2012.\n\n\nImporting Geospatial DataImporting Aspatial Data\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n2.3 Performing relational join\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n2.4 Visualising Regional Development Indicator\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation",
    "title": "Hands-on Exercise 6",
    "section": "3.0 Global Measures of Spatial Autocorrelation",
    "text": "3.0 Global Measures of Spatial Autocorrelation\n\nStep 1: Computing Contiguity Spatial WeightsStep 2: Row-standardised weights matrix\n\n\nBefore we can compute the Global Spatial autocorrelation statistics, we need to:\n\nConstruct spatial weights for the study area.\n\nBy Computing contiguity weight matrices based on adjacent regions.\nusing Queen Criteria:\n\nDefault is TRUE: Includes all neighbors that touch at edges or corners.\nYou can set queen = FALSE to consider only edge-touching neighbors (first-order neighbors).\n\n\nSo we can Define neighborhood relationships between geographical units (e.g., counties).\n\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere are 88 area units in Hunan.\nThe most connected area unit has 11 neighbours\nOnly 2 area aunits with 1 link\n\n\n\n\nNow, assign weights to each neighboring polygon.\n\nMethod: Assign each using equal weights (style = “W”)\nWeight Calculation:\n\nAssign weight of fraction 1/(#ofneighbors) to each neighboring county\nSum the weighted values (e.g., income) from neighbors.\n\nDrawback:\n\nEdge polygons have fewer neighbors, which can skew results (over- or under-estimate spatial autocorrelation).\n\nNote: For this example, we’ll use style = “W” for simplicity, but other options, like style = “B,” are more robust.\n\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe function nb2listw() requires an object of class nb (neighborhood list).\nstyle: Defines how weights are calculated. Options include:\n\n“W”: Row standardized weights (sums to 1 across neighbors).\n“B”: Basic binary coding (weights are either 0 or 1).\n“C”: Globally standardized weights (sums to the total number of connections).\n“U”: Equal weights divided by the number of neighbors (sums to 1).\n“minmax”: Min-max normalization (scales weights between 0 and 1).\n“S”: Variance-stabilizing coding (improves stability of weights).\n\nzero.poly:\n\nIf set to TRUE, this includes weights of zero for regions without neighbors.\nThis results in lag values of zero for those regions, which means they won’t affect the analysis.\nIt uses a formula that generates a vector of zeros for regions without neighbors, leading to a spatially lagged value of zero for those regions.\n\nSummary\n\nThe style argument determines how to handle the weights for neighboring regions.\nzero.poly allows for handling of regions that have no neighbors, potentially simplifying analysis but may not always be sensible."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-morans-i",
    "title": "Hands-on Exercise 6",
    "section": "3.0 Global Measures of Spatial Autocorrelation: Moran’s I",
    "text": "3.0 Global Measures of Spatial Autocorrelation: Moran’s I\n\nMaron’s I testComputing Monte Carlo Moran’s IVisualising Monte Carlo Moran’s IPlotting using ggplot2\n\n\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nFindings\n\n\n\nMoran I statistic (0.300749970) -&gt; indicate Positive correlation in GDP per capita\nSD of 4.7351 -&gt; indicate Moran’s I is &gt; expected value under null hypo\nP-value of 1.095e-06 (0.000001095) -&gt; is &lt; 0.05, indicates strong statistical significance\nExpectation of -0.011494253 -&gt; we expect slight negative autocorrelation if there were no spatial structure\nSince p-value &lt; 0.05, we reject null hypo of no spatial autocorrelation. This strongly suggests there is significant positive spatial clustering of GDPPC in Hunan Province. (Regions with High GDPPC is near areas with high GDPPC\n\n\n\n\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nFindings\n\n\n\nMoran I statistic (0.30075) -&gt; indicate Positive correlation in GDP per capita\nP-value of 0.001 -&gt; &lt; 0.05, indicates that the probability of obtaining a Moran’s I value as extreme as the observed &gt;= 1 under the null hypo\nThus, we reject null hypo as p value &lt; 0.05. There is strong evidence that areas with high GDPPC are near areas with high GDPPC\n\n\n\n\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\n\n\n\n# Create a data frame from the simulated results\ndata &lt;- data.frame(Simulated_Morans_I = bperm$res[1:999])\n\n# Plot using ggplot2\nggplot(data, aes(x = Simulated_Morans_I)) +\n  geom_histogram(binwidth = (max(data$Simulated_Morans_I) - min(data$Simulated_Morans_I)) / 20, \n                 fill = \"blue\", \n                 color = \"black\") +\n  geom_vline(xintercept = 0, \n             color = \"red\", \n             linetype = \"dashed\", \n             size = 1) +\n  labs(title = \"Histogram of Simulated Moran's I\",\n       x = \"Simulated Moran's I\",\n       y = \"Frequency\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "title": "Hands-on Exercise 6",
    "section": "3.0 Global Measures of Spatial Autocorrelation: Geary’s C",
    "text": "3.0 Global Measures of Spatial Autocorrelation: Geary’s C\n\nGeary’s C test\n\n\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\n\n\n\nFindings\n\n\n\nGeary C statistic (0.6907223) -&gt; indicate a level of spatial autocorrelation, lower value suggest positive spatial autocorrelation\nSD of 3.6108 -&gt; indicates significant lower than expected value under null hypo\nP-value of 0.0001526 -&gt; is &lt; 0.05, indicates strong statistical significance\nExpectation of 1.0000000 -&gt; on avg, we would expect no spatial autocorrelation\nSince p-value &lt; 0.05, we reject null hypo of no spatial autocorrelation. This strongly suggests there is significant positive spatial clustering of GDPPC in Hunan Province. (Regions with High GDPPC is near areas with high GDPPC than would be expected by chance\n\n\n\nComputing Monte Carlo Geary’s C\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nFindings\n\n\n\nGeary’s C Statistic (0.69072) -&gt; indicate some level of positive spatial autocorrelation\nObserved Rank of 1 -&gt; indicates that the observed value is the smallest among all the simulated values. This suggests that the observed spatial autocorrelation is much stronger than what would be expected under the null hypothesis.\nP-value of 0.001 -&gt; &lt; 0.05, indicates strong statistical significance\nThus, we reject null hypo as p value &lt; 0.05. There is strong evidence that areas with high GDPPC are near areas with high GDPPC\n\n\n\n\nVisualising Monte Carlo Geary’s C\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-monte-carlo-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-monte-carlo-gearys-c",
    "title": "Hands-on Exercise 6",
    "section": "Computing Monte Carlo Geary’s C",
    "text": "Computing Monte Carlo Geary’s C\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nFindings\n\n\n\nGeary’s C Statistic (0.69072) -&gt; indicate some level of positive spatial autocorrelation\nObserved Rank of 1 -&gt; indicates that the observed value is the smallest among all the simulated values. This suggests that the observed spatial autocorrelation is much stronger than what would be expected under the null hypothesis.\nP-value of 0.001 -&gt; &lt; 0.05, indicates strong statistical significance\nThus, we reject null hypo as p value &lt; 0.05. There is strong evidence that areas with high GDPPC are near areas with high GDPPC"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-monte-carlo-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-monte-carlo-gearys-c",
    "title": "Hands-on Exercise 6",
    "section": "Visualising Monte Carlo Geary’s C",
    "text": "Visualising Monte Carlo Geary’s C\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "title": "Hands-on Exercise 6",
    "section": "4.0 Spatial Correlogram",
    "text": "4.0 Spatial Correlogram\n\nSpatial Correlograms: Useful for examining patterns of spatial autocorrelation.\nFunction: Show how correlated pairs of spatial observations are as distance (lag) increases.\nPlot Type: Graphs of autocorrelation indices (like Moran’s I or Geary’s c) against distance.\nComparison with Variograms:\n\nNot as fundamental as variograms, which are key in geostatistics.\nProvide richer information for exploratory and descriptive analysis than variograms.\n\n\n\nCompute Moran’s I correlogramCompute Geary’s C correlogram and plot\n\n\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\n\nPlot Limitations:\n\nPlots may not give a complete interpretation of autocorrelation results.\nNot all autocorrelation values are statistically significant.\n\nImportance of Full Analysis:\n\nNecessary to examine the complete analysis report.\nPrinting the analysis results provides more detailed insights.\n\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nStatistical Observations\n\n\n\n\nPositive Autocorrelation:\n\nThe first three lags (1, 2, and 3) show positive Moran’s I values (0.30075, 0.20601, and 0.06683), indicating clustering of similar GDP per capita values at these distances.\n\nStatistical Significance:\n\nLags 1 and 2: Highly significant (p-values of 2.189e-06 and 2.029e-06), suggesting strong evidence of positive spatial autocorrelation.\nLag 3: Also significant (p-value of 0.0404), indicating some level of clustering, but less strong than the first two lags.\nLag 4: Not significant (p-value of 0.2260), suggesting a lack of clustering at this distance.\nLag 5 and 6: Show negative values (-0.15305 and -0.11871) with significant p-values (5.984e-05 and 0.008886), indicating that at these distances, similar values are less clustered.\n\nGeneral Trend:\n\nThe trend shows strong positive autocorrelation at shorter distances (lags 1-3), but transitions to negative autocorrelation at longer distances (lags 5-6).\n\n\n\nConclusion:\n\nThere is strong evidence of positive spatial clustering of GDP per capita in Hunan Province at shorter distances, but this pattern diminishes and even reverses at greater distances, suggesting that local clusters may dissipate as distance increases.\n\n\n\n\n\n\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#local-measures-of-spatial-autocorrelation-lmsa",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#local-measures-of-spatial-autocorrelation-lmsa",
    "title": "Hands-on Exercise 6",
    "section": "5.0 Local Measures of Spatial Autocorrelation (LMSA)",
    "text": "5.0 Local Measures of Spatial Autocorrelation (LMSA)\n\nFocus: Examines relationships between each observation and its surrounding observations.\n\n\n\nNature:\n\nNot summary statistics; they provide individual scores for each location.\nHelps understand the spatial structure of data.\n\nSimilarity to Global Measures:\n\nIntuition is similar to global statistics.\nSome global measures can be broken down into local measures.\n\nKey Examples:\n\nLocal Indicators of Spatial Association (LISA): Provides insights into local clustering and relationships.\nGetis-Ord’s Gi-statistics: Another LMSA method that offers complementary insights for geographic data.\n\n\n\n5.1 Local Indicators of Spatial Association(LISA)\n\nPurpose: Evaluate the presence of clusters and outliers in spatial data.\nExample: Analyzing GDP per capita in Hunan Province, China.\n\nClusters: Areas with significantly higher or lower GDP per capita than expected by chance.\nInterpretation: Identifies counties with values above or below a random distribution.\n\n\n\nStep 1: Computing Contiguity Spatial WeightsStep 2: Row-standardised weights matrix\n\n\nSame as how we compute for Global Indicators of Spatial Autocorrelation\n\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\nSame as how we compute for Global Indicators of Spatial Autocorrelation\n\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\nComputing local Moran’s IMapping the local Moran’s IMapping local Moran’s I valuesMapping local Moran’s I p-valuesMapping both local Moran’s I values and p-values\n\n\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\n\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n\nBefore mapping, Append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nthere is evidence for both positive and negative Ii values. Next we should consider p-values for each of these values\n\n\n\n\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.2 Creating a LISA Cluster Map\nPurpose: to categorize areas based on their spatial relationships.\n\nStep 1: Plotting Moran scatterplotStep 2: Plotting Moran scatterplot with standardised variable\n\n\neg.can show us whether counties with high GDP per capita are clustered together or if low GDP counties are near each other, indicating spatial patterns in economic development.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC.\nThis are high-high locations\n\n\n\n\n\nPurpose: Standardizes the GDP per capita variable for better comparison in the Moran scatterplot.\nSteps:\n\nCentering: Subtract the mean of the GDP per capita values (ignoring NAs) to center the data around zero.\nScaling: Divide the centered values by their standard deviation to standardize the data.\n\n\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\nas.vector(): Ensures the output is a vector, which fits neatly into the data frame for further analysis.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\n\n\nStep 3: Preparing LISA map classesPlotting Local Moran’s I and P-Values\n\n\nInitialize Quadrant Vector:\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nCalculate Spatially Lagged GDPPC & Center around its mean:\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nCenters the local Moran’s I values around their mean:\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nSet Significance Level:\n\nsignif &lt;- 0.05\n\nDefine Cluster Categories:\n\nAssigns values to the quadrant vector based on the relationships:\n\nLow-Low (1): Low lag and high local Moran’s I\nLow-High (2): High lag and low local Moran’s I\nHigh-Low (3): Low lag and low local Moran’s I\nHigh-High (4): High lag and high local Moran’s I\n\n\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4\n\nMarks locations with non-significant Moran’s I results as category 0:\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\nStep 4: Plotting LISA map\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\n\n\nPros:\n\nAllows for a clearer understanding of significant clusters and outliers.\nHelps identify not only where clusters exist but also their statistical significance.\n\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\ntmap_arrange(localMI.map, pvalue.map, asp=2, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-on Exercise 6",
    "section": "6.0 Hot Spot and Cold Spot Area Analysis",
    "text": "6.0 Hot Spot and Cold Spot Area Analysis\n\nPurpose: Identify hot spot (high-value) and cold spot (low-value) areas using localized spatial statistics.\nDefinition of Hot Spot: A region that has higher values relative to its surroundings.\n\n\n6.1 Getis and Ord’s G-Statistics\n\nA statistical method to detect spatial anomalies by analyzing neighbors within a certain distance.\nKey Steps:\n\nDerive Spatial Weight Matrix: Define neighbors based on distance, not just shared borders.\nCompute G_i Statistics: Calculate statistics to identify spatial clusters.\nMap G_i Statistics: Visualize the results to highlight hot and cold spots.\n\n\n\n\n6.2 Deriving Distance-Based Weight Matrix\nTypes of Matrices:\n\nFixed Distance Weight Matrix: Neighbors defined by a set distance.\nAdaptive Distance Weight Matrix: Neighbors defined by varying distances based on data density.\n\nDeriving the Centroid\n\nBecause Points are required to associate with each polygon for connectivity analysis.\n\n\n\nMap the centroid function to extract coordinates:\n\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\n\nDetermine the Cut-Off Distance\n\nto establish an upper limit for the distance band in spatial analysis.\n1) Find K Nearest Neighbors:\n\nUse knearneigh() from the spdep package to get indices of points that are the k nearest neighbors of each other.\n\n2) Convert to Neighbors List:\n\nTransform the output from knearneigh() into a neighbors list format using knn2nb(), which creates a list of neighbor region IDs.\n\n3) Calculate Distances:\n\nUse nbdists() to compute the lengths of the neighbor relationships, which gives distances in the coordinate units (kilometers if not projected).\n\n4) Flatten the List:\n\nRemove the list structure of the distances using unlist().\n\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\n\n\n\n\nNote\n\n\n\nMax is 61.79, can use this as the upper threshold.\nUsing this gives certainty that all units will have at least one neighbour\n\n\n\nComputing fixed distance weight matrixComputing adaptive distance weight matrix\n\n\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nconvert the nb object into spatial weights object:\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nPurpose: Address the variability in neighbor counts based on population density.\nCharacteristics:\n\nFixed Distance Weight Matrix:\n\nUrban areas often have more neighbors due to higher density.\nRural areas have fewer neighbors, leading to less smooth neighbor relationships.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSolution:\n\nUse k-nearest neighbors (k-NN) to control the number of neighbors directly.\nThis allows for more balanced neighbor relationships, either by accepting asymmetric neighbors or enforcing symmetry.\n\n\n\n\n\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "title": "Hands-on Exercise 6",
    "section": "7.0 Computing Gi statistics",
    "text": "7.0 Computing Gi statistics\n\nGi statistics using fixed distanceMapping Gi values with fixed distance weightsGi statistics using adaptive distanceMapping Gi values with adaptive distance weights\n\n\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nInterpretation of Gi Statistics:\n\nRepresented as a Z-score.\nHigher values indicate stronger clustering intensity.\nThe sign (positive or negative) shows whether it is a high or low cluster.\n\n\n\nJoining Gi Values to Hunan Data\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\n\n\n\n\n\nNote\n\n\n\nTasks Performed:\n\nConvert Output: Changes the G* values from a vector to a matrix using as.matrix().\nJoin Data: Uses cbind() to combine the original hunan data with the G* values, creating a new SpatialPolygonDataFrame called hunan.gi.\nRename Field: Renames the G* values column to gstat_fixed for clarity.\n\n\n\n\n\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "NetSPAA is used to analyze events that happen along networks, like roads or rivers.\neg.study where traffic accidents mostly happen on a road, or where childcare centers are located along streets\nIn this exercise, we’ll use a tool called spNetwork:\n\nNetwork Kernel Density Estimation (NKDE): This helps you see where events (like accidents) are happening the most along a network (like a road), showing areas where events are more common.\nNetwork G-function and K-function: These are methods to check if events are clustering together (happening close to each other) or if they’re spread out along the network."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "NetSPAA is used to analyze events that happen along networks, like roads or rivers.\neg.study where traffic accidents mostly happen on a road, or where childcare centers are located along streets\nIn this exercise, we’ll use a tool called spNetwork:\n\nNetwork Kernel Density Estimation (NKDE): This helps you see where events (like accidents) are happening the most along a network (like a road), showing areas where events are more common.\nNetwork G-function and K-function: These are methods to check if events are clustering together (happening close to each other) or if they’re spread out along the network."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#setup",
    "title": "Hands-on Exercise 4",
    "section": "2.0 Setup",
    "text": "2.0 Setup\n\n2.1 Installing R-Packages\n\nsf for handling geospatial data. It can manage, process, and manipulate Simple Features, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons.\nspNetwork, can perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\ntmap to plot cartographic quality static point patterns maps or interactive maps\n\n\npacman::p_load(sf, spNetwork, tmap, tidyverse)\n\n\n\n2.2 Data Acquisition\n2 datasets will be used to analyse the spatial distribution of childcare centre in Punggol planning area (Both data sets are in ESRI shapefile format):\n\nPunggol_St, a line features geospatial data which store the road network within Punggol Planning Area.\nPunggol_CC, a point feature geospatial data which store the location of childcare centres within Punggol Planning Area.\n\n\n\n2.3 Importing Geospatial Data into R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Display info about a topic/theme on a geographic location leveraging our spatial cognition & vision systems\nUsage exmaples\n\nVisualize population, temperature, crime rates, property prices using symbols\n\nObjective\n\nPlot functional & truthful choropleth maps using tmap packages\n\nOutcome"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview--thematic-map",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview--thematic-map",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Display info about a topic/theme on a geographic location leveraging our spatial cognition & vision systems\nUsage exmaples\n\nVisualize population, temperature, crime rates, property prices using symbols\n\nObjective\n\nPlot functional & truthful choropleth maps using tmap packages\n\nOutcome"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#setup",
    "title": "Hands-on Exercise 2",
    "section": "2.0 Setup",
    "text": "2.0 Setup\n\n2.1 Installing R-Packages\n\ntmap package\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data\n\n* Among the four packages, readr, tidyr and dplyr are part of tidyverse package. [Only need to install tidyverse]\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n2.2 Data Acquisition\n2 datasets will be used:\n\nURA Master Plan 2014 Subzone Boundary (Web) -(i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format\n\ngeographical boundary of Singapore at the planning subzone level\n\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 -(i.e. respopagesextod2011to2020.csv) in csv format\n\naspatial data file\nDoes not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\n2.3 Importing Geospatial Data into R\n\nImport MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz\n\n\nmpsz = st_read(dsn = \"data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP\",                 \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nExamine content of mpsz\n\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n* Why show 10 only? -&gt; Ans: By default, only show a subset of data.\n\nUse print(mpsz, n=20) -&gt; show 20 data\n\n\n\n2.4 Importing Aspatial Data into R\n\nImport Population data\n\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n2.5 Data Preparation and Wrangling\nTo create a thematic map, first, gather a data table for the year 2020. This table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n2.5.1 Data Wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package\n -&gt; \nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\nfilter\nonly take Time == 2020\n\n\nmutate\ncalculation\n\n\nmutate(YOUNG = rowSums(.[3:6]) + rowSums(.[12]))\n\nmutate(YOUNG = …): add new column ‘YOUNG’ to dataset\nrowSums(.[3:6]): calculate sum of values across column 3 to 6 each row\nrowSums(.[12]): return only column 12 value\n\n\n\n\n\npopdata2020\n\n# A tibble: 332 × 7\n   PA         SZ                   YOUNG `ECONOMY ACTIVE`  AGED TOTAL DEPENDENCY\n   &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Cen…  1440             2610   760  4810      0.843\n 2 Ang Mo Kio Cheng San             6640            15460  6050 28150      0.821\n 3 Ang Mo Kio Chong Boon            6150            13950  6470 26570      0.905\n 4 Ang Mo Kio Kebun Bahru           5540            12090  5120 22750      0.882\n 5 Ang Mo Kio Sembawang Hills       2100             3410  1310  6820      1    \n 6 Ang Mo Kio Shangri-La            3960             8420  3610 15990      0.899\n 7 Ang Mo Kio Tagore                2220             4200  1530  7950      0.893\n 8 Ang Mo Kio Townsville            4690            11450  5100 21240      0.855\n 9 Ang Mo Kio Yio Chu Kang             0                0     0     0    NaN    \n10 Ang Mo Kio Yio Chu Kang East     1220             2300   750  4270      0.857\n# ℹ 322 more rows\n\n\n\n\n2.5.2 Joining Geospatial Data and Attribute Data\nBefore performing georelational join,\n\nconvert values in PA & SZ fields to UPPERCASE -right now is both upper & lower case\n\n(SUBZONE_N and PLN_AREA_N are already in UPPERCASE)\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\nuse ‘left_join()’ from dplyr to merge geo data with the attribute table, matching them by the planning subzone names (like SUBZONE_N and SZ).\n\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n(By using mpsz as the starting point (the left table), we make sure that the result keeps all the special geographic information (like shapes and locations) from mpsz.)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 2",
    "section": "3.0 Choropleth Mapping Geospatial Data Using tmap",
    "text": "3.0 Choropleth Mapping Geospatial Data Using tmap\nChoropleth mapping is a way to show information on a map using colors or patterns for different areas like countries or states. For example, a researcher might use this type of map to show where older people live in Singapore based on specific zones.\nTo create these maps with the tmap package, you can:\n\nUse qtm() &gt; Plot a thematic map.\nUse tmap elements -&gt; Plot a more detailed and customized map.\n\n\n3.1 Plot with qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\",\n    fill.palette =\"plasma\")\n\n\n\n\n\n\n\n\ntmap_mode(“plot”) -&gt; produce static map\ntmap_mode(“view”) -&gt; interactive mode\nfill = “DEPENDENCY” -&gt; use this attribute to determine color fill for each polygon(area) on the map\n\n\n3.2 Usage of tmap’s element\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n3.3 Drawing a base map\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\nStart with tm_shape() -&gt; data to use for map\ntm_fill() and tm_polygons() -&gt; add details\n\n\n3.4 Drawing a choropleth map using tm_polygons()\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nDefault: Missing Value(grey), Color scheme of ColorBrewer(YlOrRd), Interval binning(pretty)\n\n\n3.5 Drawing a choropleth map using tm_fill() and tm_border()\nm_polygons() is a wraper of tm_fill() and tm_border(). \ntm_fill() -&gt; shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n* planning subzones are shared according to the respective dependecy values\ntm_borders()-&gt; add boundary of the planning subzones\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nalpha -&gt; transparency no. between 0 (totally transparent) and 1 (not transparent) [Default = 1]\n\ncol = border colour,\nlwd = border line width. default is 1\nlty = border line type. default is “solid”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "title": "Hands-on Exercise 2",
    "section": "4.0 Data classification methods of tmap",
    "text": "4.0 Data classification methods of tmap\n10 methods: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\n* Need to put style arg in tm_fill() or tm_polygons()\n\n4.1.0 style = “quantile”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n‘quantile’ are more evenly distributed than “equal”\n\n\n4.1.1 style = “equal”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.1.2 style = “sd”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.1.3 style = “pretty”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.1.4 style = “kmeans”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.1.5 style = “hclust”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.1.6 style = “bclust”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\n\n\n4.1.7 style = “fisher”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.1.8 style = “jenks”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-choropleth-maps-with-custom-breaks",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-choropleth-maps-with-custom-breaks",
    "title": "Hands-on Exercise 2",
    "section": "5.0 Plotting Choropleth Maps with Custom Breaks",
    "text": "5.0 Plotting Choropleth Maps with Custom Breaks\nFor built-in styles, the map automatically determines the category breaks.\nManual -&gt; use breaks argument in tm_fill(), in tmap (need specify n+1 values for n categories in ascending order, because each break range includes a min & max)\nCurrently,\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a min and max, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#colour-scheme",
    "title": "Hands-on Exercise 2",
    "section": "6.0 Colour Scheme",
    "text": "6.0 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n6.1 Using ColourBrewer palette\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-layouts",
    "title": "Hands-on Exercise 2",
    "section": "7.0 Map Layouts",
    "text": "7.0 Map Layouts\neg. Title, scale bar, compass, margins, aspects ratios\n\n7.1 Map Legend\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n7.2 Map Style (tmap_style)\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n7.3 Cartographic Furniture\nAdding compass, scale bar, grid\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n7.4 Drawing Small Multiple Choropleth Maps\nSmall multiple maps (a.k.a facet map)\nEnable the visualisation of how spatial relationships change with respect to another variable, such as time\nPlotted in 3 ways:\n\nassigning multiple values to &gt;= 1 asthetic arguments\ndefining a group-by variable in tm_facets()\ncreating multiple stand-alone maps with tmap_arrange()\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nDifferent color:\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\nGroup By using tm_facets():\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\nStand-alone maps using tmap_arrange():\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n7.4 Mapping Spatial Object Meeting a Selection Criterion\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Geospatial Data Science is a process of importing, wrangling, integrating, and processing geographically referenced data sets. In this hands-on exercise, you will learn how to perform geospatial data science tasks in R by using sf package.\nBy the end of this hands-on exercise, you should acquire the following competencies:\n\ninstalling and loading sf and tidyverse packages into R environment,\nimporting geospatial data by using appropriate functions of sf package,\nimporting aspatial data by using appropriate function of readr package,\nexploring the content of simple feature data frame by using appropriate Base R and sf functions,\nassigning or transforming coordinate systems by using using appropriate sf functions,\nconverting an aspatial data into a sf data frame by using appropriate function of sf package,\nperforming geoprocessing tasks by using appropriate functions of sf package,\nperforming data wrangling tasks by using appropriate functions of dplyr package and\nperforming Exploratory Data Analysis (EDA) by using appropriate functions from ggplot2 package.\n\n\n\n\n\nData are key to data analytics including geospatial analytics. Hence, before analysing, I extract the necessary data sets from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\n\n\n\nIn this exercise, I will be using two R packages will be used. They are:\n\nsf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTidyverse consists of a family of R packages. In this hands-on exercise, the following packages will be used:\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\nI install the required packages using the code chunk below.\n\npacman::p_load(sf, tidyverse)\n\n\n\n\n\nIn this section, I will import the following geospatial data into R by using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n\nDataset used: MP14_SUBZONE_WEB_PL File format: shapefile Data frame type: polygon feature\n\nmpsz = st_read(dsn = \"data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP\",                 \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nFrom the output message, we can see that in our mpsz simple feature data frame, there are 323 multipolygon features, 15 fields and is in the svy21 projected coordinates system.\n\n\n\nDataset used: CyclingPathGazette File format: shapefile Data frame type: line feature\n\ncyclingpath = st_read(dsn = \"data/geospatial/CyclingPath_Jul2024\",                        \n                      layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\CyclingPath_Jul2024' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nFrom the output message, we can see that in our cyclingpath linestring feature data frame, there are 1625 linestring features, 2 fields and is in the svy21 projected coordinates system.\n\n\n\nDataset used: pre-schools-location-kml File format: kml Data frame type: point feature\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nFrom the output message, we can see that in our preschool point feature data frame, there are 1359 linestring features, 2 fields and is in the wgs84 projected coordinates system.\n\n\n\n\nFor aspatial data, such as the listings Airbnb datset, there’s an extra step in the importing process. We’ll import it into a tibble data frame, then convert it into a simple feature data frame.\n\n\nSince our listings data set is in a csv file format, we’ll use the read_csv() function from the readr package, like so:\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(listings) \n\nRows: 3,540\nColumns: 18\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ latitude                       &lt;dbl&gt; 1.34537, 1.34754, 1.34531, 1.29015, 1.2…\n$ longitude                      &lt;dbl&gt; 103.9589, 103.9596, 103.9610, 103.8081,…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n\n\nFrom the output message, we can see that in our listing tibble data frame, there are 4252 rows and 16 columns (not features and fields like in our simple data feature frame!) Take note of the latitude and longitude fields - we’ll be using them in the next phase.\n\nAssumption: The data is in the wgs84 Geographic Coordinate System on account of its latitude/longtitude fields.\n\n\n\n\nNow, let’s convert our listing tibble data frame into a by using the st_as_sf() function from the sf package.\n\nlistings_sf &lt;- st_as_sf(listings,                         \n                        coords = c(\"longitude\", \"latitude\"),\n                        crs=4326) %&gt;%   \n  st_transform(crs = 3414)\n\nThis gives us the new simple feature data frame, listings_sf:\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\n\nNote that a new column called geometry has been added! In addition, longtitude and latitude have both been dropped.\n\n\n\n\n\nIn this sub-section, you will learn different ways to retrieve information related to the content of a simple feature data frame.\n\n\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nNotice that the print only displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\n\n\nBeside the basic feature information, we also would like to learn more about the associated attribute information in the data frame. This is the time you will find glimpse() of dplyr. very handy as shown in the code chunk below.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nglimpse() report reveals the data type of each fields. For example FMEL-UPD_D field is in date data type and X_ADDR, Y_ADDR, SHAPE_L and SHAPE_AREA fields are all in double-precision values.\n\n\n\nSometimes we would like to reveal complete information of a feature object, this is the job of head() of Base R\n\nhead(mpsz, n=5) \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\nNote: One of the useful argument of head() is it allows user to select the numbers of record to display (i.e. the n argument).\n\n\n\n\n\nIn geospatial data science, by looking at the feature information is not enough. We are also interested to visualise the geospatial features. I use plot() to quickly plot a sf object as shown in the code chunk below.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. We can, however, choose to plot only the geometry by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\n\n\n\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nIn this section, I project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nTo check the coordinate system of mpsz simple feature data frame, I use st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in SVY21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for SVY21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nNow, let us check the CSR again by using the code chunk below.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nI take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\nGeometry set for 2290 features  \nGeometry type: POINT \nDimension:     XYZ \nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134 \nz_range:       zmin: 0 zmax: 0 \nGeodetic CRS:  WGS 84 \nFirst 5 geometries:\nPOINT Z (103.8072 1.299333 0)\nPOINT Z (103.826 1.312839 0)\nPOINT Z (103.8409 1.348843 0)\nPOINT Z (103.8048 1.435024 0)\nPOINT Z (103.839 1.33315 0)\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool3414 &lt;- st_transform(preschool,                                \n                              crs = 3414)\n\n\nNote: In practice, we need find out the appropriate project coordinate system to use before performing the projection transformation.\n\nNext, let us display the content of preschool3414 sf data frame as shown below.\nGeometry set for 2290 features  \nGeometry type: POINT \nDimension:     XYZ \nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88 \nz_range:       zmin: 0 zmax: 0 \nProjected CRS: SVY21 / Singapore TM \nFirst 5 geometries:\nPOINT Z (25089.46 31299.16 0)\nPOINT Z (27189.07 32792.54 0)\nPOINT Z (28844.56 36773.76 0)\nPOINT Z (24821.92 46303.16 0)\nPOINT Z (28637.82 35038.49 0)\nNotice that it is in svy21 projected coordinate system now. Furthermore, if you refer to Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems.\n\n\n\n\nBesides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, I perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\n\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath,                                 \n                            dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\n\n\n\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nNext, I calculate the density of pre-school by planning subzone.\nFirstly, the code chunk below uses st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%   st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%   mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\n\n\n\nIn practice, many geospatial analytics start with Exploratory Data Analysis. In this section, you will learn how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data=mpsz3414,         \n       aes(x= as.numeric(`PreSch Density`)))+   \n  geom_histogram(bins=20,                   \n                 color=\"black\",                   \n                 fill=\"light blue\") +   \n  labs(title = \"Are pre-school even distributed in Singapore?\",        \n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",       \n       x = \"Pre-school density (per km sq)\",       \n       y = \"Frequency\")\n\n\n\n\n\n\n\n\nUsing ggplot2 method, I plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz3414,         \n       aes(y = `PreSch Count`,             \n          x= as.numeric(`PreSch Density`)))+   \n  geom_point(color=\"black\",               \n             fill=\"light blue\") +   \n  xlim(0, 40) +   \n  ylim(0, 40) +   \n  labs(title = \"\",       \n       x = \"Pre-school density (per km sq)\",       \n       y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#setup",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Data are key to data analytics including geospatial analytics. Hence, before analysing, I extract the necessary data sets from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\n\n\n\nIn this exercise, I will be using two R packages will be used. They are:\n\nsf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTidyverse consists of a family of R packages. In this hands-on exercise, the following packages will be used:\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\nI install the required packages using the code chunk below.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data-into-r",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "In this section, I will import the following geospatial data into R by using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n\nDataset used: MP14_SUBZONE_WEB_PL File format: shapefile Data frame type: polygon feature\n\nmpsz = st_read(dsn = \"data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP\",                 \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nFrom the output message, we can see that in our mpsz simple feature data frame, there are 323 multipolygon features, 15 fields and is in the svy21 projected coordinates system.\n\n\n\nDataset used: CyclingPathGazette File format: shapefile Data frame type: line feature\n\ncyclingpath = st_read(dsn = \"data/geospatial/CyclingPath_Jul2024\",                        \n                      layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\CyclingPath_Jul2024' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nFrom the output message, we can see that in our cyclingpath linestring feature data frame, there are 1625 linestring features, 2 fields and is in the svy21 projected coordinates system.\n\n\n\nDataset used: pre-schools-location-kml File format: kml Data frame type: point feature\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Users\\ngkng\\source\\github\\VAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nFrom the output message, we can see that in our preschool point feature data frame, there are 1359 linestring features, 2 fields and is in the wgs84 projected coordinates system."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-converting-aspatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-converting-aspatial-data-into-r",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "For aspatial data, such as the listings Airbnb datset, there’s an extra step in the importing process. We’ll import it into a tibble data frame, then convert it into a simple feature data frame.\n\n\nSince our listings data set is in a csv file format, we’ll use the read_csv() function from the readr package, like so:\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(listings) \n\nRows: 3,540\nColumns: 18\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ latitude                       &lt;dbl&gt; 1.34537, 1.34754, 1.34531, 1.29015, 1.2…\n$ longitude                      &lt;dbl&gt; 103.9589, 103.9596, 103.9610, 103.8081,…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n\n\nFrom the output message, we can see that in our listing tibble data frame, there are 4252 rows and 16 columns (not features and fields like in our simple data feature frame!) Take note of the latitude and longitude fields - we’ll be using them in the next phase.\n\nAssumption: The data is in the wgs84 Geographic Coordinate System on account of its latitude/longtitude fields.\n\n\n\n\nNow, let’s convert our listing tibble data frame into a by using the st_as_sf() function from the sf package.\n\nlistings_sf &lt;- st_as_sf(listings,                         \n                        coords = c(\"longitude\", \"latitude\"),\n                        crs=4326) %&gt;%   \n  st_transform(crs = 3414)\n\nThis gives us the new simple feature data frame, listings_sf:\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\n\nNote that a new column called geometry has been added! In addition, longtitude and latitude have both been dropped."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "In this sub-section, you will learn different ways to retrieve information related to the content of a simple feature data frame.\n\n\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nNotice that the print only displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\n\n\nBeside the basic feature information, we also would like to learn more about the associated attribute information in the data frame. This is the time you will find glimpse() of dplyr. very handy as shown in the code chunk below.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nglimpse() report reveals the data type of each fields. For example FMEL-UPD_D field is in date data type and X_ADDR, Y_ADDR, SHAPE_L and SHAPE_AREA fields are all in double-precision values.\n\n\n\nSometimes we would like to reveal complete information of a feature object, this is the job of head() of Base R\n\nhead(mpsz, n=5) \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\nNote: One of the useful argument of head() is it allows user to select the numbers of record to display (i.e. the n argument)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "In geospatial data science, by looking at the feature information is not enough. We are also interested to visualise the geospatial features. I use plot() to quickly plot a sf object as shown in the code chunk below.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. We can, however, choose to plot only the geometry by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-projection",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Map projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nIn this section, I project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nTo check the coordinate system of mpsz simple feature data frame, I use st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in SVY21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for SVY21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nNow, let us check the CSR again by using the code chunk below.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nI take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\nGeometry set for 2290 features  \nGeometry type: POINT \nDimension:     XYZ \nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134 \nz_range:       zmin: 0 zmax: 0 \nGeodetic CRS:  WGS 84 \nFirst 5 geometries:\nPOINT Z (103.8072 1.299333 0)\nPOINT Z (103.826 1.312839 0)\nPOINT Z (103.8409 1.348843 0)\nPOINT Z (103.8048 1.435024 0)\nPOINT Z (103.839 1.33315 0)\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool3414 &lt;- st_transform(preschool,                                \n                              crs = 3414)\n\n\nNote: In practice, we need find out the appropriate project coordinate system to use before performing the projection transformation.\n\nNext, let us display the content of preschool3414 sf data frame as shown below.\nGeometry set for 2290 features  \nGeometry type: POINT \nDimension:     XYZ \nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88 \nz_range:       zmin: 0 zmax: 0 \nProjected CRS: SVY21 / Singapore TM \nFirst 5 geometries:\nPOINT Z (25089.46 31299.16 0)\nPOINT Z (27189.07 32792.54 0)\nPOINT Z (28844.56 36773.76 0)\nPOINT Z (24821.92 46303.16 0)\nPOINT Z (28637.82 35038.49 0)\nNotice that it is in svy21 projected coordinate system now. Furthermore, if you refer to Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Besides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, I perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\n\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath,                                 \n                            dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\n\n\n\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nNext, I calculate the density of pre-school by planning subzone.\nFirstly, the code chunk below uses st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%   st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%   mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "In practice, many geospatial analytics start with Exploratory Data Analysis. In this section, you will learn how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data=mpsz3414,         \n       aes(x= as.numeric(`PreSch Density`)))+   \n  geom_histogram(bins=20,                   \n                 color=\"black\",                   \n                 fill=\"light blue\") +   \n  labs(title = \"Are pre-school even distributed in Singapore?\",        \n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",       \n       x = \"Pre-school density (per km sq)\",       \n       y = \"Frequency\")\n\n\n\n\n\n\n\n\nUsing ggplot2 method, I plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz3414,         \n       aes(y = `PreSch Count`,             \n          x= as.numeric(`PreSch Density`)))+   \n  geom_point(color=\"black\",               \n             fill=\"light blue\") +   \n  xlim(0, 40) +   \n  ylim(0, 40) +   \n  labs(title = \"\",       \n       x = \"Pre-school density (per km sq)\",       \n       y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Spatial Point Pattern Analysis is a method used to study how points are spread out over an area. These points can represent:\n\nEvents like crimes, traffic accidents, or disease outbreaks.\nLocations of businesses such as coffee shops, fast food places, or facilities like childcare centers and eldercare services.\n\nIn this exercise, we’ll use a tool called spatstat to analyze the distribution of childcare centers in Singapore.\nQuestions we want to answer are:\n\nAre childcare centers in Singapore spread out randomly, or is there a pattern?\nIf they’re not randomly distributed, where are the areas with the highest concentration of childcare centers?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#st-order-spatial-point-patterns-analysis-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#st-order-spatial-point-patterns-analysis-methods",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Spatial Point Pattern Analysis is a method used to study how points are spread out over an area. These points can represent:\n\nEvents like crimes, traffic accidents, or disease outbreaks.\nLocations of businesses such as coffee shops, fast food places, or facilities like childcare centers and eldercare services.\n\nIn this exercise, we’ll use a tool called spatstat to analyze the distribution of childcare centers in Singapore.\nQuestions we want to answer are:\n\nAre childcare centers in Singapore spread out randomly, or is there a pattern?\nIf they’re not randomly distributed, where are the areas with the highest concentration of childcare centers?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#setup",
    "title": "Hands-on Exercise 3",
    "section": "2.0 Setup",
    "text": "2.0 Setup\n\n2.1 Installing R-Packages\n\nsf for handling geospatial data\nspatstat for point pattern analysis. In this exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer. To study how points are distributed & to create a density map showing where points are concentrated\nraster deals with grid-based spatial data, like satellite img. In this exercise, we’ll use it to convert images created by spatstat into a format that raster can work with.\nmaptools for manupulating geographic data. In this exercise, we mainly use it to convert Spatial objects -&gt; ppp format of spatstat.\ntmap package\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, devtools,sp)\n\n\n\n2.2 Data Acquisition\n3 datasets will be used:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\n\n\n2.3 Importing Geospatial Data into R\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;% \n  st_transform(crs=3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Hands-on_Ex\\Hands-on_Ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn=\"data\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n2.4 Assigning Standard Coordinate Systems\n\nsg_sf &lt;- st_transform(sg_sf, crs=3414)\nmpsz_sf &lt;- st_transform(mpsz_sf, crs=3414)\n\n\n\n2.5 Data Preparation and Wrangling\n\n2.5.1 Convert simple feature data frame to sp’s Spatial* class\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\n2.5.2 Convert Spatial* class into generic sp format\n* spatstat requires the analytical data in ppp object form. (Need convert to Spatial Object first -&gt; ppp object)\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n* Diff between Spatial* classes & generic sp object:\nSpatial* classes are specialized versions of spatial objects tailored for different types of spatial data, while the generic sp object provides a base class with fundamental spatial features that can be extended by the more specific Spatial* classes.\n\n\n2.5.3 Convert generic sp format into spatstat’s ppp format\n\nchildcare_ppp &lt;- as.ppp(st_coordinates(childcare_sf), st_bbox(childcare_sf))\n\nWarning: data contain duplicated points\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nView Summary Statistics:\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n* There is warning about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#handling-duplicated-points",
    "title": "Hands-on Exercise 3",
    "section": "3.0 Handling duplicated points",
    "text": "3.0 Handling duplicated points\n\n3.1 Check duplication in a ppp object\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\n\n\n3.2 Count no. of co-indicence point\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\n\n\n3.3 Check how many locations &gt;= 1 point event\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\n\n\nView locations of these duplicated point events:\n\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\n\n3.3 3 ways to overcome duplicate points\n\nDelete the duplicate -&gt; but, this will result in some useful point events be lost\njittering -&gt; this will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nmake each point ‘unique’ + attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\n\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "title": "Hands-on Exercise 3",
    "section": "4.0 Creating owin object",
    "text": "4.0 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nConvert sg SpatialPolygon object -&gt; owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nDisplay:\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n4.1 Combining point events object + owin object\nExtract childcare events that are located within Singapore\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nchildcareSG_ppp &lt;- as.ppp(childcareSG_ppp)\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "title": "Hands-on Exercise 3",
    "section": "5.0 First-order Spatial Point Patterns Analysis",
    "text": "5.0 First-order Spatial Point Patterns Analysis\n\n5.1 Kernel Density Estimation (KDE)\n\n5.1.1 Computing kernel density estimation using automatic bandwidth selection method\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n* Density values is 0 to 0.000035 (too small to understand) -&gt; because default unit of measurement of svy21 is in meter [so it is computed in no. of points/sq meter]\nTo retrieve bandwidth used to compute the kde layer:\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n5.1.2 Convert unit of measurement from meter -&gt; km\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\n\n\n5.1.3 Different automatic badwidth methods\n\nbw.CvL()\nbw.scott()\nbw.ppl()\n\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\n bw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\n bw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\n bw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in ther experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n5.1.4 Different kernel methods\nDefault in density.ppp() is gaussian. [Choose from Epanechnikov, Quartic and Dics]\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\n\n\n\n\n\n\n\n\n\n\n5.1.4 Fixed and Adaptive KDE\n\n5.1.4.1 Computing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\n5.1.4.2 Computing KDE by using adaptive bandwidth\nvery sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nFixed VS Adaptive Kernel density estimation:\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n5.1.4.3 Converting KDE output into grid object\nThe result is the same, we just convert it so that it is suitable for mapping purposes\n\ngridded_kde_childcareSG_bw &lt;- as(kde_childcareSG.bw, \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\n\n5.1.4.4 Converting gridded density objects into raster\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n* crs is NA\n\n\n5.1.4.5 Assigning projection systems\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\n5.1.4.6 Visualising the output in tmap\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\n* Notice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field.\n\n\n5.1.4.7 Comparing Spatial Point Patterns using KDE\ncompare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas.\nExtract target planning areas:\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlot:\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n5.1.4.8 Creating owin object\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nCombining childcare points and the study area\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\nComputing KDE\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\n\nWarning: Berman-Diggle Cross-Validation criterion was minimised at right-hand\nend of interval [0, 0.198]; use argument 'hmax' to specify a wider interval for\nbandwidth 'sigma'\n\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\n\n\n\n\nComputing fixed bandwidth KDE\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\n\n\n\n\n\n\n\n\n\n\n\n5.2 Performing Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\n5.2.1 Testing spatial point patterns using Clark and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n5.2.2 Clark and Evans Test: Choa Chu Kang planning area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.92168, p-value = 0.2419\nalternative hypothesis: two-sided\n\n\n\n\n5.2.3 Clark and Evans Test: Tampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.77871, p-value = 6.503e-05\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#drawing-a-spatial-point-map",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#drawing-a-spatial-point-map",
    "title": "Hands-on Exercise 3",
    "section": "6.0 Drawing a Spatial Point Map",
    "text": "6.0 Drawing a Spatial Point Map\n\ntm_shape(mpsz_sf) +\n  tm_polygons() +\n  tm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\n* All the layers on the map fit together properly because they use the same coordinate system. This means they all refer to the same geographical area, which is crucial for accurate mapping and analysis.\n\nOR -&gt; Pin Map\n\ntmap_mode('view')\ntm_shape(childcare_sf) +\n  tm_dots()\n\n* Using interactive mode in tmap -&gt; can zoom in & out. Click on points to see more info\n* Can choose from different background map styles. Default = ESRI.WorldGrayCanvas. (Choose from ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap)\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n* Switch back to “plot”. Because each interactive mode consume a connection. Avoid &gt;10 in 1 RMarkdown doc when publish on Netlify"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#second-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#second-order-spatial-point-patterns-analysis",
    "title": "Hands-on Exercise 3",
    "section": "7.0 Second-order Spatial Point Patterns Analysis",
    "text": "7.0 Second-order Spatial Point Patterns Analysis\n\n7.1 Analysing Spatial Point Process Using G-Function\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event.\nCompute G-function estimation by using Gest() of spatstat package.\nPerform monta carlo simulation test using envelope() of spatstat package.\n\n\n7.1.1 Choa Chu Kang planning area\n\n\nComputing G-function estimation\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n7.1.2 Tampiness planning area\n\n\nComputing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-fucntion\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_tm.csr)\n\n\n\n\n\n\n\n\n\n\n7.2 Analysing Spatial Point Process Using F-Function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape.\nCompute F-function estimation by using Fest() of spatstat package.\nPerform monta carlo simulation test using envelope() of spatstat package.\n\n\n7.2.1 Choa Chu Kang planning area\n\n\nComputing F-function estimation\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-fucntion\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n7.2.2 Tampines planning area\n\n\nComputing F-function estimation\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)\n\n\n\n\n\n\n\n\n\n\n7.3 Analysing Spatial Point Process Using K-Function\nK-function measures the number of events found up to a given distance of any particular event.\nCompute K-function estimates by using Kest() of spatstat package.\nPerform monta carlo simulation test using envelope() of spatstat package.\n\n\n7.3.1 Choa Chu Kang planning area\n\n\nComputing K-function estimation\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n7.3.2 Tampines planning area\n\n\nComputing K-function estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n7.4 Analysing Spatial Point Process Using L-Function\nCompute L-function estimation by using Lest() of spatstat package.\nPerform monta carlo simulation test using envelope() of spatstat package.\n\n\n7.4.1 Choa Chu Kang planning area\n\n\nComputing L-function estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n7.4.2 Tampines planning area\n\n\nComputing L-function estimation\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "sf: Handles geospatial data, including points, lines, and polygons.\nreadr: Imports data from CSV files.\ndplyr: Performs relational joins to merge datasets.\nspdep: Computes spatial weights and calculates spatially lagged variables.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\n\nTwo data sets will be used:\n\nHunan county boundary layer: a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: contains selected Hunan’s local development indicators in 2012.\n\n\nImporting Geospatial DataImporting Aspatial Data\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#setup",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "sf: Handles geospatial data, including points, lines, and polygons.\nreadr: Imports data from CSV files.\ndplyr: Performs relational joins to merge datasets.\nspdep: Computes spatial weights and calculates spatially lagged variables.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\n\nTwo data sets will be used:\n\nHunan county boundary layer: a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: contains selected Hunan’s local development indicators in 2012.\n\n\nImporting Geospatial DataImporting Aspatial Data\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\ngkng\\Desktop\\School\\Geo -Local\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#performing-relational-join",
    "title": "Hands-on Exercise 5",
    "section": "2.0 Performing relational join",
    "text": "2.0 Performing relational join\nupdate the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe.\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 5",
    "section": "3.0 Visualising Regional Development Indicator",
    "text": "3.0 Visualising Regional Development Indicator\nDistribution of GDPPC 2012:\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5",
    "section": "4.0 Computing Contiguity Spatial Weights",
    "text": "4.0 Computing Contiguity Spatial Weights\n\nUse poly2nb() from the spdep package to find neighboring regions.\nThe function creates a list of neighboring areas based on shared borders.\nCan pass ‘queen’ as argument\n\ntake TRUE (default)/FALSE\nif FALSE -&gt; return a list of 1st order neighbours using the Queen criteria\n\n\n\nComputing (QUEEN) contiguity based neighboursCreating (ROOK) contiguity based neighbours\n\n\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\n\n\n\nExplanation\n\n\n\n\nTotal 88 area units in Hunana.\nMost connected area unit has 11 neighbours\n2 area units with only 1 neighbour\n\n\n\n\nTo see the neighbours:\neg. in 1st polygon in the object\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\n\n\n\n\n\n\nExplanation\n\n\n\n\nPolygon 1 has 5 neighbours.\nThe numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\n\n\n\n\n\nTo retrieve country name\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\n\n\nReveal country names of the 5 neighbouring polygons\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\n\n\nRetrieve GDPPC of these 5 countries\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\n\nDisplay the complete weight matrix\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\n\n\n\n\n\n\nExplanation\n\n\n\nTotal 88 area units in Hunan.\nMost connected area unit has 10 neighbours.\n2 area units with only 1 neighbour"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/data/MPSZ-2019/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex01/data/MPSZ-2019/MPSZ-2019.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/data/MPSZ-2019/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex02/data/MPSZ-2019/MPSZ-2019.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/data/MPSZ-2019/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex03/data/MPSZ-2019/MPSZ-2019.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "href": "In-class_Ex/In-class_Ex04/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5 -",
    "section": "",
    "text": "Overview\nxxx\n\n\n1.0 Setup\n\n1.1 Installing R-Packages\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)\n\nInstalling package into 'C:/Users/ngkng/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\n\n\nalso installing the dependencies 'TH.data', 'sandwich', 'DEoptimR', 'zoo', 'xts', 'intervals', 'LearnBayes', 'multcomp', 'robustbase', 'spacetime', 'spatialreg', 'FNN'\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4:\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4/PACKAGES'\n\n\n\n  There is a binary version available but the source version is later:\n         binary source needs_compilation\nsandwich  3.1-0  3.1-1             FALSE\n\npackage 'TH.data' successfully unpacked and MD5 sums checked\npackage 'DEoptimR' successfully unpacked and MD5 sums checked\npackage 'zoo' successfully unpacked and MD5 sums checked\npackage 'xts' successfully unpacked and MD5 sums checked\npackage 'intervals' successfully unpacked and MD5 sums checked\npackage 'LearnBayes' successfully unpacked and MD5 sums checked\npackage 'multcomp' successfully unpacked and MD5 sums checked\npackage 'robustbase' successfully unpacked and MD5 sums checked\npackage 'spacetime' successfully unpacked and MD5 sums checked\npackage 'spatialreg' successfully unpacked and MD5 sums checked\npackage 'FNN' successfully unpacked and MD5 sums checked\npackage 'GWmodel' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\ngkng\\AppData\\Local\\Temp\\Rtmpi8KwfL\\downloaded_packages\n\n\ninstalling the source package 'sandwich'\n\n\n\nGWmodel installed\n\n\n\n\n1.2 Data Acquisition\nWe will be using 2 sets of data:\n\n\n1.3 Importing Hunan data\n\nHunan shapefileHunan_2012 table\n\n\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\") \n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\nhunan2012\n\n\n\n\n\n\n\nTo save derived data:\n\nwrite_rds(hunan_sf, \"data/rds/hunan_sf.rds\")\nwrite_rds(hunan2012, \"data/rds/hunan2012.rds\")\n\n\n\nTo read stored derived data:\n\n\n\n\n\n\nNote\n\n\n\necho: false, will not print out\n\n\n\n1.4 Data Preparation and Wrangling\n\nJoining Hunan and Hunan_2012\n\nhunan_GDPPC &lt;- left_join(hunan_sf,hunan2012, join_by(County))%&gt;%\n  select(1:4, 7, 15)\n\nhunan_GDPPC\n\nSimple feature collection with 88 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\nConverting to SpatialPolygonDataFrame\n\nhunan_sp &lt;- hunan_GDPPC %&gt;% \n  as_Spatial()\n\n\n\n\n\n\n\nNote\n\n\n\nLook at the difference between the data structure of sp and sf\n\n\n\n\n\n\n\n2.0 Determine fixed bandwidth\n\nCross-alidationAIC\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"CV\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\nbw_CV\n\n[1] 76.29126\n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"AIC\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\nbw_AIC\n\n[1] 160.5517\n\n\n\n\n\n\n\n3.0 Determine adaptive bandwidth\n\nCross-ValidationAIC\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"CV\",\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\nbw_CV\n\n[1] 22\n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"AIC\",\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\nbw_AIC\n\n[1] 22\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFixed distance = will be in km,\nthe neighbors are the same for CV and AIC\n\n\n\n\n\n\n\n\nNote\n\n\n\nFixed bandwidth: adaptive = False\nAdaptive bandwidth: adaptive = True\n\n\n\n\n\n4.0 Geographically Weighted Summary Statistics with Adaptive bandwidth\n\ngwstat &lt;- gwss(data=hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\n\n\n5.0 Extract the data from gwstat\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)\n\n\n\n\n\n\n\nNote\n\n\n\ncbind() to append the newly derived data.frame onto hunan_sf sf data.frame\n\n\n\n\n6.0 Visualising geographically weighted summary statistics\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geographically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 1.0,\n            legend.text.size = 0.5,\n            legend.height = 1.50,\n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "Notes/Lesson_1.html",
    "href": "Notes/Lesson_1.html",
    "title": "2 Types of Data Models",
    "section": "",
    "text": "2 Types of Data Models\n\n1. Vector\n\nused for mapping boundaries, networks, and precise locations\nPoints: Discrete location (a city, tree etc)\n\n1 coordinate\n\nLines: Linear features (roads, rivers etc)\n\n&gt;= 2 coordinate pairs\nknow length\n\nPolygons: Area features (lakes, land parcels etc)\n\n&gt;=3 line segment\nknow location, length, and area\n\n\n\n\n2. Raster\n\nused for continuous data (eg. elevation, temperature, satellite, imagery, land cover)\nRepresents geographic features as a grid of cells or pixels.\nEach cell has a value representing information such as color, elevation, or land cover type.\n\n\n\n\n\n\n\n\n\n\n\nVector\nRaster\n\n\n\n\nData Representation\nPoints, lines, and polygons representing discrete features.\nGrid of cells or pixels representing continuous data.\n\n\nData Storage\nStores data as coordinates with associated attributes.\nStores data in a grid format, each cell holding a value.\n\n\nPrecision and Detail\nHighly precise, ideal for exact measurements and boundaries.\nResolution-dependent, better for continuous data representation.\n\n\nData Processing\nSuited for network analysis and topology-based operations.\nEfficient for spatial analysis involving overlays and map algebra.\n\n\nApplications\nUsed in mapping boundaries, networks, and urban planning.\nUsed in remote sensing, environmental modeling, and continuous surface analysis.\n\n\nVisualization\nSharp visuals, clear boundaries, smooth scaling.\nCan become pixelated when zoomed in; best for surface data like satellite imagery.\n\n\n\n\n\n\nCoordinate System\n\n\nProvides a location reference to the geospatial data\nTypes\n\nGCS -Geographic Coordinate System\nPCS -Projected Coordinate System\n\n\n\n\n\n\n\n\n\nGeographic Coordinate System (GCS)\nProjected Coordinate System (PCS)\n\n\n\n\n\n\n\n\nuse a 3D surface (eg. WGS84)\n\n\n\nprovides accurate position info\n\n\n\nnot appropriate for distance & area measurements\nprovides consistent length & area measurement across space\n\n\n\nNeed to transform GCS -&gt; PCS before performing geospatial analysis\n\n\nSimple Features\n\n\n\n\nShapefile\n\n\n\n\n\n\n\n\nif read, no need specify extension\n\n\n\n\n\nFor other vector format, read need to specify extension\n\nconsist of a few files\na simple, non-topological format for storing geometric location & attribute info of geographic features\nGeographic features in a shapefile can be represented by Points, Lines, Polygons(areas)\n\n\n\nSF functions\n\nGeospatial data handling\nst_read & read_sf\n\n\n\n\n\n\n\nShapefile format\nOther format\n\n\n\n\n\n\n\n\n\nread_csv\n\nglimpse -&gt; similar to print()\n\nst_write & write_sf\nst_as_sf -&gt; convert data frames/spatial objects into \"sf\" simple features, allowing for spatial data manipulation & analysis\nst_as_text -&gt; convert to Well Known Text\nst_as_binary\nst_as_sfc -&gt; convert coordinate data into \"sfc\" simple feature collections objects\nst_transform -&gt; convert coordinates to a different coordinate reference system\n\n\nGeospatial confirmation\nst_intersects\n\n\n\n\nst_disjoint -&gt; !intersect\nst_equals\nst_equal_exacts\n\n\nst_crosses -&gt; cross (don’t touch)\nst_touches\nst_within\n\n\nst_contains\nst_covers\nst_covered_by\n\n\nst_overlaps\n\n\n\n\n\n\n\nGeospatial operations\n\n\n\nst_union\nst_intersection\n\n\nst_difference\nst_sym_difference\n\n\n\n\n\n\n\n\n\n\nGeospatial creation\n\n\n\n\n\n\n\nst_interpolate_aw -&gt;\n\narea-weighted interpolation\nuses st_intersection to interpolate/redistribute attribute values, based on area of overlap\n\nst_join\neg. join a point data and polygon data together\n\n\n\n\n\n\nGeospatial operations\n\n\n\n\n\n\n\n\nst_line_merge -&gt; merge lines\nst_segmentize -&gt;\nadds points to straight lines\nst_centroid(poly)\n\n\n\nst_voronoi\nst_convex_hull\nst_triangulate\n\n\nst_polygonize\nst_simplify -&gt;\nsimplify lines by removing articles\nst_buffer(poly, 5)\n\n\n\nst_split -&gt;\nsplit a ploygon given line geometry\nst_make_valid -&gt;\nmake an invalid geometry valid\nis_boundary -&gt;\nreturn the boundary of a geometry\n\n\n\n\n\nGeospatial measurement\n\n\n\n\n\n\n\nst_zm -&gt;\nset/remove z and/or m geometry\nst_coordinates -&gt;\nreturns coordinates in a matrix/data.frame\n\n\nst_geometry\n\nst_is -&gt;\ncheck if geometry is of a particular type\n\n\n\nhead -&gt; reveal complete info of a feature object, can select the number of records to display\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo Check coordinate system of mpsz\n\n\n\nAssign EPSG code to mpsz\n\n\n\nSummary\n\n\n\nTop n\n\n\n\nSum\n\n\n\nCompute density\n\n\n\nHistogram"
  },
  {
    "objectID": "Notes/Lesson_3.html",
    "href": "Notes/Lesson_3.html",
    "title": "Notes 3",
    "section": "",
    "text": "Purpose of Geospatial Analytics\n\nSo that we can quantitatively derive it (eg. using KDE).\nUses data related to locations to find patterns & trends\n\n\n\nSpatial Point Patterns\n\nTo study how points (Event) are spread out over an area\nOnly map Events, no ‘Non-Event’\nThe mapped pattern should not be:\n\nselection bias\nNot a sample (eg. It is ok to take aged 70-80 from the population. But do not do random sampling out of this group)\n\n\nExample:\n\n\n\n\nReal-world spatial point patterns -Random OR Patterned?\n\nhard to have random distribution\n\neg. Some areas like the airport will never have childcare\nWe can use 2nd Order Spatial Point Pattern Analysis to prove\n\nhard to find something uniform in real world\n\neg. For instance a desert, if you zoom out a bit, there could be small hills, different land. It would not be the same across such as flat land\n\nBefore performing any spatial analysis, exclude areas that is definitely dont have the occurence. [Else, when generate the spatial random data, you might have childcare center there]\n\n\n\n\nSpatial Point Patterns Analysis\n\nusually in 2D space\nset X = {x ∈ D}, D = study region, subset of Rn, a n-dimensional Euclidean space\nIssue: We need infer if the given is merely random or result of some process:\n\n\n\n\n\n1st-order VS 2nd-order Analysis\n\n\n\n\n\n\n\n\n\n1st Order\n2nd Order\n\n\n\n\n\n\nfocuses on the overall intensity or density of events across a study area.\n\nexamines how the number of points (events) changes over space, often influenced by external factors such as environmental conditions, socioeconomic factors, or other large-scale trends.\nExample:\n“Where are the points more or less dense?”\n“How does the density of events vary across the study area?\n\nexamines the interaction or relationships between points within a study area.\nhelp to identify whether points tend to cluster, repel, or distribute randomly relative to each other.\n\nExample:\n“Are the points clustered, dispersed, or randomly distributed in relation to each other?”\n“How does the pattern change with distance?”\n\n\nTechnique\nDensity-based:\n\nKDE (Kernel density estimation)\nQuadrat analysis\n\nDistance-based:\n\nNearest Neighbour Index\n\n\nG function\nF function\nK function\nL function\n\n\n\n\n\n\n\n1st-order[Kernel Density Estimation (KDE)]\n\nused to estimate the probability density function of a random variable.\n\n\n\n\nSteps in KDE\n\nPlace a Kernel on Each Point (event location)\n\nThe height and shape of this bump depend on the chosen kernel function and the bandwidth.\n\nSum the Kernels\n\nFor each point in the study area, the contribution of all surrounding kernels is summed to calculate the density value at that point.\n\nCreate a Continuous Surface\n\nThe result is a smooth surface where higher values indicate areas with higher event densities, and lower values indicate areas with fewer events.\n\n\n\n\nKDE Methods\n\n\nUniform -&gt; intensity will not change during this period, immediately after, it will be 0\nTriangular -&gt; move away from center point, it will decrease very fast from the center point\nQuartic & Gaussian -&gt;\n\nnot identical, but similar. If get negative value from Gaussian, can switch to Quartic.\nGaussian is very common (Gives more weight to points closer to the event & less weight to points farther away)\nTry different option, select the appropriate one & explain why\n\n\n\n\nKDE Bandwidth\n\n\n\n\n\n\n\nFixed Bandwidth -determine distance for you\n\nDefine a fixed distance -&gt; use this distance throughout the study\nIn extreme case, might not able to calibrate in local areas where data are too sparse to satisfy the calibration requirements\n\n\n\n\n\nAdaptive Bandwidth -determine the k for you\n\nFixed the no. of spatial points\neg. I will search for 8 childcare center no matter the length\n\n\n\n\n\n\n* Small bandwidth = highly localized estimate, showing fine details (but could miss broader patterns)\n* Large bandwidth = smooth out the estimart (possibly oversimplifying the data)\n* Automatic bandwidth -&gt; bw.diggle()\n\n\n\n\n1st-order [Quadrat Analysis]\n\nSteps\n\n\n\n\n\n\n\n\nDivide the study area into subregion of equal size,\n\noften squares, but don’t have to be.\n\n\n\n\n\n\nCount the frequency of events in each region.\n\n\n\n\n\nCalculate the intensity of events in each region.\n\n\n\n\n\nCalculate the quadrat statistics and perform CSR test.\n\n\n\n\n\nUniform distribution -&gt; variance-mean ratio = 0\nRandom distribution -&gt; variance-mean ratio close to 1\nCluster distribution -&gt; variance-mean ratio greater than 1\n\n\nInterpretation\n\n\n\nWeaknesses\n\nsensitive to the quadrat size\n\nIf too small, they may contain only a couple of points, and\nIf too large, they may contain too many points.\n\nIt is a measure of dispersion rather than a measure of pattern.\n\n\n\nIt results in a single measure for the entire distribution, so variation within the region are not recognised.\n\n\n\n\nComplete Spatial Randomness CSR\n\nsatisfy 2 conditions\n\nany event has equal probability of being in any location, a 1st order effect\nThe location of one event is independent of the location of another event, a 2nd order effect.\n\n\n\n\n1st-order [Distance-based: Nearest Neighbour Index]\n\nDirect distance from a point to its nearest neighbour\nIndex &lt; 1: clustering\nIndex = 1: random\nIndex &gt; 1: dispersion\n\n\nExample:\n\n\np-value is &lt; 0.05, so reject null hypo that the point patterns are randomly distributed\n\n\n2nd-order [G function]\n\n\nwithin this radius, how many childcare i found\nWithin 0-9, what is the intensity\nClustered: If G increases rapidly at short distance\nEvenness: If G increases slowly up to distance where most events spaced, then increases rapidly\n\n\nMonte Carlo simulation test of CSR\n\n\nnsim = 999 &lt;- Performed 999 simulations [Cannot do 1 only, the more = more stable, result will converge]\nfor each simulated point pattern, estimate G(r) & use the max 95th and min 5th of these functions for the simulated patterns to define an upper and lower simulation envelope.\nEstimate G(r) is statistically significant if estimated G(r) lies above the upper envelope or below the lower envelope\n\n\n\n\n\n2nd-order [F function]\n\nSelect a sample of point locations anywhere in the study region at random\n\nDetermine min distance from each point to any event in the study area.\n\n\nClustered = F(r) rises slowly at first, but more rapidly at longer distances.\n\n\n\nEvenness = F(r) rises rapidly at first, then slowly at longer distances.\n\n\n\n\nComparison between F and G function\n\n\n\n2nd-order [K function]\n\nLimitation of nearest neighbor distance method is that it uses only nearest distance\nConsiders only the shortest scales of variation.\nK function uses more points.\n\nProvides an estimate of spatial dependence over a wider range of scales.\nBased on all the distances between events in the study area.\nAssumes isotropy over the region.\n\n\n\n\nCalculating K function\n\nConstruct a circle of radius h around each point event(i).\nCount the number of other events (j) that fall inside this circle.\nRepeat these two steps for all points (i) and sum results.\nIncrement h by a small amount and repeat the calculation.\n\n\nSignificant cluster pattern -&gt; above envelop\nSignificant regular pattern -&gt; below envelop\nCSR -&gt; inside envelop\n\n\n\n2nd-order [L function]\n\nK function will be normalised to obtained a benchmark of zero.\n\n\n\nWhen an observed L value is greater than its corresponding L(theo)(i.e. red break line) value for a particular distance and above the upper confidence envelop, spatial clustering for that distance is statistically significant (e.g. distance beyond C).\nWhen an observed L value is greater than its corresponding L(theo) value for a particular distance and lower than the upper confidence envelop, spatial clustering for that distance is statistically NOT significant (e.g. distance between B and C).\nWhen an observed L value is smaller than its corresponding L(theo) value for a particular distance and beyond the lower confidence envelop, spatial dispersion for that distance is statistically significant. - When an observed L value is smaller than its corresponding L(theo) value for a particular distance and within the lower confidence envelop, spatial dispersion for that distance is statistically NOT significant (e.g. distance between A and B).\n\n\n\nL(r)&gt;0 indicates that the observed distribution is geographically concentrated.\nL(r)&lt;0 implies dispersion.\nL(r)=0 indicates complete spatial randomness (CRS).\n\n* Anything outside of envelop, you will have enough statistical evidence, if inside means you still fall into the confidence lvl (cannot reject null, cause not enough evidence to infer)\n\n\nset.seed()\n\nto produce reproducible result\nresult from algo might change every run, use this to fix it"
  },
  {
    "objectID": "Notes/Lesson_6.html",
    "href": "Notes/Lesson_6.html",
    "title": "Notes 5",
    "section": "",
    "text": "A way to define spatial neighbourhood\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt measure from centroid!\nNeed to clean data properly. EG. If we only need to find the childcare in SG, we should remove the outer island, else u might see centroid being not in the center of where you expect it"
  },
  {
    "objectID": "Notes/Lesson_6.html#spatial-weights-wij",
    "href": "Notes/Lesson_6.html#spatial-weights-wij",
    "title": "Notes 5",
    "section": "",
    "text": "A way to define spatial neighbourhood\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt measure from centroid!\nNeed to clean data properly. EG. If we only need to find the childcare in SG, we should remove the outer island, else u might see centroid being not in the center of where you expect it"
  }
]