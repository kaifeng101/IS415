---
title: "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level"
author: "kai feng"
date: "Sep 23, 2024"
date-modified: "last-modified"
execute:
  eval: true
  echo: true
  freeze: true
---

# **Introduction**

### Drug Abuse Overview

-   **Global Impact**: Drug abuse has severe health, financial, and social consequences.

-   **Prevalence**: In 2021, 1 in 17 people aged 15â€“64 worldwide used a drug in the past year.

-   **Growth Trend**: Drug users increased from 240 million in 2011 to 296 million in 2021.

### Drug Situation in Thailand

-   **Geopolitical Context**: Proximity to the [Golden Triangle](https://en.wikipedia.org/wiki/Golden_Triangle_(Southeast_Asia)), a major drug production area, makes Thailand a key market and transit route for drug trafficking.

-   **Youth Drug Abuse**:

    -   Approximately 2.7 million young people in Thailand use drugs.

    -   Around 300,000 youth aged 15-19 need drug treatment.

    -   Vocational students are nearly twice as involved with drugs compared to secondary-school students.![](https://is415-ay2024-25t1.netlify.app/img/th_ex2_img1.png)

**This Geospatial Analytics will Focus on:**

-   **Objective:** Determine if drug abuse indicators in Thailand show spatial dependence.
-   **Analysis Goals**:
    -   Identify clusters, outliers, and hotspots of drug abuse.

    -   Examine how these patterns change over time.

<br/><br/>

# **1.0 Setup**

## 1.1 Installing R-Packages

::: panel-tabset
## *Importing and Transforming Data*

-   `sf`:

    -   For handling spatial vector data and transforming it into simple features (`sf`) objects.

    -   Functions like `st_read()` for importing spatial data and `st_transform()` for coordinate reference system transformations.

-   `tidyverse`: For data manipulation and transformation, including functions for working with `tibble` data frames.

-   `readr`: For reading in CSV or other text-based data files if needed.

-   `dplyr`: provide data manipulation capabilities (eg. to group and summarize the relationships between these columns)

-   `arrow`: To read parquet files

## *Displaying Maps*

-   `tmap`: For creating thematic maps and displaying KDE layers.

-   `ggplot2`: For additional custom visualizations if needed.

-   *`scales`*: Transform the unit of measurement for coordinate

-   `animation, png, magick`: For animation work

## *Spatial Autocorrelation*

-   `sfdep`: For performing both local and global spatial autocorrelation analysis
:::

```{r}
pacman::p_load(tidyverse, sf, readr, ggplot2, tmap, dplyr, arrow, sfdep, scales, animation, png, magick, patchwork, Kendall, zoo)
```

<br/>

## 1.2 Data Acquisition

We will be using 2 sets of data:

::: panel-tabset
## Drug offenses Data

-   **Source:** [[Thailand Drug Offenses \[2017-2022\]]{.underline}](https://www.kaggle.com/datasets/thaweewatboy/thailand-drug-offenses-2017-2022)

-   **Study Period:** 2017-2022

## Administrative Boundaries

-   **Source:** [Thailand - Subnational Administrative Boundaries](https://data.humdata.org/dataset/cod-ab-tha?) at HDX.
-   **Province Boundaries**: For understanding conflict distribution across larger administrative divisions.
:::

<br/>

## 1.3 Importing Geospatial Data into R

::: panel-tabset
## Drug Offenses Data

```{r}
#| eval: false
drug_offenses <- read_parquet("data/drug_offense/thai_drug_offenses_2017_2022.parquet")
```

```{r}
drug_offenses <- read_csv("data/drug_offense/thai_drug_offenses_2017_2022.csv")
```

::: callout-note
Since the data in CSV and Parquet formats are identical, we only need to import one of these file types.
:::

## Administrative Boundaries

```{r}
province_boundaries <- st_read(dsn = "data/subnational_administrative_boundary", layer="tha_admbnda_adm1_rtsd_20220121")
```
:::

<br/>

## 1.4 Checking Geospatial Data

::: panel-tabset
## Drug Offenses Data

```{r}
class(drug_offenses)
```

::: callout-note
Since

-   Since the class of **drug_offenses** != sf object

we have to transform it.
:::

## Administrative Boundaries

```{r}
class(province_boundaries)
st_crs(province_boundaries)
```

::: callout-note
Since Coordinate Reference System of **province_boundaries**

is in 4326 (unit of measurement = degree), we have to transform it
:::
:::

<br/>

## 1.6 Data Preparation and Wrangling

::: panel-tabset
## Drug Offenses Data

```{r}
# Drop & Rename column
drug_offenses <- drug_offenses %>% 
  select(fiscal_year, types_of_drug_offenses, no_cases, province_en) %>% 
  rename(
    year = fiscal_year,
    offense_type = types_of_drug_offenses,
    case_count = no_cases,
    province_name = province_en
  )
```

## Administrative Boundaries

##### Transform the Coordinate Reference System of these:

```{r}
province_boundaries <- province_boundaries %>%
  st_transform(crs = 4240)
```

```{r}
# Drop & Rename column
province_boundaries <- province_boundaries %>% 
  select(Shape_Leng, Shape_Area, ADM1_EN, ADM1_PCODE, geometry) %>% 
  rename(
    province_name = ADM1_EN,
    province_code = ADM1_PCODE
  )
```

##### Sample plot

```{r}
ggplot(data = province_boundaries) +
  geom_sf() +
  theme_minimal() +
  labs(title = "Map of Geometries",
       subtitle = "Displaying multipolygon geometries",
       caption = "Source: Example Data")
```

## Understanding the Data

```{r}
# Filter for unmatched province_names between Drug Offenses & Province Boundaries data set
unmatched_provinces <- drug_offenses %>%
  left_join(province_boundaries, by = "province_name") %>%
  filter(is.na(Shape_Leng)) %>%
  select(province_name)

unmatched_provinces <- unique(unmatched_provinces) #Loburi, buogkan



# Transform the province_name in the Drug Offenses dataset
drug_offenses <- drug_offenses %>%
  mutate(province_name = case_when(
    province_name == "Loburi" ~ "Lop Buri",
    province_name == "buogkan" ~ "Bueng Kan",
    TRUE ~ province_name  # Keep the original name if no match
  ))


# Assign each drug offense to a province
drug_offenses_by_province <- drug_offenses %>%
  left_join(province_boundaries, by = "province_name")

# Check for any empty attributes in the test dataset
empty_attributes <- sapply(drug_offenses_by_province, function(column) any(is.na(column)))

# Identify columns with missing values
missing_columns <- names(empty_attributes[empty_attributes]) # character(0) = No missing Column
```

::: callout-warning
The **Drug Offenses** dataset has some naming issues with `province_name`.

We found two discrepancies: **Loburi** should be changed to **Lop Buri**, and **buogkan** should be updated to **Bueng Kan** to match the **Province Boundaries** dataset.

We will update the `province_name` entries in the **Drug Offenses** dataset accordingly.s
:::
:::

<br/><br/>

# **2.0 Understanding the Data**

```{r}
offense_type <- unique(drug_offenses_by_province$offense_type) 
print(offense_type)
```

::: callout-note
These varying degrees of offense types may reveal patterns and trends in drug-related activities, providing a comprehensive understanding of the issue at hand.
:::

<br/><br/>

# **3.0 Exploratory Data Analysis**

## Summary statistics

```{r}
#| eval: false
summary_stats <- drug_offenses_by_province %>%
  group_by(province_name, year) %>%
  summarise(
    total_cases = sum(case_count, na.rm = TRUE),
    geometry = first(geometry)
    )

write_rds(summary_stats, "data/rds/summary_stats.rds")
```

```{r}
summary_stats <- read_rds("data/rds/summary_stats.rds")
summary_stats
```

## Top /Bottom 10 Related-Drug Incidents Provinces

```{r}
# Loop through each year and plot top 10 provinces
years_to_plot <- unique(summary_stats$year)
```

::: panel-tabset
## Top 10 Drug Abuse Provinces

```{r}
#| eval: false

top_10_plot_list <- list()

# Loop through each year and create the plots for top 10
for (current_year in years_to_plot) {
  # Filter and sort the data for the specific year
  top_10_year_data <- summary_stats %>%
    filter(year == current_year) %>%
    arrange(desc(total_cases)) %>%
    head(10)
  
  # Create the plot for the current year
  top_10_plot <- ggplot(top_10_year_data, aes(x = reorder(province_name, total_cases), y = total_cases)) +
    geom_bar(stat = "identity", fill = "pink", width = 0.8) +
    coord_flip() +
    labs(x = NULL, y = NULL, subtitle = paste("Year:", current_year)) +
    scale_y_continuous(labels = scales::comma_format(accuracy = 1)) +
    theme_minimal(base_size = 10) +
    geom_text(aes(label = total_cases),
              position = position_stack(vjust = 0.5),   
              color = "black", 
              size = 3) +
    theme(axis.text.x = element_blank(),   # Hide the y-axis text
          axis.ticks.x = element_blank())  # Hide the y-axis ticks
  
  # Add the plot to the list
  top_10_plot_list[[as.character(current_year)]] <- top_10_plot
}

# Combine the top 10 plots into a grid
top_10_plot_list <- wrap_plots(top_10_plot_list)

# Add a single title to the combined plot
top_10_plot_list <- top_10_plot_list +
  plot_annotation(title = "Top 10 Provinces by Total Drug Abuse Cases Over the Years")

write_rds(top_10_plot_list, "data/rds/top_10_plot_list.rds")

```

```{r}
print(read_rds("data/rds/top_10_plot_list.rds"))
```

## Bottom 10 Drug Abuse Provinces

```{r}
#| eval: false

# Create a list to store the bottom 10 plots
bottom_10_plot_list <- list()

# Loop through each year and create the plots for bottom 10
for (current_year in years_to_plot) {
  # Filter and sort the data for the specific year to get the bottom 10
  bottom_10_year_data <- summary_stats %>%
    filter(year == current_year) %>%
    arrange(total_cases) %>%   # Ascending order to get bottom cases
    head(10)
  
  # Create the plot for the current year
  bottom_10_plot <- ggplot(bottom_10_year_data, aes(x = reorder(province_name, -total_cases), y = total_cases)) +
    geom_bar(stat = "identity", fill = "steelblue", width = 0.8) +
    coord_flip() +
    labs(x = NULL, y = NULL, subtitle = paste("Year:", current_year)) +  # Subtitle to display year
    scale_y_continuous(labels = scales::comma_format(accuracy = 1)) +
    theme_minimal(base_size = 10) +
    geom_text(aes(label = total_cases),
              position = position_stack(vjust = 0.5),   
              color = "black", 
              size = 3) +
    theme(axis.text.x = element_blank(),   # Hide the y-axis text
          axis.ticks.x = element_blank())  # Hide the y-axis ticks
  
  # Add the plot to the list
  bottom_10_plot_list[[as.character(current_year)]] <- bottom_10_plot
}

# Combine the bottom 10 plots into a grid
bottom_10_plot_list <- wrap_plots(bottom_10_plot_list)

# Add a single title to the combined plot
bottom_10_plot_list <- bottom_10_plot_list +
  plot_annotation(title = "Bottom 10 Provinces by Total Drug Abuse Cases Over the Years")

write_rds(bottom_10_plot_list, "data/rds/bottom_10_plot_list.rds")
```

```{r}
print(read_rds("data/rds/bottom_10_plot_list.rds"))
```
:::

## Trends over time for the entire country

```{r}
drug_trends <- drug_offenses_by_province %>%
  group_by(year) %>%
  summarise(total_cases = sum(case_count))

# Plot trend over time with formatted y-axis labels
ggplot(drug_trends, aes(x = year, y = total_cases)) +
  geom_line(color = "blue") +
  geom_point(size = 3, color = "red") +  # Optional: Add points for better visibility
  labs(title = "Drug Abuse Cases Over Time",
       x = "Year", y = "Total Cases") +
  scale_y_continuous(labels = comma)

```

<br/><br/>

# **4.0 Global Spatial Autocorrelation Analysis**

Organize into years for more detailed analysis:

```{r}
summary_stats <- st_as_sf(summary_stats)

summary_stats_2017 <- summary_stats %>%
  filter(year == 2017) %>%
  ungroup()  # Remove any grouping

summary_stats_2018 <- summary_stats %>%
  filter(year == 2018) %>%
  ungroup()  # Remove any grouping

summary_stats_2019 <- summary_stats %>%
  filter(year == 2019) %>%
  ungroup()  # Remove any grouping

summary_stats_2020 <- summary_stats %>%
  filter(year == 2020) %>%
  ungroup()  # Remove any grouping

summary_stats_2021 <- summary_stats %>%
  filter(year == 2021) %>%
  ungroup()  # Remove any grouping

summary_stats_2022 <- summary_stats %>%
  filter(year == 2022) %>%
  ungroup()  # Remove any grouping
```

### Deriving Queenâ€™s Contiguity weights: sfdep methods

```{r}
#| eval: false

nb <- st_contiguity(summary_stats_2017$geometry)
wt <- st_weights(nb, style = "W", allow_zero = TRUE)


wm_q_2017 <- summary_stats_2017 %>% 
  mutate(
    nb = nb,
    wt = wt,
    .before = 1
  )

wm_q_2018 <- summary_stats_2018 %>% 
  mutate(
    nb = nb,
    wt = wt,
    .before = 1
  )

wm_q_2019 <- summary_stats_2019 %>% 
  mutate(
    nb = nb,
    wt = wt,
    .before = 1
  )

wm_q_2020 <- summary_stats_2020 %>% 
  mutate(
    nb = nb,
    wt = wt,
    .before = 1
  )

wm_q_2021 <- summary_stats_2021 %>% 
  mutate(
    nb = nb,
    wt = wt,
    .before = 1
  )

wm_q_2022 <- summary_stats_2022 %>% 
  mutate(
    nb = nb,
    wt = wt,
    .before = 1
  )

write_rds(wm_q_2017, "data/rds/wm_q_2017.rds")
write_rds(wm_q_2018, "data/rds/wm_q_2018.rds")
write_rds(wm_q_2019, "data/rds/wm_q_2019.rds")
write_rds(wm_q_2020, "data/rds/wm_q_2020.rds")
write_rds(wm_q_2021, "data/rds/wm_q_2021.rds")
write_rds(wm_q_2022, "data/rds/wm_q_2022.rds")
```

Initialize for use later:

```{r}
wm_q_2017 <- read_rds("data/rds/wm_q_2017.rds")
wm_q_2018 <- read_rds("data/rds/wm_q_2018.rds")
wm_q_2019 <- read_rds("data/rds/wm_q_2019.rds")
wm_q_2020 <- read_rds("data/rds/wm_q_2020.rds")
wm_q_2021 <- read_rds("data/rds/wm_q_2021.rds")
wm_q_2022 <- read_rds("data/rds/wm_q_2022.rds")
```

::: callout-note
To derive spatial autocorrelation, we first gather the relevant geographic points for our study area:

1.  **Filtering for Unique Geographic Points**: The `summary_stats` dataset contains multiple entries for each geographic point across different years. We filter it to retain data for a single year (e.g., 2017) to work with a unique set of locations.

2.  **Identifying Neighbors**: To assess the spatial relationships between areas, we identify neighboring regions. We use Queen's contiguity weights, which include all neighbors that touch at edges or corners, capturing comprehensive spatial interactions.

3.  **Calculating Weights**: After identifying neighbors, we calculate spatial weights that quantify the influence neighboring areas have on one another. These weights are crucial for measuring spatial autocorrelation, as they inform how a variable in one area relates to values in its neighbors.
:::

## 2017: An Initial Overview

### Global Moran' I

::: panel-tabset
## Computing Global Moranâ€™ I

```{r}
moranI_2017 <- global_moran(wm_q_2017$total_cases,
                       wm_q_2017$nb,
                       wm_q_2017$wt)

glimpse(moranI_2017)
```

## Performing Global Moranâ€™s I test

```{r}
global_moran_test(wm_q_2017$total_cases,
                  wm_q_2017$nb,
                  wm_q_2017$wt,
                  zero.policy = TRUE)
```

::: callout-note
Moran I statistic (0.133140650) -\> indicates a positive correlation in the variable of interest (e.g., total cases).

SD of 2.4598 -\> suggests that Moranâ€™s I is greater than the expected value under the null hypothesis.

P-value of 0.006951 -\> is \< 0.05, indicating strong statistical significance.

Expectation of -0.013333333 -\> suggests we would expect slight negative autocorrelation if there were no spatial structure.

Since the p-value \< 0.05, we reject the null hypothesis of no spatial autocorrelation. This strongly suggests there is significant positive spatial clustering of the variable in the study area (regions with high values are near areas with high values).
:::

## Performing Global Moranâ€™s I permutation test (Monte Carlo)

```{r}
set.seed(1234)

global_moran_perm_result_2017 <- global_moran_perm(wm_q_2017$total_cases,
                                              wm_q_2017$nb,
                                              wm_q_2017$wt,
                                              zero.policy = TRUE,
                                              nsim = 99)
global_moran_perm_result_2017
```

```{r}
summary(global_moran_perm_result_2017$res)
```

```{r}
#| eval: false

png("data/rds/global_moran_perm_result_2017.png", width = 1600, height = 1000)

# Adjust font size and scaling using par()
par(cex = 2,       # Overall scaling for text and symbols
    cex.axis = 1.5, # Axis text size
    cex.lab = 2,    # Axis label size
    cex.main = 2.5, # Main title size
    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot

# Extract the simulated statistics and observed statistic
simulated_values <- global_moran_perm_result_2017$res

global_moran_perm_hist_2017 <- hist(simulated_values, 
                                    freq=TRUE, 
                                    breaks=20, 
                                    xlab="Simulated Moran's I in 2017")
abline(v=0, 
       col="red") 

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/global_moran_perm_result_2017.png")
```

::: callout-note
To ensure our results are accurate, we'll perform a Monte Carlo (permutation) test on Moranâ€™s I statistic. This method helps us understand if the observed clustering of values is statistically significant.

First, we set the seed using `set.seed(1234)`. This step is crucial because it guarantees that our simulation results will be reproducible. Every time we run the simulation, we should get the same outcomes, which is important for consistency in our analysis.

Now, looking at the results from our permutation test:

-   **Moranâ€™s I statistic**: 0.13314

-   **Observed rank**: 98

-   **P-value**: 0.04

The p-value being less than 0.05 tells us that there's strong statistical evidence against the null hypothesis of no spatial autocorrelation. This means we can conclude thereâ€™s significant positive spatial clustering in our dataâ€”areas with high values are near other areas with high values.

Looking at the summary of the simulated statistics, with the maximum being 0.162326 and the minimum at -0.151935. The distribution of these values helps us understand the expected behavior of our statistic under the null hypothesis.
:::
:::

::: callout-note
It's important to note that some areas may have no neighboring regions, which results in null weights. To address this, we use `zero.policy = TRUE` in our analysis, allowing regions with no neighbors to be included without causing errors in calculations.

However, it's essential to understand that Global Moran's I does not accommodate regions without neighbors in its calculations, meaning that these regions, even when included, will not contribute to the overall assessment of spatial autocorrelation.

Consequently, regions with null weights may still affect the results, leading to potential skewing of the analysis and limiting its interpretability. Therefore, careful consideration of how to handle such regions is crucial for ensuring accurate spatial analysis.
:::

## Visualising across time span (2017-2022)

::: panel-tabset
## 2018 Global Moran' I

### Performing Global Moranâ€™s I permutation test (Monte Carlo)

```{r}
set.seed(1234)

global_moran_perm_result_2018 <- global_moran_perm(wm_q_2018$total_cases,
                                              wm_q_2018$nb,
                                              wm_q_2018$wt,
                                              zero.policy = TRUE,
                                              nsim = 99)
global_moran_perm_result_2018
```

```{r}
summary(global_moran_perm_result_2018$res)
```

```{r}
#| eval: false

png("data/rds/global_moran_perm_result_2018.png", width = 1600, height = 1000)

# Adjust font size and scaling using par()
par(cex = 2,       # Overall scaling for text and symbols
    cex.axis = 1.5, # Axis text size
    cex.lab = 2,    # Axis label size
    cex.main = 2.5, # Main title size
    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot

# Extract the simulated statistics and observed statistic
simulated_values <- global_moran_perm_result_2018$res

hist(simulated_values, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I in 2018")
abline(v=0, 
       col="red") 

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/global_moran_perm_result_2018.png")
```

## 2019 Global Moran' I

### Performing Global Moranâ€™s I permutation test (Monte Carlo)

```{r}
set.seed(1234)

global_moran_perm_result_2019 <- global_moran_perm(wm_q_2019$total_cases,
                                              wm_q_2019$nb,
                                              wm_q_2019$wt,
                                              zero.policy = TRUE,
                                              nsim = 99)
global_moran_perm_result_2019
```

```{r}
summary(global_moran_perm_result_2019$res)
```

```{r}
#| eval: false

png("data/rds/global_moran_perm_result_2019.png", width = 1600, height = 1000)

# Adjust font size and scaling using par()
par(cex = 2,       # Overall scaling for text and symbols
    cex.axis = 1.5, # Axis text size
    cex.lab = 2,    # Axis label size
    cex.main = 2.5, # Main title size
    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot

# Extract the simulated statistics and observed statistic
simulated_values <- global_moran_perm_result_2019$res

hist(simulated_values, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I in 2019")
abline(v=0, 
       col="red") 


# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/global_moran_perm_result_2019.png")
```

## 2020 Global Moran' I

### Performing Global Moranâ€™s I permutation test (Monte Carlo)

```{r}
set.seed(1234)

global_moran_perm_result_2020 <- global_moran_perm(wm_q_2020$total_cases,
                                              wm_q_2020$nb,
                                              wm_q_2020$wt,
                                              zero.policy = TRUE,
                                              nsim = 99)
global_moran_perm_result_2020
```

```{r}
summary(global_moran_perm_result_2020$res)
```

```{r}
#| eval: false

png("data/rds/global_moran_perm_result_2020.png", width = 1600, height = 1000)

# Adjust font size and scaling using par()
par(cex = 2,       # Overall scaling for text and symbols
    cex.axis = 1.5, # Axis text size
    cex.lab = 2,    # Axis label size
    cex.main = 2.5, # Main title size
    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot

# Extract the simulated statistics and observed statistic
simulated_values <- global_moran_perm_result_2020$res

hist(simulated_values, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I in 2020")
abline(v=0, 
       col="red") 

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/global_moran_perm_result_2020.png")
```

## 2021 Global Moran' I

### Performing Global Moranâ€™s I permutation test (Monte Carlo)

```{r}
set.seed(1234)

global_moran_perm_result_2021 <- global_moran_perm(wm_q_2021$total_cases,
                                              wm_q_2021$nb,
                                              wm_q_2021$wt,
                                              zero.policy = TRUE,
                                              nsim = 99)
global_moran_perm_result_2021
```

```{r}
summary(global_moran_perm_result_2021$res)
```

```{r}
#| eval: false

png("data/rds/global_moran_perm_result_2021.png", width = 1600, height = 1000)

# Adjust font size and scaling using par()
par(cex = 2,       # Overall scaling for text and symbols
    cex.axis = 1.5, # Axis text size
    cex.lab = 2,    # Axis label size
    cex.main = 2.5, # Main title size
    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot

# Extract the simulated statistics and observed statistic
simulated_values <- global_moran_perm_result_2021$res

hist(simulated_values, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I in 2021")
abline(v=0, 
       col="red") 

# Close the graphic device
dev.off() 
```

```{r}
image_read("data/rds/global_moran_perm_result_2021.png")
```

## 2022 Global Moran' I

### Performing Global Moranâ€™s I permutation test (Monte Carlo)

```{r}
set.seed(1234)

global_moran_perm_result_2022 <- global_moran_perm(wm_q_2022$total_cases,
                                              wm_q_2022$nb,
                                              wm_q_2022$wt,
                                              zero.policy = TRUE,
                                              nsim = 99)
global_moran_perm_result_2022
```

```{r}
summary(global_moran_perm_result_2022$res)
```

```{r}
#| eval: false

png("data/rds/global_moran_perm_result_2022.png", width = 1600, height = 1000)

# Adjust font size and scaling using par()
par(cex = 2,       # Overall scaling for text and symbols
    cex.axis = 1.5, # Axis text size
    cex.lab = 2,    # Axis label size
    cex.main = 2.5, # Main title size
    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot

# Extract the simulated statistics and observed statistic
simulated_values <- global_moran_perm_result_2022$res

hist(simulated_values, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I in 2022")
abline(v=0, 
       col="red") 

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/global_moran_perm_result_2022.png")
```
:::

::: callout-note
-   The results indicate a general trend of positive spatial autocorrelation from 2017 to 2022, with significant clustering observed in 2021 and 2022.

-   The years 2017, 2019, 2021, and 2022 show statistically significant evidence of clustering, while 2018 and 2020 have lower evidence of spatial correlation.

-   This trend suggests that the variable of interest tends to cluster in certain areas, particularly from 2021 onwards, which may warrant further investigation into the factors driving this clustering.
:::

```{r}
#| eval: false

# Get a list of image files in the specified directory
global_moran_perm_result_files <- list.files("data/rds/", pattern = "\\.png$", full.names = TRUE)

# Load saved images and combine them into an animated GIF
global_moran_images <- lapply(global_moran_perm_result_files, image_read)

# Create an animation from the Global Moran's images
global_moran_animation <- image_animate(image_join(global_moran_images), fps = 1)

# Save the animation as a GIF file
image_write(global_moran_animation, path = "data/rds/global_moran_animation.gif")
```

```{r}
image_read("data/rds/global_moran_animation.gif")
```

<br/><br/>

# **5.0 Local Spatial Autocorrelation Analysis**

## Visualising LISA Map

::: panel-tabset
## 2017

### Computing Local Moran's I

```{r}
#| eval: false
lisa_2017 <- wm_q_2017 %>% 
  mutate(local_moran = local_moran(
    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),
    .before = 1) %>% 
  unnest(local_moran)
```

### Local Moran's I VS P-Value

```{r}
#| eval: false

png("data/rds/local_moran_vs_pvalue_map_2017.png", width = 1600, height = 1000)

tmap_mode("plot")
local_moran_map_2017 <- tm_shape(lisa_2017) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of Total Cases in 2017",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

local_moran_pvalue_map_2017 <- tm_shape(lisa_2017) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I of Total Cases in 2017",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

tmap_arrange(local_moran_map_2017, local_moran_pvalue_map_2017, ncol = 2)

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/local_moran_vs_pvalue_map_2017.png")
```

### Putting together

```{r}
#| eval: false

png("data/rds/lisa_map_2017.png", width = 1600, height = 1200)

lisa_sig_2017 <- lisa_2017  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("plot")

tm_shape(lisa_2017) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig_2017) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4) +
  tm_layout(main.title = "LISA Map 2017",   
            main.title.size = 2.5,              
            legend.text.size = 2.0,           
            legend.title.size = 2.7,         
            legend.position = c("right", "bottom"), 
            frame = TRUE)  # Add a frame around the map

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/lisa_map_2017.png")
```

## 2018

### Computing Local Moran's I

```{r}
#| eval: false

lisa_2018 <- wm_q_2018 %>% 
  mutate(local_moran = local_moran(
    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),
    .before = 1) %>% 
  unnest(local_moran)
```

### Local Moran's I VS P-Value

```{r}
#| eval: false

png("data/rds/local_moran_vs_pvalue_map_2018.png", width = 1600, height = 1000)

tmap_mode("plot")
local_moran_map_2018 <- tm_shape(lisa_2018) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of Total Cases in 2018",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

local_moran_pvalue_map_2018 <- tm_shape(lisa_2018) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I of Total Cases in 2018",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

tmap_arrange(local_moran_map_2018, local_moran_pvalue_map_2018, ncol = 2)

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/local_moran_vs_pvalue_map_2018.png")
```

### Putting together

```{r}
#| eval: false

png("data/rds/lisa_map_2018.png", width = 1600, height = 1200)

lisa_sig_2018 <- lisa_2018  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("plot")

tm_shape(lisa_2018) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig_2018) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4) +
  tm_layout(main.title = "LISA Map 2018",   
            main.title.size = 2.5,              
            legend.text.size = 2.0,           
            legend.title.size = 2.7,         
            legend.position = c("right", "bottom"), 
            frame = TRUE)  # Add a frame around the map

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/lisa_map_2018.png")
```

## 2019

### Computing Local Moran's I

```{r}
#| eval: false

lisa_2019 <- wm_q_2019 %>% 
  mutate(local_moran = local_moran(
    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),
    .before = 1) %>% 
  unnest(local_moran)
```

### Local Moran's I VS P-Value

```{r}
#| eval: false

png("data/rds/local_moran_vs_pvalue_map_2019.png", width = 1600, height = 1000)

tmap_mode("plot")
local_moran_map_2019 <- tm_shape(lisa_2019) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of Total Cases in 2019",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

local_moran_pvalue_map_2019 <- tm_shape(lisa_2019) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I of Total Cases in 2019",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

tmap_arrange(local_moran_map_2019, local_moran_pvalue_map_2019, ncol = 2)

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/local_moran_vs_pvalue_map_2019.png")
```

### Putting together

```{r}
#| eval: false

png("data/rds/lisa_map_2019.png", width = 1600, height = 1200)

lisa_sig_2019 <- lisa_2019  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("plot")

tm_shape(lisa_2019) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig_2019) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4) +
  tm_layout(main.title = "LISA Map 2019",   
            main.title.size = 2.5,              
            legend.text.size = 2.0,           
            legend.title.size = 2.7,         
            legend.position = c("right", "bottom"), 
            frame = TRUE)  # Add a frame around the map

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/lisa_map_2019.png")
```

## 2020

### Computing Local Moran's I

```{r}
#| eval: false

lisa_2020 <- wm_q_2020 %>% 
  mutate(local_moran = local_moran(
    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),
    .before = 1) %>% 
  unnest(local_moran)
```

### Local Moran's I VS P-Value

```{r}
#| eval: false

png("data/rds/local_moran_vs_pvalue_map_2020.png", width = 1600, height = 1000)

tmap_mode("plot")
local_moran_map_2020 <- tm_shape(lisa_2020) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of Total Cases in 2020",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

local_moran_pvalue_map_2020 <- tm_shape(lisa_2020) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I of Total Cases in 2020",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

tmap_arrange(local_moran_map_2020, local_moran_pvalue_map_2020, ncol = 2)

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/local_moran_vs_pvalue_map_2020.png")
```

### Putting together

```{r}
#| eval: false

png("data/rds/lisa_map_2020.png", width = 1600, height = 1200)

lisa_sig_2020 <- lisa_2020  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("plot")

tm_shape(lisa_2020) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig_2020) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4) +
  tm_layout(main.title = "LISA Map 2020",   
            main.title.size = 2.5,              
            legend.text.size = 2.0,           
            legend.title.size = 2.7,         
            legend.position = c("right", "bottom"), 
            frame = TRUE)  # Add a frame around the map

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/lisa_map_2020.png")
```

## 2021

### Computing Local Moran's I

```{r}
#| eval: false

lisa_2021 <- wm_q_2021 %>% 
  mutate(local_moran = local_moran(
    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),
    .before = 1) %>% 
  unnest(local_moran)
```

### Local Moran's I VS P-Value

```{r}
#| eval: false

png("data/rds/local_moran_vs_pvalue_map_2021.png", width = 1600, height = 1000)

tmap_mode("plot")
local_moran_map_2021 <- tm_shape(lisa_2021) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of Total Cases in 2021",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

local_moran_pvalue_map_2021 <- tm_shape(lisa_2021) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I of Total Cases in 2021",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

tmap_arrange(local_moran_map_2021, local_moran_pvalue_map_2021, ncol = 2)

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/local_moran_vs_pvalue_map_2021.png")
```

### Putting together

```{r}
#| eval: false

png("data/rds/lisa_map_2021.png", width = 1600, height = 1200)

lisa_sig_2021 <- lisa_2021  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("plot")

tm_shape(lisa_2021) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig_2021) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4) +
  tm_layout(main.title = "LISA Map 2021",   
            main.title.size = 2.5,              
            legend.text.size = 2.0,           
            legend.title.size = 2.7,         
            legend.position = c("right", "bottom"), 
            frame = TRUE)  # Add a frame around the map

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/lisa_map_2021.png")
```

## 2022

### Computing Local Moran's I

```{r}
#| eval: false

lisa_2022 <- wm_q_2022 %>% 
  mutate(local_moran = local_moran(
    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),
    .before = 1) %>% 
  unnest(local_moran)
```

### Local Moran's I VS P-Value

```{r}
#| eval: false

png("data/rds/local_moran_vs_pvalue_map_2022.png", width = 1600, height = 1000)

tmap_mode("plot")
local_moran_map_2022 <- tm_shape(lisa_2022) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of Total Cases in 2022",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

local_moran_pvalue_map_2022 <- tm_shape(lisa_2022) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I of Total Cases in 2022",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

tmap_arrange(local_moran_map_2022, local_moran_pvalue_map_2022, ncol = 2)

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/local_moran_vs_pvalue_map_2022.png")
```

### Putting together

```{r}
#| eval: false

png("data/rds/lisa_map_2022.png", width = 1600, height = 1200)

lisa_sig_2022 <- lisa_2022  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("plot")

tm_shape(lisa_2022) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig_2022) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4) +
  tm_layout(main.title = "LISA Map 2022",   
            main.title.size = 2.5,              
            legend.text.size = 2.0,           
            legend.title.size = 2.7,         
            legend.position = c("right", "bottom"), 
            frame = TRUE)  # Add a frame around the map

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/lisa_map_2022.png")
```
:::

## Visualising LISA map across time span (2017-2022)

```{r}
#| eval: false

# Get a list of image files in the specified directory for LISA maps
lisa_map_files <- list.files("data/rds/", pattern = "lisa_map_\\d{4}\\.png$", full.names = TRUE)

# Load saved images and combine them into an animated GIF
lisa_images <- lapply(lisa_map_files, image_read)

# Create an animation from the LISA map images
lisa_animation <- image_animate(image_join(lisa_images), fps = 1)

# Save the animation as a GIF file
image_write(lisa_animation, path = "data/rds/lisa_animation.gif")
```

```{r}
image_read("data/rds/lisa_animation.gif")
```

## Hot Spot & Cold Spot Area Analysis (HCSA)

::: panel-tabset
## 2017

### Computing local Gi\* statistics

```{r}
#| eval: false

HCSA_2017 <- wm_q_2017 %>% 
  mutate(local_Gi = local_gstar_perm(
    total_cases, nb, wts, nsim = 99),
         .before = 1) %>%
  unnest(local_Gi)
```

### Gi\* VS P-Value

```{r}
#| eval: false

png("data/rds/gistar_vs_pvalue_map_2017.png", width = 1600, height = 1200)

gi_star_2017 <- tm_shape(HCSA_2017) +
  tm_fill("gi_star") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "Gi* of Total Cases in 2017",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

gi_star_pvalue_2017 <- tm_shape(HCSA_2017) +
  tm_fill("p_value",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of Gi* in 2017", 
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

tmap_arrange(gi_star_2017, gi_star_pvalue_2017, ncol = 2)

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/gistar_vs_pvalue_map_2017.png")
```

### Putting together

```{r}
#| eval: false

png("data/rds/hcsa_map_2017.png", width = 1600, height = 1200)

HCSA_sig_2017 <- HCSA_2017  %>%
  filter(p_sim < 0.05)
tmap_mode("plot")

tm_shape(HCSA_2017) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(HCSA_sig_2017) +
  tm_fill("cluster") + 
  tm_borders(alpha = 0.4) +
  tm_layout(main.title = "HCSA in 2017",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/hcsa_map_2017.png")
```

## 2018

### Computing local Gi\* statistics

```{r}
#| eval: false

HCSA_2018 <- wm_q_2018 %>%    
  mutate(local_Gi = local_gstar_perm(     
    total_cases, nb, wts, nsim = 99),          
    .before = 1) %>%   
  unnest(local_Gi)
```

### Visualising Hot Spot & Cold Spot (HCSA)

```{r}
#| eval: false

png("data/rds/gistar_vs_pvalue_map_2018.png", width = 1600, height = 1200)

gi_star_2018 <- tm_shape(HCSA_2018) +
  tm_fill("gi_star") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "Gi* of Total Cases in 2018",
            main.title.size = 0.8)

gi_star_pvalue_2018 <- tm_shape(HCSA_2018) +
  tm_fill("p_value",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of Gi* in 2018",
            main.title.size = 0.8)

tmap_arrange(gi_star_2018, gi_star_pvalue_2018, ncol = 2)

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/gistar_vs_pvalue_map_2018.png")
```

### Putting together

```{r}
#| eval: false

png("data/rds/hcsa_map_2018.png", width = 1600, height = 1200)

HCSA_sig_2018 <- HCSA_2018  %>%
  filter(p_sim < 0.05)
tmap_mode("plot")

tm_shape(HCSA_2018) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(HCSA_sig_2018) +
  tm_fill("cluster") + 
  tm_borders(alpha = 0.4) +
  tm_layout(main.title = "HCSA in 2018",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/hcsa_map_2018.png")
```

## 2019

### Computing local Gi\* statistics

```{r}
#| eval: false

HCSA_2019 <- wm_q_2019 %>% 
  mutate(local_Gi = local_gstar_perm(
    total_cases, nb, wts, nsim = 99),
         .before = 1) %>%
  unnest(local_Gi)
```

### Gi\* VS P-Value

```{r}
#| eval: false

png("data/rds/gistar_vs_pvalue_map_2019.png", width = 1600, height = 1200)

gi_star_2019 <- tm_shape(HCSA_2019) +
  tm_fill("gi_star") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "Gi* of Total Cases in 2019",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

gi_star_pvalue_2019 <- tm_shape(HCSA_2019) +
  tm_fill("p_value",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of Gi* in 2019", 
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

tmap_arrange(gi_star_2019, gi_star_pvalue_2019, ncol = 2)

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/gistar_vs_pvalue_map_2019.png")
```

### Putting together

```{r}
#| eval: false

png("data/rds/hcsa_map_2019.png", width = 1600, height = 1200)

HCSA_sig_2019 <- HCSA_2019  %>%
  filter(p_sim < 0.05)
tmap_mode("plot")

tm_shape(HCSA_2019) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(HCSA_sig_2019) +
  tm_fill("cluster") + 
  tm_borders(alpha = 0.4) +
  tm_layout(main.title = "HCSA in 2019",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/hcsa_map_2019.png")
```

## 2020

### Computing local Gi\* statistics

```{r}
#| eval: false

HCSA_2020 <- wm_q_2020 %>% 
  mutate(local_Gi = local_gstar_perm(
    total_cases, nb, wts, nsim = 99),
         .before = 1) %>%
  unnest(local_Gi)
```

### Gi\* VS P-Value

```{r}
#| eval: false

png("data/rds/gistar_vs_pvalue_map_2020.png", width = 1600, height = 1200)

gi_star_2020 <- tm_shape(HCSA_2020) +
  tm_fill("gi_star") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "Gi* of Total Cases in 2020",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

gi_star_pvalue_2020 <- tm_shape(HCSA_2020) +
  tm_fill("p_value",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of Gi* in 2020", 
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

tmap_arrange(gi_star_2020, gi_star_pvalue_2020, ncol = 2)

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/gistar_vs_pvalue_map_2020.png")
```

### Putting together

```{r}
#| eval: false

png("data/rds/hcsa_map_2020.png", width = 1600, height = 1200)

HCSA_sig_2020 <- HCSA_2020  %>%
  filter(p_sim < 0.05)
tmap_mode("plot")

tm_shape(HCSA_2020) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(HCSA_sig_2020) +
  tm_fill("cluster") + 
  tm_borders(alpha = 0.4) +
  tm_layout(main.title = "HCSA in 2020",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/hcsa_map_2020.png")
```

## 2021

### Computing local Gi\* statistics

```{r}
#| eval: false

HCSA_2021 <- wm_q_2021 %>% 
  mutate(local_Gi = local_gstar_perm(
    total_cases, nb, wts, nsim = 99),
         .before = 1) %>%
  unnest(local_Gi)
```

### Gi\* VS P-Value

```{r}
#| eval: false

png("data/rds/gistar_vs_pvalue_map_2021.png", width = 1600, height = 1200)

gi_star_2021 <- tm_shape(HCSA_2021) +
  tm_fill("gi_star") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "Gi* of Total Cases in 2021",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

gi_star_pvalue_2021 <- tm_shape(HCSA_2021) +
  tm_fill("p_value",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of Gi* in 2021", 
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

tmap_arrange(gi_star_2021, gi_star_pvalue_2021, ncol = 2)

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/gistar_vs_pvalue_map_2021.png")
```

### Putting together

```{r}
#| eval: false

png("data/rds/hcsa_map_2021.png", width = 1600, height = 1200)

HCSA_sig_2021 <- HCSA_2021  %>%
  filter(p_sim < 0.05)
tmap_mode("plot")

tm_shape(HCSA_2021) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(HCSA_sig_2021) +
  tm_fill("cluster") + 
  tm_borders(alpha = 0.4) +
  tm_layout(main.title = "HCSA in 2021",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/hcsa_map_2021.png")
```

## 2022

### Computing local Gi\* statistics

```{r}
#| eval: false

HCSA_2022 <- wm_q_2022 %>% 
  mutate(local_Gi = local_gstar_perm(
    total_cases, nb, wts, nsim = 99),
         .before = 1) %>%
  unnest(local_Gi)
```

### Gi\* VS P-Value

```{r}
#| eval: false

png("data/rds/gistar_vs_pvalue_map_2022.png", width = 1600, height = 1200)

gi_star_2022 <- tm_shape(HCSA_2022) +
  tm_fill("gi_star") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "Gi* of Total Cases in 2022",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

gi_star_pvalue_2022 <- tm_shape(HCSA_2022) +
  tm_fill("p_value",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of Gi* in 2022", 
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

tmap_arrange(gi_star_2022, gi_star_pvalue_2022, ncol = 2)

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/gistar_vs_pvalue_map_2022.png")
```

### Putting together

```{r}
#| eval: false

png("data/rds/hcsa_map_2022.png", width = 1600, height = 1200)

HCSA_sig_2022 <- HCSA_2022  %>%
  filter(p_sim < 0.05)
tmap_mode("plot")

tm_shape(HCSA_2022) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(HCSA_sig_2022) +
  tm_fill("cluster") + 
  tm_borders(alpha = 0.4) +
  tm_layout(main.title = "HCSA in 2022",
            main.title.size = 2.5,   
            legend.text.size = 2.0, 
            legend.title.size = 2.7) 

# Close the graphic device
dev.off()
```

```{r}
image_read("data/rds/hcsa_map_2022.png")
```
:::

## Visualising HCSA map across time span (2017-2022)

```{r}
#| eval: false

# Get a list of image files in the specified directory for HCSA maps
hcsa_map_files <- list.files("data/rds/", pattern = "hcsa_map_\\d{4}\\.png$", full.names = TRUE)

# Load saved images and combine them into an animated GIF
hcsa_images <- lapply(hcsa_map_files, image_read)

# Create an animation from the HCSA map images
hcsa_animation <- image_animate(image_join(hcsa_images), fps = 1)

# Save the animation as a GIF file
image_write(hcsa_animation, path = "data/rds/hcsa_animation.gif")
```

```{r}
# Read the animations
lisa_animation <- image_read("data/rds/lisa_animation.gif")
hcsa_animation <- image_read("data/rds/hcsa_animation.gif")

# Ensure both animations have the same number of frames by replicating frames if needed
lisa_frames <- length(lisa_animation)
hcsa_frames <- length(hcsa_animation)

if (lisa_frames != hcsa_frames) {
  if (lisa_frames > hcsa_frames) {
    hcsa_animation <- image_cycle(hcsa_animation, lisa_frames)
  } else {
    lisa_animation <- image_cycle(lisa_animation, hcsa_frames)
  }
}

# Convert each animation into a list of individual frames
lisa_frames_list <- as.list(lisa_animation)
hcsa_frames_list <- as.list(hcsa_animation)

# Resize each frame to ensure no margins and same height
lisa_frames_resized <- lapply(lisa_frames_list, function(frame) {
  image_scale(frame, "800x")  # Adjust the width as needed
})

hcsa_frames_resized <- lapply(hcsa_frames_list, function(frame) {
  image_scale(frame, "800x")  # Adjust the width as needed
})

# Combine corresponding frames side by side with no gaps
side_by_side_frames <- mapply(function(lisa_frame, hcsa_frame) {
  # Use `image_append` with `stack = FALSE` for horizontal stacking
  image_append(c(lisa_frame, hcsa_frame), stack = FALSE)
}, lisa_frames_resized, hcsa_frames_resized, SIMPLIFY = FALSE)

# Create a new animation from the combined frames
side_by_side_animation <- image_animate(image_join(side_by_side_frames), fps = 1)

# Save the final combined animation
image_write(side_by_side_animation, path = "data/rds/lisa_hcsa_side_by_side_animation.gif")

side_by_side_animation
```

# **6.0 Mann-Kendall Test for Trend**

This will assess the trend of drug abuse in each province over multiple years. \[See if the abuse case is increasing, decreasing, or stable over time\]

```{r}
#| eval: false

# Apply Mann-Kendall Test for each province
trend_results <- summary_stats %>%
  group_by(province_name) %>%
  summarise(
    total_cases = list(total_cases),         # Store total cases for each year in a list
    trend = MannKendall(unlist(total_cases))$tau,  # Tau value indicates trend direction
    p_value = MannKendall(unlist(total_cases))$sl,   # p-value for significance
  )

# Classify trends based on the Mann-Kendall results
trend_results <- trend_results %>%
  mutate(trend_status = case_when(
    p_value < 0.05 & trend > 0 ~ "Increasing",
    p_value < 0.05 & trend < 0 ~ "Decreasing",
    p_value >= 0.05 ~ "Stable",
    TRUE ~ "No sufficient data"
  ))

write_rds(trend_results, "data/rds/trend_results.rds")
```

## Provincial Trends

::: panel-tabset
## Increasing Trends

```{r}
#| eval: false

increasing_trends <- trend_results %>%
  filter(trend_status == "Increasing") %>%
  pull(province_name)

write_rds(increasing_trends, "data/rds/increasing_trends.rds")
```

```{r}
increasing_trends <- read_rds("data/rds/increasing_trends.rds")

# Check if increasing_trends is null or empty and set a default message
if (is.null(increasing_trends) || length(increasing_trends) == 0) {
  result <- "NIL"
} else {
  result <- paste(increasing_trends, collapse = ", ")
}

# Print the result
cat(result, "\n")
```

## Decreasing Trends

```{r}
#| eval: false

decreasing_trends <- trend_results %>%
  filter(trend_status == "Decreasing") %>%
  pull(province_name)

write_rds(decreasing_trends, "data/rds/decreasing_trends.rds")
```

```{r}
decreasing_trends <- read_rds("data/rds/decreasing_trends.rds")

# Check if decreasing_trends is null or empty and set a default message
if (is.null(decreasing_trends) || length(decreasing_trends) == 0) {
  result <- "NIL"
} else {
  result <- paste(decreasing_trends, collapse = ", ")
}

# Print the result
cat(result, "\n")
```

## Stable

```{r}
#| eval: false

stable_trends <- trend_results %>%
  filter(trend_status == "Stable") %>%
  pull(province_name)

write_rds(stable_trends, "data/rds/stable_trends.rds")
```

```{r}
stable_trends <- read_rds("data/rds/stable_trends.rds")

# Check if stable_trends is null or empty and set a default message
if (is.null(stable_trends) || length(stable_trends) == 0) {
  result <- "NIL"
} else {
  result <- paste(stable_trends, collapse = ", ")
}

# Print the result
cat(result, "\n")
```
:::
