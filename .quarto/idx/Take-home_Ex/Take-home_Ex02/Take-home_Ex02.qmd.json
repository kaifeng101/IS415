{"title":"Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level","markdown":{"yaml":{"title":"Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level","author":"kai feng","date":"Sep 23, 2024","date-modified":"last-modified","execute":{"eval":true,"echo":true,"freeze":true}},"headingText":"**Introduction**","containsRefs":false,"markdown":"\n\n\n### Drug Abuse Overview\n\n-   **Global Impact**: Drug abuse has severe health, financial, and social consequences.\n\n-   **Prevalence**: In 2021, 1 in 17 people aged 15–64 worldwide used a drug in the past year.\n\n-   **Growth Trend**: Drug users increased from 240 million in 2011 to 296 million in 2021.\n\n### Drug Situation in Thailand\n\n-   **Geopolitical Context**: Proximity to the [Golden Triangle](https://en.wikipedia.org/wiki/Golden_Triangle_(Southeast_Asia)), a major drug production area, makes Thailand a key market and transit route for drug trafficking.\n\n-   **Youth Drug Abuse**:\n\n    -   Approximately 2.7 million young people in Thailand use drugs.\n\n    -   Around 300,000 youth aged 15-19 need drug treatment.\n\n    -   Vocational students are nearly twice as involved with drugs compared to secondary-school students.![](https://is415-ay2024-25t1.netlify.app/img/th_ex2_img1.png)\n\n**This Geospatial Analytics will Focus on:**\n\n-   **Objective:** Determine if drug abuse indicators in Thailand show spatial dependence.\n-   **Analysis Goals**:\n    -   Identify clusters, outliers, and hotspots of drug abuse.\n\n    -   Examine how these patterns change over time.\n\n<br/><br/>\n\n# **1.0 Setup**\n\n## 1.1 Installing R-Packages\n\n::: panel-tabset\n## *Importing and Transforming Data*\n\n-   `sf`:\n\n    -   For handling spatial vector data and transforming it into simple features (`sf`) objects.\n\n    -   Functions like `st_read()` for importing spatial data and `st_transform()` for coordinate reference system transformations.\n\n-   `tidyverse`: For data manipulation and transformation, including functions for working with `tibble` data frames.\n\n-   `readr`: For reading in CSV or other text-based data files if needed.\n\n-   `dplyr`: provide data manipulation capabilities (eg. to group and summarize the relationships between these columns)\n\n-   `arrow`: To read parquet files\n\n## *Displaying Maps*\n\n-   `tmap`: For creating thematic maps and displaying KDE layers.\n\n-   `ggplot2`: For additional custom visualizations if needed.\n\n-   *`scales`*: Transform the unit of measurement for coordinate\n\n-   `animation, png, magick`: For animation work\n\n## *Spatial Autocorrelation*\n\n-   `sfdep`: For performing both local and global spatial autocorrelation analysis\n\n## *Prediction*\n\n-   `forecast`: For trend prediction\n:::\n\n```{r}\npacman::p_load(tidyverse, sf, readr, ggplot2, tmap, dplyr, arrow, sfdep, scales, animation, png, magick, patchwork, Kendall, zoo, forecast)\n```\n\n<br/>\n\n## 1.2 Data Acquisition\n\nWe will be using 2 sets of data:\n\n::: panel-tabset\n## Drug offenses Data\n\n-   **Source:** [[Thailand Drug Offenses \\[2017-2022\\]]{.underline}](https://www.kaggle.com/datasets/thaweewatboy/thailand-drug-offenses-2017-2022)\n\n-   **Study Period:** 2017-2022\n\n## Administrative Boundaries\n\n-   **Source:** [Thailand - Subnational Administrative Boundaries](https://data.humdata.org/dataset/cod-ab-tha?) at HDX.\n-   **Province Boundaries**: For understanding conflict distribution across larger administrative divisions.\n:::\n\n<br/>\n\n## 1.3 Importing Geospatial Data into R\n\n::: panel-tabset\n## Drug Offenses Data\n\n```{r}\n#| eval: false\ndrug_offenses <- read_parquet(\"data/drug_offense/thai_drug_offenses_2017_2022.parquet\")\n```\n\n```{r}\ndrug_offenses <- read_csv(\"data/drug_offense/thai_drug_offenses_2017_2022.csv\")\n```\n\n::: callout-note\nSince the data in CSV and Parquet formats are identical, we only need to import one of these file types.\n:::\n\n## Administrative Boundaries\n\n```{r}\nprovince_boundaries <- st_read(dsn = \"data/subnational_administrative_boundary\", layer=\"tha_admbnda_adm1_rtsd_20220121\")\n```\n:::\n\n<br/>\n\n## 1.4 Checking Geospatial Data\n\n::: panel-tabset\n## Drug Offenses Data\n\n```{r}\nclass(drug_offenses)\n```\n\n::: callout-note\nSince\n\n-   Since the class of **drug_offenses** != sf object\n\nwe have to transform it.\n:::\n\n## Administrative Boundaries\n\n```{r}\nclass(province_boundaries)\nst_crs(province_boundaries)\n```\n\n::: callout-note\nSince Coordinate Reference System of **province_boundaries**\n\nis in 4326 (unit of measurement = degree), we have to transform it\n:::\n:::\n\n<br/>\n\n## 1.6 Data Preparation and Wrangling\n\n::: panel-tabset\n## Drug Offenses Data\n\n```{r}\n# Drop & Rename column\ndrug_offenses <- drug_offenses %>% \n  select(fiscal_year, types_of_drug_offenses, no_cases, province_en) %>% \n  rename(\n    year = fiscal_year,\n    offense_type = types_of_drug_offenses,\n    case_count = no_cases,\n    province_name = province_en\n  )\n```\n\n## Administrative Boundaries\n\n##### Transform the Coordinate Reference System of these:\n\n```{r}\nprovince_boundaries <- province_boundaries %>%\n  st_transform(crs = 4240)\n```\n\n```{r}\n# Drop & Rename column\nprovince_boundaries <- province_boundaries %>% \n  select(Shape_Leng, Shape_Area, ADM1_EN, ADM1_PCODE, geometry) %>% \n  rename(\n    province_name = ADM1_EN,\n    province_code = ADM1_PCODE\n  )\n```\n\n##### Sample plot\n\n```{r}\nggplot(data = province_boundaries) +\n  geom_sf() +\n  theme_minimal() +\n  labs(title = \"Map of Geometries\",\n       subtitle = \"Displaying multipolygon geometries\",\n       caption = \"Source: Example Data\")\n```\n\n## Understanding the Data\n\n```{r}\n# Filter for unmatched province_names between Drug Offenses & Province Boundaries data set\nunmatched_provinces <- drug_offenses %>%\n  left_join(province_boundaries, by = \"province_name\") %>%\n  filter(is.na(Shape_Leng)) %>%\n  select(province_name)\n\nunmatched_provinces <- unique(unmatched_provinces) #Loburi, buogkan\n\n\n\n# Transform the province_name in the Drug Offenses dataset\ndrug_offenses <- drug_offenses %>%\n  mutate(province_name = case_when(\n    province_name == \"Loburi\" ~ \"Lop Buri\",\n    province_name == \"buogkan\" ~ \"Bueng Kan\",\n    TRUE ~ province_name  # Keep the original name if no match\n  ))\n\n\n# Assign each drug offense to a province\ndrug_offenses_by_province <- drug_offenses %>%\n  left_join(province_boundaries, by = \"province_name\")\n\n# Check for any empty attributes in the test dataset\nempty_attributes <- sapply(drug_offenses_by_province, function(column) any(is.na(column)))\n\n# Identify columns with missing values\nmissing_columns <- names(empty_attributes[empty_attributes]) # character(0) = No missing Column\n```\n\n::: callout-warning\nThe **Drug Offenses** dataset has some naming issues with `province_name`.\n\nWe found two discrepancies: **Loburi** should be changed to **Lop Buri**, and **buogkan** should be updated to **Bueng Kan** to match the **Province Boundaries** dataset.\n\nWe will update the `province_name` entries in the **Drug Offenses** dataset accordingly.\n:::\n:::\n\n<br/><br/>\n\n# **2.0 Understanding the Data**\n\n```{r}\noffense_type <- unique(drug_offenses_by_province$offense_type) \nprint(offense_type)\n```\n\n::: callout-note\nThese varying degrees of offense types may reveal patterns and trends in drug-related activities, providing a comprehensive understanding of the issue at hand.\n:::\n\n<br/><br/>\n\n# **3.0 Exploratory Data Analysis**\n\n## Summary statistics\n\n```{r}\n#| eval: false\nsummary_stats <- drug_offenses_by_province %>%\n  group_by(province_name, year) %>%\n  summarise(\n    total_cases = sum(case_count, na.rm = TRUE),\n    geometry = first(geometry)\n    )\n\nwrite_rds(summary_stats, \"data/rds/summary_stats.rds\")\n```\n\n```{r}\nsummary_stats <- read_rds(\"data/rds/summary_stats.rds\")\nsummary_stats\n```\n\n## Top /Bottom 10 Related-Drug Incidents Provinces\n\n```{r}\n# Loop through each year and plot top 10 provinces\nyears_to_plot <- unique(summary_stats$year)\n```\n\n::: panel-tabset\n## Top 10 Drug Abuse Provinces\n\n```{r}\n#| eval: false\n\ntop_10_plot_list <- list()\n\n# Loop through each year and create the plots for top 10\nfor (current_year in years_to_plot) {\n  # Filter and sort the data for the specific year\n  top_10_year_data <- summary_stats %>%\n    filter(year == current_year) %>%\n    arrange(desc(total_cases)) %>%\n    head(10)\n  \n  # Create the plot for the current year\n  top_10_plot <- ggplot(top_10_year_data, aes(x = reorder(province_name, total_cases), y = total_cases)) +\n    geom_bar(stat = \"identity\", fill = \"pink\", width = 0.8) +\n    coord_flip() +\n    labs(x = NULL, y = NULL, subtitle = paste(\"Year:\", current_year)) +\n    scale_y_continuous(labels = scales::comma_format(accuracy = 1)) +\n    theme_minimal(base_size = 10) +\n    geom_text(aes(label = total_cases),\n              position = position_stack(vjust = 0.5),   \n              color = \"black\", \n              size = 3) +\n    theme(axis.text.x = element_blank(),   # Hide the y-axis text\n          axis.ticks.x = element_blank())  # Hide the y-axis ticks\n  \n  # Add the plot to the list\n  top_10_plot_list[[as.character(current_year)]] <- top_10_plot\n}\n\n# Combine the top 10 plots into a grid\ntop_10_plot_list <- wrap_plots(top_10_plot_list)\n\n# Add a single title to the combined plot\ntop_10_plot_list <- top_10_plot_list +\n  plot_annotation(title = \"Top 10 Provinces by Total Drug Abuse Cases Over the Years\")\n\nwrite_rds(top_10_plot_list, \"data/rds/top_10_plot_list.rds\")\n\n```\n\n```{r}\nprint(read_rds(\"data/rds/top_10_plot_list.rds\"))\n```\n\n## Bottom 10 Drug Abuse Provinces\n\n```{r}\n#| eval: false\n\n# Create a list to store the bottom 10 plots\nbottom_10_plot_list <- list()\n\n# Loop through each year and create the plots for bottom 10\nfor (current_year in years_to_plot) {\n  # Filter and sort the data for the specific year to get the bottom 10\n  bottom_10_year_data <- summary_stats %>%\n    filter(year == current_year) %>%\n    arrange(total_cases) %>%   # Ascending order to get bottom cases\n    head(10)\n  \n  # Create the plot for the current year\n  bottom_10_plot <- ggplot(bottom_10_year_data, aes(x = reorder(province_name, -total_cases), y = total_cases)) +\n    geom_bar(stat = \"identity\", fill = \"steelblue\", width = 0.8) +\n    coord_flip() +\n    labs(x = NULL, y = NULL, subtitle = paste(\"Year:\", current_year)) +  # Subtitle to display year\n    scale_y_continuous(labels = scales::comma_format(accuracy = 1)) +\n    theme_minimal(base_size = 10) +\n    geom_text(aes(label = total_cases),\n              position = position_stack(vjust = 0.5),   \n              color = \"black\", \n              size = 3) +\n    theme(axis.text.x = element_blank(),   # Hide the y-axis text\n          axis.ticks.x = element_blank())  # Hide the y-axis ticks\n  \n  # Add the plot to the list\n  bottom_10_plot_list[[as.character(current_year)]] <- bottom_10_plot\n}\n\n# Combine the bottom 10 plots into a grid\nbottom_10_plot_list <- wrap_plots(bottom_10_plot_list)\n\n# Add a single title to the combined plot\nbottom_10_plot_list <- bottom_10_plot_list +\n  plot_annotation(title = \"Bottom 10 Provinces by Total Drug Abuse Cases Over the Years\")\n\nwrite_rds(bottom_10_plot_list, \"data/rds/bottom_10_plot_list.rds\")\n```\n\n```{r}\nprint(read_rds(\"data/rds/bottom_10_plot_list.rds\"))\n```\n:::\n\n## Trends over time for the entire country\n\n```{r}\ndrug_trends <- drug_offenses_by_province %>%\n  group_by(year) %>%\n  summarise(total_cases = sum(case_count))\n\n# Plot trend over time with formatted y-axis labels\nggplot(drug_trends, aes(x = year, y = total_cases)) +\n  geom_line(color = \"blue\") +\n  geom_point(size = 3, color = \"red\") +  \n  labs(title = \"Drug Abuse Cases Over Time\",\n       x = \"Year\", y = \"Total Cases\") +\n  scale_y_continuous(labels = comma)\n\n```\n\n<br/><br/>\n\n# **4.0 Global Spatial Autocorrelation Analysis**\n\nOrganize into years for more detailed analysis:\n\n```{r}\nsummary_stats <- st_as_sf(summary_stats)\n\nsummary_stats_2017 <- summary_stats %>%\n  filter(year == 2017) %>%\n  ungroup()  # Remove any grouping\n\nsummary_stats_2018 <- summary_stats %>%\n  filter(year == 2018) %>%\n  ungroup()  # Remove any grouping\n\nsummary_stats_2019 <- summary_stats %>%\n  filter(year == 2019) %>%\n  ungroup()  # Remove any grouping\n\nsummary_stats_2020 <- summary_stats %>%\n  filter(year == 2020) %>%\n  ungroup()  # Remove any grouping\n\nsummary_stats_2021 <- summary_stats %>%\n  filter(year == 2021) %>%\n  ungroup()  # Remove any grouping\n\nsummary_stats_2022 <- summary_stats %>%\n  filter(year == 2022) %>%\n  ungroup()  # Remove any grouping\n```\n\n### Deriving Queen’s Contiguity weights: sfdep methods\n\n```{r}\n#| eval: false\n\nnb <- st_contiguity(summary_stats_2017$geometry)\nwt <- st_weights(nb, style = \"W\", allow_zero = TRUE)\n\n\nwm_q_2017 <- summary_stats_2017 %>% \n  mutate(\n    nb = nb,\n    wt = wt,\n    .before = 1\n  )\n\nwm_q_2018 <- summary_stats_2018 %>% \n  mutate(\n    nb = nb,\n    wt = wt,\n    .before = 1\n  )\n\nwm_q_2019 <- summary_stats_2019 %>% \n  mutate(\n    nb = nb,\n    wt = wt,\n    .before = 1\n  )\n\nwm_q_2020 <- summary_stats_2020 %>% \n  mutate(\n    nb = nb,\n    wt = wt,\n    .before = 1\n  )\n\nwm_q_2021 <- summary_stats_2021 %>% \n  mutate(\n    nb = nb,\n    wt = wt,\n    .before = 1\n  )\n\nwm_q_2022 <- summary_stats_2022 %>% \n  mutate(\n    nb = nb,\n    wt = wt,\n    .before = 1\n  )\n\nwrite_rds(wm_q_2017, \"data/rds/wm_q_2017.rds\")\nwrite_rds(wm_q_2018, \"data/rds/wm_q_2018.rds\")\nwrite_rds(wm_q_2019, \"data/rds/wm_q_2019.rds\")\nwrite_rds(wm_q_2020, \"data/rds/wm_q_2020.rds\")\nwrite_rds(wm_q_2021, \"data/rds/wm_q_2021.rds\")\nwrite_rds(wm_q_2022, \"data/rds/wm_q_2022.rds\")\n```\n\nInitialize for use later:\n\n```{r}\nwm_q_2017 <- read_rds(\"data/rds/wm_q_2017.rds\")\nwm_q_2018 <- read_rds(\"data/rds/wm_q_2018.rds\")\nwm_q_2019 <- read_rds(\"data/rds/wm_q_2019.rds\")\nwm_q_2020 <- read_rds(\"data/rds/wm_q_2020.rds\")\nwm_q_2021 <- read_rds(\"data/rds/wm_q_2021.rds\")\nwm_q_2022 <- read_rds(\"data/rds/wm_q_2022.rds\")\n```\n\n::: callout-note\nTo derive spatial autocorrelation, we first gather the relevant geographic points for our study area:\n\n1.  **Filtering for Unique Geographic Points**: The `summary_stats` dataset contains multiple entries for each geographic point across different years. We filter it to retain data for a single year (e.g., 2017) to work with a unique set of locations.\n\n2.  **Identifying Neighbors**: To assess the spatial relationships between areas, we identify neighboring regions. We use Queen's contiguity weights, which include all neighbors that touch at edges or corners, capturing comprehensive spatial interactions.\n\n3.  **Calculating Weights**: After identifying neighbors, we calculate spatial weights that quantify the influence neighboring areas have on one another. These weights are crucial for measuring spatial autocorrelation, as they inform how a variable in one area relates to values in its neighbors.\n:::\n\n## 2017: An Initial Overview\n\n### Global Moran' I\n\n::: panel-tabset\n## Computing Global Moran’ I\n\n```{r}\nmoranI_2017 <- global_moran(wm_q_2017$total_cases,\n                       wm_q_2017$nb,\n                       wm_q_2017$wt)\n\nglimpse(moranI_2017)\n```\n\n## Performing Global Moran’s I test\n\n```{r}\nglobal_moran_test(wm_q_2017$total_cases,\n                  wm_q_2017$nb,\n                  wm_q_2017$wt,\n                  zero.policy = TRUE)\n```\n\n::: callout-note\nMoran I statistic (0.133140650) -\\> indicates a positive correlation in the variable of interest (e.g., total cases).\n\nSD of 2.4598 -\\> suggests that Moran’s I is greater than the expected value under the null hypothesis.\n\nP-value of 0.006951 -\\> is \\< 0.05, indicating strong statistical significance.\n\nExpectation of -0.013333333 -\\> suggests we would expect slight negative autocorrelation if there were no spatial structure.\n\nSince the p-value \\< 0.05, we reject the null hypothesis of no spatial autocorrelation. This strongly suggests there is significant positive spatial clustering of the variable in the study area (regions with high values are near areas with high values).\n:::\n\n## Performing Global Moran’s I permutation test (Monte Carlo)\n\n```{r}\nset.seed(1234)\n\nglobal_moran_perm_result_2017 <- global_moran_perm(wm_q_2017$total_cases,\n                                              wm_q_2017$nb,\n                                              wm_q_2017$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2017\n```\n\n```{r}\nsummary(global_moran_perm_result_2017$res)\n```\n\n```{r}\n#| eval: false\n\npng(\"data/rds/global_moran_perm_result_2017.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values <- global_moran_perm_result_2017$res\n\nglobal_moran_perm_hist_2017 <- hist(simulated_values, \n                                    freq=TRUE, \n                                    breaks=20, \n                                    xlab=\"Simulated Moran's I in 2017\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/global_moran_perm_result_2017.png\")\n```\n\n::: callout-note\nTo ensure our results are accurate, we'll perform a Monte Carlo (permutation) test on Moran’s I statistic. This method helps us understand if the observed clustering of values is statistically significant.\n\nFirst, we set the seed using `set.seed(1234)`. This step is crucial because it guarantees that our simulation results will be reproducible. Every time we run the simulation, we should get the same outcomes, which is important for consistency in our analysis.\n\nNow, looking at the results from our permutation test:\n\n-   **Moran’s I statistic**: 0.13314\n\n-   **Observed rank**: 98\n\n-   **P-value**: 0.04\n\nThe p-value being less than 0.05 tells us that there's strong statistical evidence against the null hypothesis of no spatial autocorrelation. This means we can conclude there’s significant positive spatial clustering in our data—areas with high values are near other areas with high values.\n\nLooking at the summary of the simulated statistics, with the maximum being 0.162326 and the minimum at -0.151935. The distribution of these values helps us understand the expected behavior of our statistic under the null hypothesis.\n:::\n:::\n\n::: callout-note\nIt's important to note that some areas may have no neighboring regions, which results in null weights. To address this, we use `zero.policy = TRUE` in our analysis, allowing regions with no neighbors to be included without causing errors in calculations.\n\nHowever, it's essential to understand that Global Moran's I does not accommodate regions without neighbors in its calculations, meaning that these regions, even when included, will not contribute to the overall assessment of spatial autocorrelation.\n\nConsequently, regions with null weights may still affect the results, leading to potential skewing of the analysis and limiting its interpretability. Therefore, careful consideration of how to handle such regions is crucial for ensuring accurate spatial analysis.\n:::\n\n## Visualising across time span (2017-2022)\n\n::: panel-tabset\n## 2018 Global Moran' I\n\n### Performing Global Moran’s I permutation test (Monte Carlo)\n\n```{r}\nset.seed(1234)\n\nglobal_moran_perm_result_2018 <- global_moran_perm(wm_q_2018$total_cases,\n                                              wm_q_2018$nb,\n                                              wm_q_2018$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2018\n```\n\n```{r}\nsummary(global_moran_perm_result_2018$res)\n```\n\n```{r}\n#| eval: false\n\npng(\"data/rds/global_moran_perm_result_2018.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values <- global_moran_perm_result_2018$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2018\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/global_moran_perm_result_2018.png\")\n```\n\n## 2019 Global Moran' I\n\n### Performing Global Moran’s I permutation test (Monte Carlo)\n\n```{r}\nset.seed(1234)\n\nglobal_moran_perm_result_2019 <- global_moran_perm(wm_q_2019$total_cases,\n                                              wm_q_2019$nb,\n                                              wm_q_2019$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2019\n```\n\n```{r}\nsummary(global_moran_perm_result_2019$res)\n```\n\n```{r}\n#| eval: false\n\npng(\"data/rds/global_moran_perm_result_2019.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values <- global_moran_perm_result_2019$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2019\")\nabline(v=0, \n       col=\"red\") \n\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/global_moran_perm_result_2019.png\")\n```\n\n## 2020 Global Moran' I\n\n### Performing Global Moran’s I permutation test (Monte Carlo)\n\n```{r}\nset.seed(1234)\n\nglobal_moran_perm_result_2020 <- global_moran_perm(wm_q_2020$total_cases,\n                                              wm_q_2020$nb,\n                                              wm_q_2020$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2020\n```\n\n```{r}\nsummary(global_moran_perm_result_2020$res)\n```\n\n```{r}\n#| eval: false\n\npng(\"data/rds/global_moran_perm_result_2020.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values <- global_moran_perm_result_2020$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2020\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/global_moran_perm_result_2020.png\")\n```\n\n## 2021 Global Moran' I\n\n### Performing Global Moran’s I permutation test (Monte Carlo)\n\n```{r}\nset.seed(1234)\n\nglobal_moran_perm_result_2021 <- global_moran_perm(wm_q_2021$total_cases,\n                                              wm_q_2021$nb,\n                                              wm_q_2021$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2021\n```\n\n```{r}\nsummary(global_moran_perm_result_2021$res)\n```\n\n```{r}\n#| eval: false\n\npng(\"data/rds/global_moran_perm_result_2021.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values <- global_moran_perm_result_2021$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2021\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off() \n```\n\n```{r}\nimage_read(\"data/rds/global_moran_perm_result_2021.png\")\n```\n\n## 2022 Global Moran' I\n\n### Performing Global Moran’s I permutation test (Monte Carlo)\n\n```{r}\nset.seed(1234)\n\nglobal_moran_perm_result_2022 <- global_moran_perm(wm_q_2022$total_cases,\n                                              wm_q_2022$nb,\n                                              wm_q_2022$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2022\n```\n\n```{r}\nsummary(global_moran_perm_result_2022$res)\n```\n\n```{r}\n#| eval: false\n\npng(\"data/rds/global_moran_perm_result_2022.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values <- global_moran_perm_result_2022$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2022\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/global_moran_perm_result_2022.png\")\n```\n:::\n\n::: callout-note\n-   The results indicate a general trend of positive spatial autocorrelation from 2017 to 2022, with significant clustering observed in 2021 and 2022.\n\n-   The years 2017, 2019, 2021, and 2022 show statistically significant evidence of clustering, while 2018 and 2020 have lower evidence of spatial correlation.\n\n-   This trend suggests that the variable of interest tends to cluster in certain areas, particularly from 2021 onwards, which may warrant further investigation into the factors driving this clustering.\n:::\n\n```{r}\n#| eval: false\n\n# Get a list of image files in the specified directory\nglobal_moran_perm_result_files <- list.files(\"data/rds/\", pattern = \"\\\\.png$\", full.names = TRUE)\n\n# Load saved images and combine them into an animated GIF\nglobal_moran_images <- lapply(global_moran_perm_result_files, image_read)\n\n# Create an animation from the Global Moran's images\nglobal_moran_animation <- image_animate(image_join(global_moran_images), fps = 1)\n\n# Save the animation as a GIF file\nimage_write(global_moran_animation, path = \"data/rds/global_moran_animation.gif\")\n```\n\n```{r}\nimage_read(\"data/rds/global_moran_animation.gif\")\n```\n\n<br/><br/>\n\n# **5.0 Local Spatial Autocorrelation Analysis**\n\n## Visualising LISA Map\n\n::: panel-tabset\n## 2017\n\n### Computing Local Moran's I\n\n```{r}\n#| eval: false\nlisa_2017 <- wm_q_2017 %>% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %>% \n  unnest(local_moran)\n```\n\n### Local Moran's I VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/local_moran_vs_pvalue_map_2017.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2017 <- tm_shape(lisa_2017) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2017\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2017 <- tm_shape(lisa_2017) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (< 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (> 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2017\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2017, local_moran_pvalue_map_2017, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2017.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/lisa_map_2017.png\", width = 1600, height = 1200)\n\nlisa_sig_2017 <- lisa_2017  %>%\n  filter(p_ii_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2017) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2017) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2017\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/lisa_map_2017.png\")\n```\n\n## 2018\n\n### Computing Local Moran's I\n\n```{r}\n#| eval: false\n\nlisa_2018 <- wm_q_2018 %>% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %>% \n  unnest(local_moran)\n```\n\n### Local Moran's I VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/local_moran_vs_pvalue_map_2018.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2018 <- tm_shape(lisa_2018) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2018\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2018 <- tm_shape(lisa_2018) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (< 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (> 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2018\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2018, local_moran_pvalue_map_2018, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2018.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/lisa_map_2018.png\", width = 1600, height = 1200)\n\nlisa_sig_2018 <- lisa_2018  %>%\n  filter(p_ii_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2018) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2018) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2018\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/lisa_map_2018.png\")\n```\n\n## 2019\n\n### Computing Local Moran's I\n\n```{r}\n#| eval: false\n\nlisa_2019 <- wm_q_2019 %>% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %>% \n  unnest(local_moran)\n```\n\n### Local Moran's I VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/local_moran_vs_pvalue_map_2019.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2019 <- tm_shape(lisa_2019) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2019\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2019 <- tm_shape(lisa_2019) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (< 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (> 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2019\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2019, local_moran_pvalue_map_2019, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2019.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/lisa_map_2019.png\", width = 1600, height = 1200)\n\nlisa_sig_2019 <- lisa_2019  %>%\n  filter(p_ii_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2019) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2019) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2019\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/lisa_map_2019.png\")\n```\n\n## 2020\n\n### Computing Local Moran's I\n\n```{r}\n#| eval: false\n\nlisa_2020 <- wm_q_2020 %>% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %>% \n  unnest(local_moran)\n```\n\n### Local Moran's I VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/local_moran_vs_pvalue_map_2020.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2020 <- tm_shape(lisa_2020) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2020\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2020 <- tm_shape(lisa_2020) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (< 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (> 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2020\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2020, local_moran_pvalue_map_2020, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2020.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/lisa_map_2020.png\", width = 1600, height = 1200)\n\nlisa_sig_2020 <- lisa_2020  %>%\n  filter(p_ii_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2020) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2020) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2020\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/lisa_map_2020.png\")\n```\n\n## 2021\n\n### Computing Local Moran's I\n\n```{r}\n#| eval: false\n\nlisa_2021 <- wm_q_2021 %>% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %>% \n  unnest(local_moran)\n```\n\n### Local Moran's I VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/local_moran_vs_pvalue_map_2021.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2021 <- tm_shape(lisa_2021) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2021\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2021 <- tm_shape(lisa_2021) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (< 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (> 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2021\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2021, local_moran_pvalue_map_2021, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2021.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/lisa_map_2021.png\", width = 1600, height = 1200)\n\nlisa_sig_2021 <- lisa_2021  %>%\n  filter(p_ii_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2021) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2021) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2021\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/lisa_map_2021.png\")\n```\n\n## 2022\n\n### Computing Local Moran's I\n\n```{r}\n#| eval: false\n\nlisa_2022 <- wm_q_2022 %>% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %>% \n  unnest(local_moran)\n```\n\n### Local Moran's I VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/local_moran_vs_pvalue_map_2022.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2022 <- tm_shape(lisa_2022) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2022\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2022 <- tm_shape(lisa_2022) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (< 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (> 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2022\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2022, local_moran_pvalue_map_2022, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2022.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/lisa_map_2022.png\", width = 1600, height = 1200)\n\nlisa_sig_2022 <- lisa_2022  %>%\n  filter(p_ii_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2022) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2022) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2022\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/lisa_map_2022.png\")\n```\n:::\n\n::: callout-note\n**Computing Local Moran’s I**\n\nadd new column \\[local_moran\\] -\\> stores the calculated Local Moran's I values\n\n`zero.policy = TRUE` option allows the method to handle regions without neighbors appropriately.\n\nunnest(local_moran) -\\> flatten the results, simplifying further analysis of the output.\n\n**Local Moran’s I VS P-Value Visualization**\n\nThis segment creates visualizations for the Local Moran's I statistic and its associated p-values for the year 2017\n\nLocal Moran's I values (color-coded) indicating spatial clustering: Ranges from -1.0 (cold spots) to 3.0 (strong hot spots). Provides insights into areas of similar or dissimilar values in case distribution.\n\nP-Value Map:\n\nIllustrates the statistical significance of Local Moran's I: Breaks defined for p-values (\\< 0.001, 0.001-0.01, 0.01-0.05, \\> 0.05).\n\n**Putting Together Significant LISA Results**\n\nThis segment visualizes the significant clusters identified by the Local Moran's I analysis.\n\nThe visualization includes both all regions and the significant clusters, with the latter highlighted based on their mean Local Moran's I values.\n\n1.  **Low-Low (LL)**\n\n-   **Definition**: Areas with low values surrounded by other low-value areas.\n\n-   **Interpretation**: Indicates regions that are underperforming or stable and may not need immediate intervention.\n\n2.  **High-Low (HL)**\n\n-   **Definition**: Areas with high values surrounded by low-value areas.\n\n-   **Interpretation**: Highlights potential hotspots that require further investigation or targeted intervention.\n\n3.  **Low-High (LH)**\n\n-   **Definition**: Areas with low values surrounded by high-value areas.\n\n-   **Interpretation**: Suggests vulnerability to spillover effects from neighboring high-value regions, requiring monitoring.\n\n4.  **High-High (HH)**\n\n-   **Definition**: Areas with high values surrounded by other high-value areas.\n\n-   **Interpretation**: Identifies significant hotspots that may need immediate attention and indicate systemic issues.\n:::\n\n## Visualising LISA map across time span (2017-2022)\n\n```{r}\n#| eval: false\n\n# Get a list of image files in the specified directory for LISA maps\nlisa_map_files <- list.files(\"data/rds/\", pattern = \"lisa_map_\\\\d{4}\\\\.png$\", full.names = TRUE)\n\n# Load saved images and combine them into an animated GIF\nlisa_images <- lapply(lisa_map_files, image_read)\n\n# Create an animation from the LISA map images\nlisa_animation <- image_animate(image_join(lisa_images), fps = 1)\n\n# Save the animation as a GIF file\nimage_write(lisa_animation, path = \"data/rds/lisa_animation.gif\")\n```\n\n```{r}\nimage_read(\"data/rds/lisa_animation.gif\")\n```\n\n## Summarize Local Moran's I values\n\n```{r}\n#| eval: false\n\nsummarize_local_moran <- function(data) {\n  data %>%\n    summarise(\n      mean_local_moran = mean(ii, na.rm = TRUE),\n      min_local_moran = min(ii, na.rm = TRUE),\n      max_local_moran = max(ii, na.rm = TRUE),\n      sd_local_moran = sd(ii, na.rm = TRUE),\n      mean_p_value = mean(p_ii_sim, na.rm = TRUE),\n      min_p_value = min(p_ii_sim, na.rm = TRUE),\n      max_p_value = max(p_ii_sim, na.rm = TRUE),\n      count_high_high = sum(ii > 0 & p_ii_sim < 0.05),\n      count_low_low = sum(ii < 0 & p_ii_sim < 0.05),\n      count_high_low = sum(ii > 0 & p_ii_sim >= 0.05),\n      count_low_high = sum(ii < 0 & p_ii_sim >= 0.05)\n    )\n}\n\n# Apply the function to each year's dataset\nlocal_moran_summary_2017 <- summarize_local_moran(lisa_2017)\nlocal_moran_summary_2018 <- summarize_local_moran(lisa_2018)\nlocal_moran_summary_2019 <- summarize_local_moran(lisa_2019)\nlocal_moran_summary_2020 <- summarize_local_moran(lisa_2020)\nlocal_moran_summary_2021 <- summarize_local_moran(lisa_2021)\nlocal_moran_summary_2022 <- summarize_local_moran(lisa_2022)\n\n# Combine summaries into a single data frame\nlocal_moran_summary_all_years <- bind_rows(\n  mutate(local_moran_summary_2017, year = 2017),\n  mutate(local_moran_summary_2018, year = 2018),\n  mutate(local_moran_summary_2019, year = 2019),\n  mutate(local_moran_summary_2020, year = 2020),\n  mutate(local_moran_summary_2021, year = 2021),\n  mutate(local_moran_summary_2022, year = 2022)\n)\n\nwrite_rds(local_moran_summary_all_years, \"data/rds/local_moran_summary_all_years.rds\")\n```\n\n```{r}\nlocal_moran_summary_all_years <- read_rds(\"data/rds/local_moran_summary_all_years.rds\")\n\n# Show all rows and columns\nprint(local_moran_summary_all_years, n = Inf, width = Inf)\n\n```\n\n::: callout-note\n### Summary of Findings:\n\n1.  **Mean Local Moran's I Values**:\n\n    -   Ranged from **0.116 to 0.201**, indicating increasing clustering of values over time.\n\n2.  **Min/Max Local Moran's I**:\n\n    -   Minimum values: **-1.37 to -0.943** (low-value clusters).\n\n    -   Maximum values: **2.14 to 4.73** (significant high-value clusters).\n\n3.  **Standard Deviation**:\n\n    -   Varied from **0.384 to 0.608**, indicating differences in clustering variability across years.\n\n4.  **P-Values**:\n\n    -   Mean p-values consistent at **0.412 to 0.455**, with a minimum p-value of **0.02**, suggesting significant clustering.\n\n5.  **Cluster Counts**:\n\n    -   High-high clusters decreased from **7** in 2017 to **2** in 2019 but increased in later years.\n\n    -   Low-low clusters remained relatively low, peaking at **3** in 2022.\n\n6.  **Yearly Trends**:\n\n    -   2022 exhibited the highest mean Local Moran's I value (**0.201**), indicating stronger clustering effects.\n:::\n\n## Hot Spot & Cold Spot Area Analysis (HCSA)\n\n::: panel-tabset\n## 2017\n\n### Computing local Gi\\* statistics\n\n```{r}\n#| eval: false\n\nHCSA_2017 <- wm_q_2017 %>% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n```\n\n### Gi\\* VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/gistar_vs_pvalue_map_2017.png\", width = 1600, height = 1200)\n\ngi_star_2017 <- tm_shape(HCSA_2017) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2017\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2017 <- tm_shape(HCSA_2017) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2017\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2017, gi_star_pvalue_2017, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/gistar_vs_pvalue_map_2017.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/hcsa_map_2017.png\", width = 1600, height = 1200)\n\nHCSA_sig_2017 <- HCSA_2017  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2017) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2017) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2017\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/hcsa_map_2017.png\")\n```\n\n## 2018\n\n### Computing local Gi\\* statistics\n\n```{r}\n#| eval: false\n\nHCSA_2018 <- wm_q_2018 %>%    \n  mutate(local_Gi = local_gstar_perm(     \n    total_cases, nb, wts, nsim = 99),          \n    .before = 1) %>%   \n  unnest(local_Gi)\n```\n\n### Visualising Hot Spot & Cold Spot (HCSA)\n\n```{r}\n#| eval: false\n\npng(\"data/rds/gistar_vs_pvalue_map_2018.png\", width = 1600, height = 1200)\n\ngi_star_2018 <- tm_shape(HCSA_2018) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2018\",\n            main.title.size = 0.8)\n\ngi_star_pvalue_2018 <- tm_shape(HCSA_2018) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2018\",\n            main.title.size = 0.8)\n\ntmap_arrange(gi_star_2018, gi_star_pvalue_2018, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/gistar_vs_pvalue_map_2018.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/hcsa_map_2018.png\", width = 1600, height = 1200)\n\nHCSA_sig_2018 <- HCSA_2018  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2018) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2018) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2018\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/hcsa_map_2018.png\")\n```\n\n## 2019\n\n### Computing local Gi\\* statistics\n\n```{r}\n#| eval: false\n\nHCSA_2019 <- wm_q_2019 %>% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n```\n\n### Gi\\* VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/gistar_vs_pvalue_map_2019.png\", width = 1600, height = 1200)\n\ngi_star_2019 <- tm_shape(HCSA_2019) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2019\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2019 <- tm_shape(HCSA_2019) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2019\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2019, gi_star_pvalue_2019, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/gistar_vs_pvalue_map_2019.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/hcsa_map_2019.png\", width = 1600, height = 1200)\n\nHCSA_sig_2019 <- HCSA_2019  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2019) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2019) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2019\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/hcsa_map_2019.png\")\n```\n\n## 2020\n\n### Computing local Gi\\* statistics\n\n```{r}\n#| eval: false\n\nHCSA_2020 <- wm_q_2020 %>% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n```\n\n### Gi\\* VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/gistar_vs_pvalue_map_2020.png\", width = 1600, height = 1200)\n\ngi_star_2020 <- tm_shape(HCSA_2020) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2020\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2020 <- tm_shape(HCSA_2020) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2020\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2020, gi_star_pvalue_2020, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/gistar_vs_pvalue_map_2020.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/hcsa_map_2020.png\", width = 1600, height = 1200)\n\nHCSA_sig_2020 <- HCSA_2020  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2020) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2020) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2020\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/hcsa_map_2020.png\")\n```\n\n## 2021\n\n### Computing local Gi\\* statistics\n\n```{r}\n#| eval: false\n\nHCSA_2021 <- wm_q_2021 %>% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n```\n\n### Gi\\* VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/gistar_vs_pvalue_map_2021.png\", width = 1600, height = 1200)\n\ngi_star_2021 <- tm_shape(HCSA_2021) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2021\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2021 <- tm_shape(HCSA_2021) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2021\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2021, gi_star_pvalue_2021, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/gistar_vs_pvalue_map_2021.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/hcsa_map_2021.png\", width = 1600, height = 1200)\n\nHCSA_sig_2021 <- HCSA_2021  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2021) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2021) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2021\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/hcsa_map_2021.png\")\n```\n\n## 2022\n\n### Computing local Gi\\* statistics\n\n```{r}\n#| eval: false\n\nHCSA_2022 <- wm_q_2022 %>% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n```\n\n### Gi\\* VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/gistar_vs_pvalue_map_2022.png\", width = 1600, height = 1200)\n\ngi_star_2022 <- tm_shape(HCSA_2022) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2022\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2022 <- tm_shape(HCSA_2022) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2022\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2022, gi_star_pvalue_2022, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/gistar_vs_pvalue_map_2022.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/hcsa_map_2022.png\", width = 1600, height = 1200)\n\nHCSA_sig_2022 <- HCSA_2022  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2022) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2022) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2022\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/hcsa_map_2022.png\")\n```\n:::\n\n::: callout-note\n### Summary of Gi\\* and P-Value Analysis\n\n1.  *Gi Statistic (Hot Spot & Cold Spot Analysis)*\\*\n\n    -   The *Gi statistic*\\* is calculated to identify **clusters of high or low values** of total cases in a given area.\n\n    -   It measures whether the number of cases in a location is significantly higher (**hot spot**) or lower (**cold spot**) than would be expected by random distribution.\n\n2.  *P-Value of Gi Statistic*\\*\n\n    -   The **p-value** determines the **statistical significance** of the observed clusters (hot or cold spots).\n\n    -   A low p-value (\\< 0.05) suggests that the cluster is **unlikely to have occurred by chance**, while a higher p-value indicates randomness in the observed pattern.\n\n3.  **Purpose of Both Analyses**\n\n    -   *Gi* of Total Cases\\* map visually displays the clustering of total cases.\n\n    -   **P-Value of Gi**\\* map helps verify whether the identified clusters are **statistically significant** or if they might be due to random variation.\n\nThese two analyses together provide a clear picture of where significant hot or cold spots are and how reliable these findings are. This ensures any conclusions drawn about spatial patterns are both **visualized** and **statistically validated**.\n:::\n\n## Visualising HCSA map across time span (2017-2022)\n\n```{r}\n#| eval: false\n\n# Get a list of image files in the specified directory for HCSA maps\nhcsa_map_files <- list.files(\"data/rds/\", pattern = \"hcsa_map_\\\\d{4}\\\\.png$\", full.names = TRUE)\n\n# Load saved images and combine them into an animated GIF\nhcsa_images <- lapply(hcsa_map_files, image_read)\n\n# Create an animation from the HCSA map images\nhcsa_animation <- image_animate(image_join(hcsa_images), fps = 1)\n\n# Save the animation as a GIF file\nimage_write(hcsa_animation, path = \"data/rds/hcsa_animation.gif\")\n```\n\n```{r}\nimage_read(\"data/rds/hcsa_animation.gif\")\n```\n\n## Summary of HCSA value\n\n```{r}\n#| eval: false\n\n# Function to summarize HCSA values for a given year\nsummarize_hcsa <- function(data) {\n  data %>%\n    summarise(\n      mean_gi_star = mean(gi_star, na.rm = TRUE),\n      min_gi_star = min(gi_star, na.rm = TRUE),\n      max_gi_star = max(gi_star, na.rm = TRUE),\n      sd_gi_star = sd(gi_star, na.rm = TRUE),\n      mean_p_value = mean(p_value, na.rm = TRUE),\n      min_p_value = min(p_value, na.rm = TRUE),\n      max_p_value = max(p_value, na.rm = TRUE),\n      count_hot_spots = sum(gi_star > 0 & p_value < 0.05),\n      count_cold_spots = sum(gi_star < 0 & p_value < 0.05),\n      count_non_significant = sum(p_value >= 0.05),\n      geometry = st_union(geometry)  # Combine geometries\n    )\n}\n\n# Summarizing HCSA for each year\nhcsa_summary_2017 <- summarize_hcsa(HCSA_2017)\nhcsa_summary_2018 <- summarize_hcsa(HCSA_2018)\nhcsa_summary_2019 <- summarize_hcsa(HCSA_2019)\nhcsa_summary_2020 <- summarize_hcsa(HCSA_2020)\nhcsa_summary_2021 <- summarize_hcsa(HCSA_2021)\nhcsa_summary_2022 <- summarize_hcsa(HCSA_2022)\n\n\nhcsa_summary_all <- bind_rows(\n  mutate(hcsa_summary_2017, year = 2017),\n  mutate(hcsa_summary_2018, year = 2018),\n  mutate(hcsa_summary_2019, year = 2019),\n  mutate(hcsa_summary_2020, year = 2020),\n  mutate(hcsa_summary_2021, year = 2021),\n  mutate(hcsa_summary_2022, year = 2022)\n)\n\nwrite_rds(hcsa_summary_all, \"data/rds/hcsa_summary_all.rds\")\n```\n\n```{r}\nhcsa_summary_all <- read_rds(\"data/rds/hcsa_summary_all.rds\")\n\n# Show all rows and columns\nprint(hcsa_summary_all, n = Inf, width = Inf)\n```\n\n::: callout-note\n### Summary of Findings:\n\n1.  *Mean Gi Values*\\*:\n\n    -   Increased from **0.0838 (2017)** to **0.199 (2022)**, indicating more hot spots over time.\n\n2.  *Gi Range*\\*:\n\n    -   Minimum values between **-2.61 to -1.47** (cold spots) and maximum values from **3.06 to 4.67** (significant hot spots).\n\n3.  **Standard Deviation**:\n\n    -   Stable variability in Gi\\* scores, ranging from **1.20 to 1.36**.\n\n4.  **P-Values**:\n\n    -   Average p-values between **0.393 to 0.529**, suggesting many Gi\\* values are not statistically significant.\n\n    -   Minimum p-values as low as **7.95e-13** indicate some significant hot spots.\n\n5.  **Count of Hot Spots and Cold Spots**:\n\n    -   Up to **7 hot spots in 2022**; several years reported **NA** for cold spots, indicating few or no significant cold spots.\n\n6.  **Overall Trends**:\n\n    -   An overall trend of increasing hot spot concentration from 2017 to 2022, suggesting growing areas affected by the phenomena studied (e.g., drug abuse, crime).\n\n### Conclusion\n\nThe HCSA findings highlight a significant rise in hot spot areas over the years, which may require targeted interventions and further investigation into the factors influencing these changes.\n:::\n\n```{r}\nlisa_animation <- image_read(\"data/rds/lisa_animation.gif\")\nhcsa_animation <- image_read(\"data/rds/hcsa_animation.gif\")\n\n# Ensure both animations have the same number of frames by replicating frames if needed\nlisa_frames <- length(lisa_animation)\nhcsa_frames <- length(hcsa_animation)\n\nif (lisa_frames != hcsa_frames) {\n  if (lisa_frames > hcsa_frames) {\n    hcsa_animation <- image_cycle(hcsa_animation, lisa_frames)\n  } else {\n    lisa_animation <- image_cycle(lisa_animation, hcsa_frames)\n  }\n}\n\n# Convert each animation into a list of individual frames\nlisa_frames_list <- as.list(lisa_animation)\nhcsa_frames_list <- as.list(hcsa_animation)\n\n# Resize each frame to ensure no margins and same height\nlisa_frames_resized <- lapply(lisa_frames_list, function(frame) {\n  image_scale(frame, \"800x\")  \n})\n\nhcsa_frames_resized <- lapply(hcsa_frames_list, function(frame) {\n  image_scale(frame, \"800x\")  \n})\n\n# Combine corresponding frames side by side with no gaps\nside_by_side_frames <- mapply(function(lisa_frame, hcsa_frame) {\n  # Use `image_append` with `stack = FALSE` for horizontal stacking\n  image_append(c(lisa_frame, hcsa_frame), stack = FALSE)\n}, lisa_frames_resized, hcsa_frames_resized, SIMPLIFY = FALSE)\n\n# Create a new animation from the combined frames\nside_by_side_animation <- image_animate(image_join(side_by_side_frames), fps = 1)\n\n# Save the final combined animation\nimage_write(side_by_side_animation, path = \"data/rds/lisa_hcsa_side_by_side_animation.gif\")\n\nside_by_side_animation\n```\n\n<br/><br/>\n\n# **6.0 Mann-Kendall Test for Trend**\n\nThis will assess the trend of drug abuse in each province over multiple years. \\[See if the abuse case is increasing, decreasing, or stable over time\\]\n\n```{r}\n#| eval: false\n\n# Apply Mann-Kendall Test for each province\ntrend_results <- summary_stats %>%\n  group_by(province_name) %>%\n  summarise(\n    total_cases = list(total_cases),         \n    trend = MannKendall(unlist(total_cases))$tau,  # Tau value indicates trend direction\n    p_value = MannKendall(unlist(total_cases))$sl,   # p-value for significance\n  )\n\n# Classify trends based on the Mann-Kendall results\ntrend_results <- trend_results %>%\n  mutate(trend_status = case_when(\n    p_value < 0.05 & trend > 0 ~ \"Increasing\",\n    p_value < 0.05 & trend < 0 ~ \"Decreasing\",\n    p_value >= 0.05 ~ \"Stable\",\n    TRUE ~ \"No sufficient data\"\n  ))\n\nwrite_rds(trend_results, \"data/rds/trend_results.rds\")\n```\n\n## Provincial Trends\n\n::: panel-tabset\n## Increasing Trends\n\n```{r}\n#| eval: false\n\nincreasing_trends <- trend_results %>%\n  filter(trend_status == \"Increasing\") %>%\n  pull(province_name)\n\nwrite_rds(increasing_trends, \"data/rds/increasing_trends.rds\")\n```\n\n```{r}\nincreasing_trends <- read_rds(\"data/rds/increasing_trends.rds\")\n\n# Check if increasing_trends is null or empty and set a default message\nif (is.null(increasing_trends) || length(increasing_trends) == 0) {\n  result <- \"NIL\"\n} else {\n  result <- paste(increasing_trends, collapse = \", \")\n}\n\ncat(result, \"\\n\")\n```\n\n## Decreasing Trends\n\n```{r}\n#| eval: false\n\ndecreasing_trends <- trend_results %>%\n  filter(trend_status == \"Decreasing\") %>%\n  pull(province_name)\n\nwrite_rds(decreasing_trends, \"data/rds/decreasing_trends.rds\")\n```\n\n```{r}\ndecreasing_trends <- read_rds(\"data/rds/decreasing_trends.rds\")\n\n# Check if decreasing_trends is null or empty and set a default message\nif (is.null(decreasing_trends) || length(decreasing_trends) == 0) {\n  result <- \"NIL\"\n} else {\n  result <- paste(decreasing_trends, collapse = \", \")\n}\n\ncat(result, \"\\n\")\n```\n\n## Stable\n\n```{r}\n#| eval: false\n\nstable_trends <- trend_results %>%\n  filter(trend_status == \"Stable\") %>%\n  pull(province_name)\n\nwrite_rds(stable_trends, \"data/rds/stable_trends.rds\")\n```\n\n```{r}\nstable_trends <- read_rds(\"data/rds/stable_trends.rds\")\n\n# Check if stable_trends is null or empty and set a default message\nif (is.null(stable_trends) || length(stable_trends) == 0) {\n  result <- \"NIL\"\n} else {\n  result <- paste(stable_trends, collapse = \", \")\n}\n\ncat(result, \"\\n\")\n```\n:::\n\n<br/><br/>\n\n# **7.0 Predicting near future trends**\n\nBy forecasting, we can enhance our strategic planning, enabling proactive policy development, targeted interventions, and more effective resource allocation. This foresight allows decision-makers to anticipate challenges and respond promptly, ultimately reducing the impact of drug abuse on communities.\n\n## Forecast Future Values\n\n```{r}\nlibrary(forecast)\n\n\narima_forecasts <- list()\n\nfor (province in unique(drug_offenses_by_province$province_name)) {\n  province_data <- drug_offenses_by_province %>%\n    filter(province_name == province) %>%\n    arrange(year)\n  \n  # Create time series object for case count\n  ts_data <- ts(province_data$case_count, start = min(province_data$year), frequency = 1)\n  \n  # Fit ARIMA model\n  fit <- auto.arima(ts_data)\n  \n  # Forecast for the next 5 years (2023 to 2027)\n  forecasted_values <- forecast(fit, h = 5)\n  \n  # Store forecast results for each year\n  arima_forecasts[[province]] <- data.frame(\n    province_name = province,\n    year = 2023:2027,\n    predicted_cases = as.numeric(forecasted_values$mean)\n  )\n}\n\n# Combine forecast results for all provinces\nfuture_predictions <- bind_rows(arima_forecasts)\n```\n\n## Hot/Cold Spot Classification\n\n```{r}\n# Set thresholds for hot and cold spots\nhot_spot_threshold <- quantile(drug_offenses_by_province$case_count, 0.75)\ncold_spot_threshold <- quantile(drug_offenses_by_province$case_count, 0.25)\n\n# Classify hot/cold spots based on predicted cases for each year\nfuture_predictions <- future_predictions %>%\n  mutate(hot_cold_label = case_when(\n    predicted_cases > hot_spot_threshold ~ \"Hot Spot\",\n    predicted_cases < cold_spot_threshold ~ \"Cold Spot\",\n    TRUE ~ \"Neutral\"\n  ))\n\nprint(future_predictions)\n```\n\n## Visualization of Predictions\n\n```{r}\nlibrary(tmap)\n\n# Merge predictions with spatial data\nfuture_spatial <- province_boundaries %>%\n  left_join(future_predictions, by = \"province_name\")\n\n\ntm_shape(future_spatial) +\n  tm_polygons(\"hot_cold_label\", palette = c(\"blue\", \"red\", \"gray\"), \n              title = \"Predicted Hot/Cold Spots (2023-2027)\") +\n  tm_borders() +\n  tm_layout(title = \"Predicted Drug Abuse Hot/Cold Spots in Thailand (2023-2027)\")\n```\n\n::: callout-note\nARIMA (AutoRegressive Integrated Moving Average) model is used for our time series forecasting.\n\nAlso it offers,\n\n-   **Flexibility**: in various time series patterns, suitable for non-stationary data.\n\n-   **Automatic Parameter Selection** (`auto.arima`): simplifies model fitting by automatically selecting optimal parameters.\n\n-   **Robustness**: in capturing fluctuations in historical data.\n:::\n","srcMarkdownNoYaml":"\n\n# **Introduction**\n\n### Drug Abuse Overview\n\n-   **Global Impact**: Drug abuse has severe health, financial, and social consequences.\n\n-   **Prevalence**: In 2021, 1 in 17 people aged 15–64 worldwide used a drug in the past year.\n\n-   **Growth Trend**: Drug users increased from 240 million in 2011 to 296 million in 2021.\n\n### Drug Situation in Thailand\n\n-   **Geopolitical Context**: Proximity to the [Golden Triangle](https://en.wikipedia.org/wiki/Golden_Triangle_(Southeast_Asia)), a major drug production area, makes Thailand a key market and transit route for drug trafficking.\n\n-   **Youth Drug Abuse**:\n\n    -   Approximately 2.7 million young people in Thailand use drugs.\n\n    -   Around 300,000 youth aged 15-19 need drug treatment.\n\n    -   Vocational students are nearly twice as involved with drugs compared to secondary-school students.![](https://is415-ay2024-25t1.netlify.app/img/th_ex2_img1.png)\n\n**This Geospatial Analytics will Focus on:**\n\n-   **Objective:** Determine if drug abuse indicators in Thailand show spatial dependence.\n-   **Analysis Goals**:\n    -   Identify clusters, outliers, and hotspots of drug abuse.\n\n    -   Examine how these patterns change over time.\n\n<br/><br/>\n\n# **1.0 Setup**\n\n## 1.1 Installing R-Packages\n\n::: panel-tabset\n## *Importing and Transforming Data*\n\n-   `sf`:\n\n    -   For handling spatial vector data and transforming it into simple features (`sf`) objects.\n\n    -   Functions like `st_read()` for importing spatial data and `st_transform()` for coordinate reference system transformations.\n\n-   `tidyverse`: For data manipulation and transformation, including functions for working with `tibble` data frames.\n\n-   `readr`: For reading in CSV or other text-based data files if needed.\n\n-   `dplyr`: provide data manipulation capabilities (eg. to group and summarize the relationships between these columns)\n\n-   `arrow`: To read parquet files\n\n## *Displaying Maps*\n\n-   `tmap`: For creating thematic maps and displaying KDE layers.\n\n-   `ggplot2`: For additional custom visualizations if needed.\n\n-   *`scales`*: Transform the unit of measurement for coordinate\n\n-   `animation, png, magick`: For animation work\n\n## *Spatial Autocorrelation*\n\n-   `sfdep`: For performing both local and global spatial autocorrelation analysis\n\n## *Prediction*\n\n-   `forecast`: For trend prediction\n:::\n\n```{r}\npacman::p_load(tidyverse, sf, readr, ggplot2, tmap, dplyr, arrow, sfdep, scales, animation, png, magick, patchwork, Kendall, zoo, forecast)\n```\n\n<br/>\n\n## 1.2 Data Acquisition\n\nWe will be using 2 sets of data:\n\n::: panel-tabset\n## Drug offenses Data\n\n-   **Source:** [[Thailand Drug Offenses \\[2017-2022\\]]{.underline}](https://www.kaggle.com/datasets/thaweewatboy/thailand-drug-offenses-2017-2022)\n\n-   **Study Period:** 2017-2022\n\n## Administrative Boundaries\n\n-   **Source:** [Thailand - Subnational Administrative Boundaries](https://data.humdata.org/dataset/cod-ab-tha?) at HDX.\n-   **Province Boundaries**: For understanding conflict distribution across larger administrative divisions.\n:::\n\n<br/>\n\n## 1.3 Importing Geospatial Data into R\n\n::: panel-tabset\n## Drug Offenses Data\n\n```{r}\n#| eval: false\ndrug_offenses <- read_parquet(\"data/drug_offense/thai_drug_offenses_2017_2022.parquet\")\n```\n\n```{r}\ndrug_offenses <- read_csv(\"data/drug_offense/thai_drug_offenses_2017_2022.csv\")\n```\n\n::: callout-note\nSince the data in CSV and Parquet formats are identical, we only need to import one of these file types.\n:::\n\n## Administrative Boundaries\n\n```{r}\nprovince_boundaries <- st_read(dsn = \"data/subnational_administrative_boundary\", layer=\"tha_admbnda_adm1_rtsd_20220121\")\n```\n:::\n\n<br/>\n\n## 1.4 Checking Geospatial Data\n\n::: panel-tabset\n## Drug Offenses Data\n\n```{r}\nclass(drug_offenses)\n```\n\n::: callout-note\nSince\n\n-   Since the class of **drug_offenses** != sf object\n\nwe have to transform it.\n:::\n\n## Administrative Boundaries\n\n```{r}\nclass(province_boundaries)\nst_crs(province_boundaries)\n```\n\n::: callout-note\nSince Coordinate Reference System of **province_boundaries**\n\nis in 4326 (unit of measurement = degree), we have to transform it\n:::\n:::\n\n<br/>\n\n## 1.6 Data Preparation and Wrangling\n\n::: panel-tabset\n## Drug Offenses Data\n\n```{r}\n# Drop & Rename column\ndrug_offenses <- drug_offenses %>% \n  select(fiscal_year, types_of_drug_offenses, no_cases, province_en) %>% \n  rename(\n    year = fiscal_year,\n    offense_type = types_of_drug_offenses,\n    case_count = no_cases,\n    province_name = province_en\n  )\n```\n\n## Administrative Boundaries\n\n##### Transform the Coordinate Reference System of these:\n\n```{r}\nprovince_boundaries <- province_boundaries %>%\n  st_transform(crs = 4240)\n```\n\n```{r}\n# Drop & Rename column\nprovince_boundaries <- province_boundaries %>% \n  select(Shape_Leng, Shape_Area, ADM1_EN, ADM1_PCODE, geometry) %>% \n  rename(\n    province_name = ADM1_EN,\n    province_code = ADM1_PCODE\n  )\n```\n\n##### Sample plot\n\n```{r}\nggplot(data = province_boundaries) +\n  geom_sf() +\n  theme_minimal() +\n  labs(title = \"Map of Geometries\",\n       subtitle = \"Displaying multipolygon geometries\",\n       caption = \"Source: Example Data\")\n```\n\n## Understanding the Data\n\n```{r}\n# Filter for unmatched province_names between Drug Offenses & Province Boundaries data set\nunmatched_provinces <- drug_offenses %>%\n  left_join(province_boundaries, by = \"province_name\") %>%\n  filter(is.na(Shape_Leng)) %>%\n  select(province_name)\n\nunmatched_provinces <- unique(unmatched_provinces) #Loburi, buogkan\n\n\n\n# Transform the province_name in the Drug Offenses dataset\ndrug_offenses <- drug_offenses %>%\n  mutate(province_name = case_when(\n    province_name == \"Loburi\" ~ \"Lop Buri\",\n    province_name == \"buogkan\" ~ \"Bueng Kan\",\n    TRUE ~ province_name  # Keep the original name if no match\n  ))\n\n\n# Assign each drug offense to a province\ndrug_offenses_by_province <- drug_offenses %>%\n  left_join(province_boundaries, by = \"province_name\")\n\n# Check for any empty attributes in the test dataset\nempty_attributes <- sapply(drug_offenses_by_province, function(column) any(is.na(column)))\n\n# Identify columns with missing values\nmissing_columns <- names(empty_attributes[empty_attributes]) # character(0) = No missing Column\n```\n\n::: callout-warning\nThe **Drug Offenses** dataset has some naming issues with `province_name`.\n\nWe found two discrepancies: **Loburi** should be changed to **Lop Buri**, and **buogkan** should be updated to **Bueng Kan** to match the **Province Boundaries** dataset.\n\nWe will update the `province_name` entries in the **Drug Offenses** dataset accordingly.\n:::\n:::\n\n<br/><br/>\n\n# **2.0 Understanding the Data**\n\n```{r}\noffense_type <- unique(drug_offenses_by_province$offense_type) \nprint(offense_type)\n```\n\n::: callout-note\nThese varying degrees of offense types may reveal patterns and trends in drug-related activities, providing a comprehensive understanding of the issue at hand.\n:::\n\n<br/><br/>\n\n# **3.0 Exploratory Data Analysis**\n\n## Summary statistics\n\n```{r}\n#| eval: false\nsummary_stats <- drug_offenses_by_province %>%\n  group_by(province_name, year) %>%\n  summarise(\n    total_cases = sum(case_count, na.rm = TRUE),\n    geometry = first(geometry)\n    )\n\nwrite_rds(summary_stats, \"data/rds/summary_stats.rds\")\n```\n\n```{r}\nsummary_stats <- read_rds(\"data/rds/summary_stats.rds\")\nsummary_stats\n```\n\n## Top /Bottom 10 Related-Drug Incidents Provinces\n\n```{r}\n# Loop through each year and plot top 10 provinces\nyears_to_plot <- unique(summary_stats$year)\n```\n\n::: panel-tabset\n## Top 10 Drug Abuse Provinces\n\n```{r}\n#| eval: false\n\ntop_10_plot_list <- list()\n\n# Loop through each year and create the plots for top 10\nfor (current_year in years_to_plot) {\n  # Filter and sort the data for the specific year\n  top_10_year_data <- summary_stats %>%\n    filter(year == current_year) %>%\n    arrange(desc(total_cases)) %>%\n    head(10)\n  \n  # Create the plot for the current year\n  top_10_plot <- ggplot(top_10_year_data, aes(x = reorder(province_name, total_cases), y = total_cases)) +\n    geom_bar(stat = \"identity\", fill = \"pink\", width = 0.8) +\n    coord_flip() +\n    labs(x = NULL, y = NULL, subtitle = paste(\"Year:\", current_year)) +\n    scale_y_continuous(labels = scales::comma_format(accuracy = 1)) +\n    theme_minimal(base_size = 10) +\n    geom_text(aes(label = total_cases),\n              position = position_stack(vjust = 0.5),   \n              color = \"black\", \n              size = 3) +\n    theme(axis.text.x = element_blank(),   # Hide the y-axis text\n          axis.ticks.x = element_blank())  # Hide the y-axis ticks\n  \n  # Add the plot to the list\n  top_10_plot_list[[as.character(current_year)]] <- top_10_plot\n}\n\n# Combine the top 10 plots into a grid\ntop_10_plot_list <- wrap_plots(top_10_plot_list)\n\n# Add a single title to the combined plot\ntop_10_plot_list <- top_10_plot_list +\n  plot_annotation(title = \"Top 10 Provinces by Total Drug Abuse Cases Over the Years\")\n\nwrite_rds(top_10_plot_list, \"data/rds/top_10_plot_list.rds\")\n\n```\n\n```{r}\nprint(read_rds(\"data/rds/top_10_plot_list.rds\"))\n```\n\n## Bottom 10 Drug Abuse Provinces\n\n```{r}\n#| eval: false\n\n# Create a list to store the bottom 10 plots\nbottom_10_plot_list <- list()\n\n# Loop through each year and create the plots for bottom 10\nfor (current_year in years_to_plot) {\n  # Filter and sort the data for the specific year to get the bottom 10\n  bottom_10_year_data <- summary_stats %>%\n    filter(year == current_year) %>%\n    arrange(total_cases) %>%   # Ascending order to get bottom cases\n    head(10)\n  \n  # Create the plot for the current year\n  bottom_10_plot <- ggplot(bottom_10_year_data, aes(x = reorder(province_name, -total_cases), y = total_cases)) +\n    geom_bar(stat = \"identity\", fill = \"steelblue\", width = 0.8) +\n    coord_flip() +\n    labs(x = NULL, y = NULL, subtitle = paste(\"Year:\", current_year)) +  # Subtitle to display year\n    scale_y_continuous(labels = scales::comma_format(accuracy = 1)) +\n    theme_minimal(base_size = 10) +\n    geom_text(aes(label = total_cases),\n              position = position_stack(vjust = 0.5),   \n              color = \"black\", \n              size = 3) +\n    theme(axis.text.x = element_blank(),   # Hide the y-axis text\n          axis.ticks.x = element_blank())  # Hide the y-axis ticks\n  \n  # Add the plot to the list\n  bottom_10_plot_list[[as.character(current_year)]] <- bottom_10_plot\n}\n\n# Combine the bottom 10 plots into a grid\nbottom_10_plot_list <- wrap_plots(bottom_10_plot_list)\n\n# Add a single title to the combined plot\nbottom_10_plot_list <- bottom_10_plot_list +\n  plot_annotation(title = \"Bottom 10 Provinces by Total Drug Abuse Cases Over the Years\")\n\nwrite_rds(bottom_10_plot_list, \"data/rds/bottom_10_plot_list.rds\")\n```\n\n```{r}\nprint(read_rds(\"data/rds/bottom_10_plot_list.rds\"))\n```\n:::\n\n## Trends over time for the entire country\n\n```{r}\ndrug_trends <- drug_offenses_by_province %>%\n  group_by(year) %>%\n  summarise(total_cases = sum(case_count))\n\n# Plot trend over time with formatted y-axis labels\nggplot(drug_trends, aes(x = year, y = total_cases)) +\n  geom_line(color = \"blue\") +\n  geom_point(size = 3, color = \"red\") +  \n  labs(title = \"Drug Abuse Cases Over Time\",\n       x = \"Year\", y = \"Total Cases\") +\n  scale_y_continuous(labels = comma)\n\n```\n\n<br/><br/>\n\n# **4.0 Global Spatial Autocorrelation Analysis**\n\nOrganize into years for more detailed analysis:\n\n```{r}\nsummary_stats <- st_as_sf(summary_stats)\n\nsummary_stats_2017 <- summary_stats %>%\n  filter(year == 2017) %>%\n  ungroup()  # Remove any grouping\n\nsummary_stats_2018 <- summary_stats %>%\n  filter(year == 2018) %>%\n  ungroup()  # Remove any grouping\n\nsummary_stats_2019 <- summary_stats %>%\n  filter(year == 2019) %>%\n  ungroup()  # Remove any grouping\n\nsummary_stats_2020 <- summary_stats %>%\n  filter(year == 2020) %>%\n  ungroup()  # Remove any grouping\n\nsummary_stats_2021 <- summary_stats %>%\n  filter(year == 2021) %>%\n  ungroup()  # Remove any grouping\n\nsummary_stats_2022 <- summary_stats %>%\n  filter(year == 2022) %>%\n  ungroup()  # Remove any grouping\n```\n\n### Deriving Queen’s Contiguity weights: sfdep methods\n\n```{r}\n#| eval: false\n\nnb <- st_contiguity(summary_stats_2017$geometry)\nwt <- st_weights(nb, style = \"W\", allow_zero = TRUE)\n\n\nwm_q_2017 <- summary_stats_2017 %>% \n  mutate(\n    nb = nb,\n    wt = wt,\n    .before = 1\n  )\n\nwm_q_2018 <- summary_stats_2018 %>% \n  mutate(\n    nb = nb,\n    wt = wt,\n    .before = 1\n  )\n\nwm_q_2019 <- summary_stats_2019 %>% \n  mutate(\n    nb = nb,\n    wt = wt,\n    .before = 1\n  )\n\nwm_q_2020 <- summary_stats_2020 %>% \n  mutate(\n    nb = nb,\n    wt = wt,\n    .before = 1\n  )\n\nwm_q_2021 <- summary_stats_2021 %>% \n  mutate(\n    nb = nb,\n    wt = wt,\n    .before = 1\n  )\n\nwm_q_2022 <- summary_stats_2022 %>% \n  mutate(\n    nb = nb,\n    wt = wt,\n    .before = 1\n  )\n\nwrite_rds(wm_q_2017, \"data/rds/wm_q_2017.rds\")\nwrite_rds(wm_q_2018, \"data/rds/wm_q_2018.rds\")\nwrite_rds(wm_q_2019, \"data/rds/wm_q_2019.rds\")\nwrite_rds(wm_q_2020, \"data/rds/wm_q_2020.rds\")\nwrite_rds(wm_q_2021, \"data/rds/wm_q_2021.rds\")\nwrite_rds(wm_q_2022, \"data/rds/wm_q_2022.rds\")\n```\n\nInitialize for use later:\n\n```{r}\nwm_q_2017 <- read_rds(\"data/rds/wm_q_2017.rds\")\nwm_q_2018 <- read_rds(\"data/rds/wm_q_2018.rds\")\nwm_q_2019 <- read_rds(\"data/rds/wm_q_2019.rds\")\nwm_q_2020 <- read_rds(\"data/rds/wm_q_2020.rds\")\nwm_q_2021 <- read_rds(\"data/rds/wm_q_2021.rds\")\nwm_q_2022 <- read_rds(\"data/rds/wm_q_2022.rds\")\n```\n\n::: callout-note\nTo derive spatial autocorrelation, we first gather the relevant geographic points for our study area:\n\n1.  **Filtering for Unique Geographic Points**: The `summary_stats` dataset contains multiple entries for each geographic point across different years. We filter it to retain data for a single year (e.g., 2017) to work with a unique set of locations.\n\n2.  **Identifying Neighbors**: To assess the spatial relationships between areas, we identify neighboring regions. We use Queen's contiguity weights, which include all neighbors that touch at edges or corners, capturing comprehensive spatial interactions.\n\n3.  **Calculating Weights**: After identifying neighbors, we calculate spatial weights that quantify the influence neighboring areas have on one another. These weights are crucial for measuring spatial autocorrelation, as they inform how a variable in one area relates to values in its neighbors.\n:::\n\n## 2017: An Initial Overview\n\n### Global Moran' I\n\n::: panel-tabset\n## Computing Global Moran’ I\n\n```{r}\nmoranI_2017 <- global_moran(wm_q_2017$total_cases,\n                       wm_q_2017$nb,\n                       wm_q_2017$wt)\n\nglimpse(moranI_2017)\n```\n\n## Performing Global Moran’s I test\n\n```{r}\nglobal_moran_test(wm_q_2017$total_cases,\n                  wm_q_2017$nb,\n                  wm_q_2017$wt,\n                  zero.policy = TRUE)\n```\n\n::: callout-note\nMoran I statistic (0.133140650) -\\> indicates a positive correlation in the variable of interest (e.g., total cases).\n\nSD of 2.4598 -\\> suggests that Moran’s I is greater than the expected value under the null hypothesis.\n\nP-value of 0.006951 -\\> is \\< 0.05, indicating strong statistical significance.\n\nExpectation of -0.013333333 -\\> suggests we would expect slight negative autocorrelation if there were no spatial structure.\n\nSince the p-value \\< 0.05, we reject the null hypothesis of no spatial autocorrelation. This strongly suggests there is significant positive spatial clustering of the variable in the study area (regions with high values are near areas with high values).\n:::\n\n## Performing Global Moran’s I permutation test (Monte Carlo)\n\n```{r}\nset.seed(1234)\n\nglobal_moran_perm_result_2017 <- global_moran_perm(wm_q_2017$total_cases,\n                                              wm_q_2017$nb,\n                                              wm_q_2017$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2017\n```\n\n```{r}\nsummary(global_moran_perm_result_2017$res)\n```\n\n```{r}\n#| eval: false\n\npng(\"data/rds/global_moran_perm_result_2017.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values <- global_moran_perm_result_2017$res\n\nglobal_moran_perm_hist_2017 <- hist(simulated_values, \n                                    freq=TRUE, \n                                    breaks=20, \n                                    xlab=\"Simulated Moran's I in 2017\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/global_moran_perm_result_2017.png\")\n```\n\n::: callout-note\nTo ensure our results are accurate, we'll perform a Monte Carlo (permutation) test on Moran’s I statistic. This method helps us understand if the observed clustering of values is statistically significant.\n\nFirst, we set the seed using `set.seed(1234)`. This step is crucial because it guarantees that our simulation results will be reproducible. Every time we run the simulation, we should get the same outcomes, which is important for consistency in our analysis.\n\nNow, looking at the results from our permutation test:\n\n-   **Moran’s I statistic**: 0.13314\n\n-   **Observed rank**: 98\n\n-   **P-value**: 0.04\n\nThe p-value being less than 0.05 tells us that there's strong statistical evidence against the null hypothesis of no spatial autocorrelation. This means we can conclude there’s significant positive spatial clustering in our data—areas with high values are near other areas with high values.\n\nLooking at the summary of the simulated statistics, with the maximum being 0.162326 and the minimum at -0.151935. The distribution of these values helps us understand the expected behavior of our statistic under the null hypothesis.\n:::\n:::\n\n::: callout-note\nIt's important to note that some areas may have no neighboring regions, which results in null weights. To address this, we use `zero.policy = TRUE` in our analysis, allowing regions with no neighbors to be included without causing errors in calculations.\n\nHowever, it's essential to understand that Global Moran's I does not accommodate regions without neighbors in its calculations, meaning that these regions, even when included, will not contribute to the overall assessment of spatial autocorrelation.\n\nConsequently, regions with null weights may still affect the results, leading to potential skewing of the analysis and limiting its interpretability. Therefore, careful consideration of how to handle such regions is crucial for ensuring accurate spatial analysis.\n:::\n\n## Visualising across time span (2017-2022)\n\n::: panel-tabset\n## 2018 Global Moran' I\n\n### Performing Global Moran’s I permutation test (Monte Carlo)\n\n```{r}\nset.seed(1234)\n\nglobal_moran_perm_result_2018 <- global_moran_perm(wm_q_2018$total_cases,\n                                              wm_q_2018$nb,\n                                              wm_q_2018$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2018\n```\n\n```{r}\nsummary(global_moran_perm_result_2018$res)\n```\n\n```{r}\n#| eval: false\n\npng(\"data/rds/global_moran_perm_result_2018.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values <- global_moran_perm_result_2018$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2018\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/global_moran_perm_result_2018.png\")\n```\n\n## 2019 Global Moran' I\n\n### Performing Global Moran’s I permutation test (Monte Carlo)\n\n```{r}\nset.seed(1234)\n\nglobal_moran_perm_result_2019 <- global_moran_perm(wm_q_2019$total_cases,\n                                              wm_q_2019$nb,\n                                              wm_q_2019$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2019\n```\n\n```{r}\nsummary(global_moran_perm_result_2019$res)\n```\n\n```{r}\n#| eval: false\n\npng(\"data/rds/global_moran_perm_result_2019.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values <- global_moran_perm_result_2019$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2019\")\nabline(v=0, \n       col=\"red\") \n\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/global_moran_perm_result_2019.png\")\n```\n\n## 2020 Global Moran' I\n\n### Performing Global Moran’s I permutation test (Monte Carlo)\n\n```{r}\nset.seed(1234)\n\nglobal_moran_perm_result_2020 <- global_moran_perm(wm_q_2020$total_cases,\n                                              wm_q_2020$nb,\n                                              wm_q_2020$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2020\n```\n\n```{r}\nsummary(global_moran_perm_result_2020$res)\n```\n\n```{r}\n#| eval: false\n\npng(\"data/rds/global_moran_perm_result_2020.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values <- global_moran_perm_result_2020$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2020\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/global_moran_perm_result_2020.png\")\n```\n\n## 2021 Global Moran' I\n\n### Performing Global Moran’s I permutation test (Monte Carlo)\n\n```{r}\nset.seed(1234)\n\nglobal_moran_perm_result_2021 <- global_moran_perm(wm_q_2021$total_cases,\n                                              wm_q_2021$nb,\n                                              wm_q_2021$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2021\n```\n\n```{r}\nsummary(global_moran_perm_result_2021$res)\n```\n\n```{r}\n#| eval: false\n\npng(\"data/rds/global_moran_perm_result_2021.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values <- global_moran_perm_result_2021$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2021\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off() \n```\n\n```{r}\nimage_read(\"data/rds/global_moran_perm_result_2021.png\")\n```\n\n## 2022 Global Moran' I\n\n### Performing Global Moran’s I permutation test (Monte Carlo)\n\n```{r}\nset.seed(1234)\n\nglobal_moran_perm_result_2022 <- global_moran_perm(wm_q_2022$total_cases,\n                                              wm_q_2022$nb,\n                                              wm_q_2022$wt,\n                                              zero.policy = TRUE,\n                                              nsim = 99)\nglobal_moran_perm_result_2022\n```\n\n```{r}\nsummary(global_moran_perm_result_2022$res)\n```\n\n```{r}\n#| eval: false\n\npng(\"data/rds/global_moran_perm_result_2022.png\", width = 1600, height = 1000)\n\n# Adjust font size and scaling using par()\npar(cex = 2,       # Overall scaling for text and symbols\n    cex.axis = 1.5, # Axis text size\n    cex.lab = 2,    # Axis label size\n    cex.main = 2.5, # Main title size\n    mar = c(5, 5, 4, 2) + 0.1) # Adjust margins for more space around the plot\n\n# Extract the simulated statistics and observed statistic\nsimulated_values <- global_moran_perm_result_2022$res\n\nhist(simulated_values, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I in 2022\")\nabline(v=0, \n       col=\"red\") \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/global_moran_perm_result_2022.png\")\n```\n:::\n\n::: callout-note\n-   The results indicate a general trend of positive spatial autocorrelation from 2017 to 2022, with significant clustering observed in 2021 and 2022.\n\n-   The years 2017, 2019, 2021, and 2022 show statistically significant evidence of clustering, while 2018 and 2020 have lower evidence of spatial correlation.\n\n-   This trend suggests that the variable of interest tends to cluster in certain areas, particularly from 2021 onwards, which may warrant further investigation into the factors driving this clustering.\n:::\n\n```{r}\n#| eval: false\n\n# Get a list of image files in the specified directory\nglobal_moran_perm_result_files <- list.files(\"data/rds/\", pattern = \"\\\\.png$\", full.names = TRUE)\n\n# Load saved images and combine them into an animated GIF\nglobal_moran_images <- lapply(global_moran_perm_result_files, image_read)\n\n# Create an animation from the Global Moran's images\nglobal_moran_animation <- image_animate(image_join(global_moran_images), fps = 1)\n\n# Save the animation as a GIF file\nimage_write(global_moran_animation, path = \"data/rds/global_moran_animation.gif\")\n```\n\n```{r}\nimage_read(\"data/rds/global_moran_animation.gif\")\n```\n\n<br/><br/>\n\n# **5.0 Local Spatial Autocorrelation Analysis**\n\n## Visualising LISA Map\n\n::: panel-tabset\n## 2017\n\n### Computing Local Moran's I\n\n```{r}\n#| eval: false\nlisa_2017 <- wm_q_2017 %>% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %>% \n  unnest(local_moran)\n```\n\n### Local Moran's I VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/local_moran_vs_pvalue_map_2017.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2017 <- tm_shape(lisa_2017) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2017\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2017 <- tm_shape(lisa_2017) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (< 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (> 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2017\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2017, local_moran_pvalue_map_2017, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2017.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/lisa_map_2017.png\", width = 1600, height = 1200)\n\nlisa_sig_2017 <- lisa_2017  %>%\n  filter(p_ii_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2017) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2017) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2017\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/lisa_map_2017.png\")\n```\n\n## 2018\n\n### Computing Local Moran's I\n\n```{r}\n#| eval: false\n\nlisa_2018 <- wm_q_2018 %>% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %>% \n  unnest(local_moran)\n```\n\n### Local Moran's I VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/local_moran_vs_pvalue_map_2018.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2018 <- tm_shape(lisa_2018) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2018\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2018 <- tm_shape(lisa_2018) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (< 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (> 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2018\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2018, local_moran_pvalue_map_2018, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2018.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/lisa_map_2018.png\", width = 1600, height = 1200)\n\nlisa_sig_2018 <- lisa_2018  %>%\n  filter(p_ii_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2018) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2018) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2018\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/lisa_map_2018.png\")\n```\n\n## 2019\n\n### Computing Local Moran's I\n\n```{r}\n#| eval: false\n\nlisa_2019 <- wm_q_2019 %>% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %>% \n  unnest(local_moran)\n```\n\n### Local Moran's I VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/local_moran_vs_pvalue_map_2019.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2019 <- tm_shape(lisa_2019) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2019\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2019 <- tm_shape(lisa_2019) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (< 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (> 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2019\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2019, local_moran_pvalue_map_2019, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2019.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/lisa_map_2019.png\", width = 1600, height = 1200)\n\nlisa_sig_2019 <- lisa_2019  %>%\n  filter(p_ii_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2019) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2019) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2019\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/lisa_map_2019.png\")\n```\n\n## 2020\n\n### Computing Local Moran's I\n\n```{r}\n#| eval: false\n\nlisa_2020 <- wm_q_2020 %>% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %>% \n  unnest(local_moran)\n```\n\n### Local Moran's I VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/local_moran_vs_pvalue_map_2020.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2020 <- tm_shape(lisa_2020) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2020\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2020 <- tm_shape(lisa_2020) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (< 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (> 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2020\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2020, local_moran_pvalue_map_2020, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2020.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/lisa_map_2020.png\", width = 1600, height = 1200)\n\nlisa_sig_2020 <- lisa_2020  %>%\n  filter(p_ii_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2020) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2020) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2020\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/lisa_map_2020.png\")\n```\n\n## 2021\n\n### Computing Local Moran's I\n\n```{r}\n#| eval: false\n\nlisa_2021 <- wm_q_2021 %>% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %>% \n  unnest(local_moran)\n```\n\n### Local Moran's I VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/local_moran_vs_pvalue_map_2021.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2021 <- tm_shape(lisa_2021) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2021\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2021 <- tm_shape(lisa_2021) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (< 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (> 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2021\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2021, local_moran_pvalue_map_2021, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2021.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/lisa_map_2021.png\", width = 1600, height = 1200)\n\nlisa_sig_2021 <- lisa_2021  %>%\n  filter(p_ii_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2021) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2021) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2021\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/lisa_map_2021.png\")\n```\n\n## 2022\n\n### Computing Local Moran's I\n\n```{r}\n#| eval: false\n\nlisa_2022 <- wm_q_2022 %>% \n  mutate(local_moran = local_moran(\n    total_cases, nb, wt, nsim = 99, zero.policy = TRUE),\n    .before = 1) %>% \n  unnest(local_moran)\n```\n\n### Local Moran's I VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/local_moran_vs_pvalue_map_2022.png\", width = 1600, height = 1000)\n\ntmap_mode(\"plot\")\nlocal_moran_map_2022 <- tm_shape(lisa_2022) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of Total Cases in 2022\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\nlocal_moran_pvalue_map_2022 <- tm_shape(lisa_2022) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\n                \"Highly significant (< 0.001)\", \n                \"Significant (0.001 - 0.01)\",\n                \"Moderately significant (0.01 - 0.05)\", \n                \"Not significant (> 0.05)\"\n              )) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I of Total Cases in 2022\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(local_moran_map_2022, local_moran_pvalue_map_2022, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/local_moran_vs_pvalue_map_2022.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/lisa_map_2022.png\", width = 1600, height = 1200)\n\nlisa_sig_2022 <- lisa_2022  %>%\n  filter(p_ii_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(lisa_2022) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_2022) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA Map 2022\",   \n            main.title.size = 2.5,              \n            legend.text.size = 2.0,           \n            legend.title.size = 2.7,         \n            legend.position = c(\"right\", \"bottom\"), \n            frame = TRUE)  # Add a frame around the map\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/lisa_map_2022.png\")\n```\n:::\n\n::: callout-note\n**Computing Local Moran’s I**\n\nadd new column \\[local_moran\\] -\\> stores the calculated Local Moran's I values\n\n`zero.policy = TRUE` option allows the method to handle regions without neighbors appropriately.\n\nunnest(local_moran) -\\> flatten the results, simplifying further analysis of the output.\n\n**Local Moran’s I VS P-Value Visualization**\n\nThis segment creates visualizations for the Local Moran's I statistic and its associated p-values for the year 2017\n\nLocal Moran's I values (color-coded) indicating spatial clustering: Ranges from -1.0 (cold spots) to 3.0 (strong hot spots). Provides insights into areas of similar or dissimilar values in case distribution.\n\nP-Value Map:\n\nIllustrates the statistical significance of Local Moran's I: Breaks defined for p-values (\\< 0.001, 0.001-0.01, 0.01-0.05, \\> 0.05).\n\n**Putting Together Significant LISA Results**\n\nThis segment visualizes the significant clusters identified by the Local Moran's I analysis.\n\nThe visualization includes both all regions and the significant clusters, with the latter highlighted based on their mean Local Moran's I values.\n\n1.  **Low-Low (LL)**\n\n-   **Definition**: Areas with low values surrounded by other low-value areas.\n\n-   **Interpretation**: Indicates regions that are underperforming or stable and may not need immediate intervention.\n\n2.  **High-Low (HL)**\n\n-   **Definition**: Areas with high values surrounded by low-value areas.\n\n-   **Interpretation**: Highlights potential hotspots that require further investigation or targeted intervention.\n\n3.  **Low-High (LH)**\n\n-   **Definition**: Areas with low values surrounded by high-value areas.\n\n-   **Interpretation**: Suggests vulnerability to spillover effects from neighboring high-value regions, requiring monitoring.\n\n4.  **High-High (HH)**\n\n-   **Definition**: Areas with high values surrounded by other high-value areas.\n\n-   **Interpretation**: Identifies significant hotspots that may need immediate attention and indicate systemic issues.\n:::\n\n## Visualising LISA map across time span (2017-2022)\n\n```{r}\n#| eval: false\n\n# Get a list of image files in the specified directory for LISA maps\nlisa_map_files <- list.files(\"data/rds/\", pattern = \"lisa_map_\\\\d{4}\\\\.png$\", full.names = TRUE)\n\n# Load saved images and combine them into an animated GIF\nlisa_images <- lapply(lisa_map_files, image_read)\n\n# Create an animation from the LISA map images\nlisa_animation <- image_animate(image_join(lisa_images), fps = 1)\n\n# Save the animation as a GIF file\nimage_write(lisa_animation, path = \"data/rds/lisa_animation.gif\")\n```\n\n```{r}\nimage_read(\"data/rds/lisa_animation.gif\")\n```\n\n## Summarize Local Moran's I values\n\n```{r}\n#| eval: false\n\nsummarize_local_moran <- function(data) {\n  data %>%\n    summarise(\n      mean_local_moran = mean(ii, na.rm = TRUE),\n      min_local_moran = min(ii, na.rm = TRUE),\n      max_local_moran = max(ii, na.rm = TRUE),\n      sd_local_moran = sd(ii, na.rm = TRUE),\n      mean_p_value = mean(p_ii_sim, na.rm = TRUE),\n      min_p_value = min(p_ii_sim, na.rm = TRUE),\n      max_p_value = max(p_ii_sim, na.rm = TRUE),\n      count_high_high = sum(ii > 0 & p_ii_sim < 0.05),\n      count_low_low = sum(ii < 0 & p_ii_sim < 0.05),\n      count_high_low = sum(ii > 0 & p_ii_sim >= 0.05),\n      count_low_high = sum(ii < 0 & p_ii_sim >= 0.05)\n    )\n}\n\n# Apply the function to each year's dataset\nlocal_moran_summary_2017 <- summarize_local_moran(lisa_2017)\nlocal_moran_summary_2018 <- summarize_local_moran(lisa_2018)\nlocal_moran_summary_2019 <- summarize_local_moran(lisa_2019)\nlocal_moran_summary_2020 <- summarize_local_moran(lisa_2020)\nlocal_moran_summary_2021 <- summarize_local_moran(lisa_2021)\nlocal_moran_summary_2022 <- summarize_local_moran(lisa_2022)\n\n# Combine summaries into a single data frame\nlocal_moran_summary_all_years <- bind_rows(\n  mutate(local_moran_summary_2017, year = 2017),\n  mutate(local_moran_summary_2018, year = 2018),\n  mutate(local_moran_summary_2019, year = 2019),\n  mutate(local_moran_summary_2020, year = 2020),\n  mutate(local_moran_summary_2021, year = 2021),\n  mutate(local_moran_summary_2022, year = 2022)\n)\n\nwrite_rds(local_moran_summary_all_years, \"data/rds/local_moran_summary_all_years.rds\")\n```\n\n```{r}\nlocal_moran_summary_all_years <- read_rds(\"data/rds/local_moran_summary_all_years.rds\")\n\n# Show all rows and columns\nprint(local_moran_summary_all_years, n = Inf, width = Inf)\n\n```\n\n::: callout-note\n### Summary of Findings:\n\n1.  **Mean Local Moran's I Values**:\n\n    -   Ranged from **0.116 to 0.201**, indicating increasing clustering of values over time.\n\n2.  **Min/Max Local Moran's I**:\n\n    -   Minimum values: **-1.37 to -0.943** (low-value clusters).\n\n    -   Maximum values: **2.14 to 4.73** (significant high-value clusters).\n\n3.  **Standard Deviation**:\n\n    -   Varied from **0.384 to 0.608**, indicating differences in clustering variability across years.\n\n4.  **P-Values**:\n\n    -   Mean p-values consistent at **0.412 to 0.455**, with a minimum p-value of **0.02**, suggesting significant clustering.\n\n5.  **Cluster Counts**:\n\n    -   High-high clusters decreased from **7** in 2017 to **2** in 2019 but increased in later years.\n\n    -   Low-low clusters remained relatively low, peaking at **3** in 2022.\n\n6.  **Yearly Trends**:\n\n    -   2022 exhibited the highest mean Local Moran's I value (**0.201**), indicating stronger clustering effects.\n:::\n\n## Hot Spot & Cold Spot Area Analysis (HCSA)\n\n::: panel-tabset\n## 2017\n\n### Computing local Gi\\* statistics\n\n```{r}\n#| eval: false\n\nHCSA_2017 <- wm_q_2017 %>% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n```\n\n### Gi\\* VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/gistar_vs_pvalue_map_2017.png\", width = 1600, height = 1200)\n\ngi_star_2017 <- tm_shape(HCSA_2017) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2017\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2017 <- tm_shape(HCSA_2017) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2017\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2017, gi_star_pvalue_2017, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/gistar_vs_pvalue_map_2017.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/hcsa_map_2017.png\", width = 1600, height = 1200)\n\nHCSA_sig_2017 <- HCSA_2017  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2017) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2017) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2017\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/hcsa_map_2017.png\")\n```\n\n## 2018\n\n### Computing local Gi\\* statistics\n\n```{r}\n#| eval: false\n\nHCSA_2018 <- wm_q_2018 %>%    \n  mutate(local_Gi = local_gstar_perm(     \n    total_cases, nb, wts, nsim = 99),          \n    .before = 1) %>%   \n  unnest(local_Gi)\n```\n\n### Visualising Hot Spot & Cold Spot (HCSA)\n\n```{r}\n#| eval: false\n\npng(\"data/rds/gistar_vs_pvalue_map_2018.png\", width = 1600, height = 1200)\n\ngi_star_2018 <- tm_shape(HCSA_2018) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2018\",\n            main.title.size = 0.8)\n\ngi_star_pvalue_2018 <- tm_shape(HCSA_2018) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2018\",\n            main.title.size = 0.8)\n\ntmap_arrange(gi_star_2018, gi_star_pvalue_2018, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/gistar_vs_pvalue_map_2018.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/hcsa_map_2018.png\", width = 1600, height = 1200)\n\nHCSA_sig_2018 <- HCSA_2018  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2018) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2018) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2018\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/hcsa_map_2018.png\")\n```\n\n## 2019\n\n### Computing local Gi\\* statistics\n\n```{r}\n#| eval: false\n\nHCSA_2019 <- wm_q_2019 %>% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n```\n\n### Gi\\* VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/gistar_vs_pvalue_map_2019.png\", width = 1600, height = 1200)\n\ngi_star_2019 <- tm_shape(HCSA_2019) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2019\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2019 <- tm_shape(HCSA_2019) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2019\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2019, gi_star_pvalue_2019, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/gistar_vs_pvalue_map_2019.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/hcsa_map_2019.png\", width = 1600, height = 1200)\n\nHCSA_sig_2019 <- HCSA_2019  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2019) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2019) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2019\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/hcsa_map_2019.png\")\n```\n\n## 2020\n\n### Computing local Gi\\* statistics\n\n```{r}\n#| eval: false\n\nHCSA_2020 <- wm_q_2020 %>% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n```\n\n### Gi\\* VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/gistar_vs_pvalue_map_2020.png\", width = 1600, height = 1200)\n\ngi_star_2020 <- tm_shape(HCSA_2020) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2020\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2020 <- tm_shape(HCSA_2020) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2020\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2020, gi_star_pvalue_2020, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/gistar_vs_pvalue_map_2020.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/hcsa_map_2020.png\", width = 1600, height = 1200)\n\nHCSA_sig_2020 <- HCSA_2020  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2020) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2020) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2020\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/hcsa_map_2020.png\")\n```\n\n## 2021\n\n### Computing local Gi\\* statistics\n\n```{r}\n#| eval: false\n\nHCSA_2021 <- wm_q_2021 %>% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n```\n\n### Gi\\* VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/gistar_vs_pvalue_map_2021.png\", width = 1600, height = 1200)\n\ngi_star_2021 <- tm_shape(HCSA_2021) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2021\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2021 <- tm_shape(HCSA_2021) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2021\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2021, gi_star_pvalue_2021, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/gistar_vs_pvalue_map_2021.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/hcsa_map_2021.png\", width = 1600, height = 1200)\n\nHCSA_sig_2021 <- HCSA_2021  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2021) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2021) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2021\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/hcsa_map_2021.png\")\n```\n\n## 2022\n\n### Computing local Gi\\* statistics\n\n```{r}\n#| eval: false\n\nHCSA_2022 <- wm_q_2022 %>% \n  mutate(local_Gi = local_gstar_perm(\n    total_cases, nb, wts, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n```\n\n### Gi\\* VS P-Value\n\n```{r}\n#| eval: false\n\npng(\"data/rds/gistar_vs_pvalue_map_2022.png\", width = 1600, height = 1200)\n\ngi_star_2022 <- tm_shape(HCSA_2022) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Total Cases in 2022\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ngi_star_pvalue_2022 <- tm_shape(HCSA_2022) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi* in 2022\", \n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\ntmap_arrange(gi_star_2022, gi_star_pvalue_2022, ncol = 2)\n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/gistar_vs_pvalue_map_2022.png\")\n```\n\n### Putting together\n\n```{r}\n#| eval: false\n\npng(\"data/rds/hcsa_map_2022.png\", width = 1600, height = 1200)\n\nHCSA_sig_2022 <- HCSA_2022  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\n\ntm_shape(HCSA_2022) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_2022) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"HCSA in 2022\",\n            main.title.size = 2.5,   \n            legend.text.size = 2.0, \n            legend.title.size = 2.7) \n\n# Close the graphic device\ndev.off()\n```\n\n```{r}\nimage_read(\"data/rds/hcsa_map_2022.png\")\n```\n:::\n\n::: callout-note\n### Summary of Gi\\* and P-Value Analysis\n\n1.  *Gi Statistic (Hot Spot & Cold Spot Analysis)*\\*\n\n    -   The *Gi statistic*\\* is calculated to identify **clusters of high or low values** of total cases in a given area.\n\n    -   It measures whether the number of cases in a location is significantly higher (**hot spot**) or lower (**cold spot**) than would be expected by random distribution.\n\n2.  *P-Value of Gi Statistic*\\*\n\n    -   The **p-value** determines the **statistical significance** of the observed clusters (hot or cold spots).\n\n    -   A low p-value (\\< 0.05) suggests that the cluster is **unlikely to have occurred by chance**, while a higher p-value indicates randomness in the observed pattern.\n\n3.  **Purpose of Both Analyses**\n\n    -   *Gi* of Total Cases\\* map visually displays the clustering of total cases.\n\n    -   **P-Value of Gi**\\* map helps verify whether the identified clusters are **statistically significant** or if they might be due to random variation.\n\nThese two analyses together provide a clear picture of where significant hot or cold spots are and how reliable these findings are. This ensures any conclusions drawn about spatial patterns are both **visualized** and **statistically validated**.\n:::\n\n## Visualising HCSA map across time span (2017-2022)\n\n```{r}\n#| eval: false\n\n# Get a list of image files in the specified directory for HCSA maps\nhcsa_map_files <- list.files(\"data/rds/\", pattern = \"hcsa_map_\\\\d{4}\\\\.png$\", full.names = TRUE)\n\n# Load saved images and combine them into an animated GIF\nhcsa_images <- lapply(hcsa_map_files, image_read)\n\n# Create an animation from the HCSA map images\nhcsa_animation <- image_animate(image_join(hcsa_images), fps = 1)\n\n# Save the animation as a GIF file\nimage_write(hcsa_animation, path = \"data/rds/hcsa_animation.gif\")\n```\n\n```{r}\nimage_read(\"data/rds/hcsa_animation.gif\")\n```\n\n## Summary of HCSA value\n\n```{r}\n#| eval: false\n\n# Function to summarize HCSA values for a given year\nsummarize_hcsa <- function(data) {\n  data %>%\n    summarise(\n      mean_gi_star = mean(gi_star, na.rm = TRUE),\n      min_gi_star = min(gi_star, na.rm = TRUE),\n      max_gi_star = max(gi_star, na.rm = TRUE),\n      sd_gi_star = sd(gi_star, na.rm = TRUE),\n      mean_p_value = mean(p_value, na.rm = TRUE),\n      min_p_value = min(p_value, na.rm = TRUE),\n      max_p_value = max(p_value, na.rm = TRUE),\n      count_hot_spots = sum(gi_star > 0 & p_value < 0.05),\n      count_cold_spots = sum(gi_star < 0 & p_value < 0.05),\n      count_non_significant = sum(p_value >= 0.05),\n      geometry = st_union(geometry)  # Combine geometries\n    )\n}\n\n# Summarizing HCSA for each year\nhcsa_summary_2017 <- summarize_hcsa(HCSA_2017)\nhcsa_summary_2018 <- summarize_hcsa(HCSA_2018)\nhcsa_summary_2019 <- summarize_hcsa(HCSA_2019)\nhcsa_summary_2020 <- summarize_hcsa(HCSA_2020)\nhcsa_summary_2021 <- summarize_hcsa(HCSA_2021)\nhcsa_summary_2022 <- summarize_hcsa(HCSA_2022)\n\n\nhcsa_summary_all <- bind_rows(\n  mutate(hcsa_summary_2017, year = 2017),\n  mutate(hcsa_summary_2018, year = 2018),\n  mutate(hcsa_summary_2019, year = 2019),\n  mutate(hcsa_summary_2020, year = 2020),\n  mutate(hcsa_summary_2021, year = 2021),\n  mutate(hcsa_summary_2022, year = 2022)\n)\n\nwrite_rds(hcsa_summary_all, \"data/rds/hcsa_summary_all.rds\")\n```\n\n```{r}\nhcsa_summary_all <- read_rds(\"data/rds/hcsa_summary_all.rds\")\n\n# Show all rows and columns\nprint(hcsa_summary_all, n = Inf, width = Inf)\n```\n\n::: callout-note\n### Summary of Findings:\n\n1.  *Mean Gi Values*\\*:\n\n    -   Increased from **0.0838 (2017)** to **0.199 (2022)**, indicating more hot spots over time.\n\n2.  *Gi Range*\\*:\n\n    -   Minimum values between **-2.61 to -1.47** (cold spots) and maximum values from **3.06 to 4.67** (significant hot spots).\n\n3.  **Standard Deviation**:\n\n    -   Stable variability in Gi\\* scores, ranging from **1.20 to 1.36**.\n\n4.  **P-Values**:\n\n    -   Average p-values between **0.393 to 0.529**, suggesting many Gi\\* values are not statistically significant.\n\n    -   Minimum p-values as low as **7.95e-13** indicate some significant hot spots.\n\n5.  **Count of Hot Spots and Cold Spots**:\n\n    -   Up to **7 hot spots in 2022**; several years reported **NA** for cold spots, indicating few or no significant cold spots.\n\n6.  **Overall Trends**:\n\n    -   An overall trend of increasing hot spot concentration from 2017 to 2022, suggesting growing areas affected by the phenomena studied (e.g., drug abuse, crime).\n\n### Conclusion\n\nThe HCSA findings highlight a significant rise in hot spot areas over the years, which may require targeted interventions and further investigation into the factors influencing these changes.\n:::\n\n```{r}\nlisa_animation <- image_read(\"data/rds/lisa_animation.gif\")\nhcsa_animation <- image_read(\"data/rds/hcsa_animation.gif\")\n\n# Ensure both animations have the same number of frames by replicating frames if needed\nlisa_frames <- length(lisa_animation)\nhcsa_frames <- length(hcsa_animation)\n\nif (lisa_frames != hcsa_frames) {\n  if (lisa_frames > hcsa_frames) {\n    hcsa_animation <- image_cycle(hcsa_animation, lisa_frames)\n  } else {\n    lisa_animation <- image_cycle(lisa_animation, hcsa_frames)\n  }\n}\n\n# Convert each animation into a list of individual frames\nlisa_frames_list <- as.list(lisa_animation)\nhcsa_frames_list <- as.list(hcsa_animation)\n\n# Resize each frame to ensure no margins and same height\nlisa_frames_resized <- lapply(lisa_frames_list, function(frame) {\n  image_scale(frame, \"800x\")  \n})\n\nhcsa_frames_resized <- lapply(hcsa_frames_list, function(frame) {\n  image_scale(frame, \"800x\")  \n})\n\n# Combine corresponding frames side by side with no gaps\nside_by_side_frames <- mapply(function(lisa_frame, hcsa_frame) {\n  # Use `image_append` with `stack = FALSE` for horizontal stacking\n  image_append(c(lisa_frame, hcsa_frame), stack = FALSE)\n}, lisa_frames_resized, hcsa_frames_resized, SIMPLIFY = FALSE)\n\n# Create a new animation from the combined frames\nside_by_side_animation <- image_animate(image_join(side_by_side_frames), fps = 1)\n\n# Save the final combined animation\nimage_write(side_by_side_animation, path = \"data/rds/lisa_hcsa_side_by_side_animation.gif\")\n\nside_by_side_animation\n```\n\n<br/><br/>\n\n# **6.0 Mann-Kendall Test for Trend**\n\nThis will assess the trend of drug abuse in each province over multiple years. \\[See if the abuse case is increasing, decreasing, or stable over time\\]\n\n```{r}\n#| eval: false\n\n# Apply Mann-Kendall Test for each province\ntrend_results <- summary_stats %>%\n  group_by(province_name) %>%\n  summarise(\n    total_cases = list(total_cases),         \n    trend = MannKendall(unlist(total_cases))$tau,  # Tau value indicates trend direction\n    p_value = MannKendall(unlist(total_cases))$sl,   # p-value for significance\n  )\n\n# Classify trends based on the Mann-Kendall results\ntrend_results <- trend_results %>%\n  mutate(trend_status = case_when(\n    p_value < 0.05 & trend > 0 ~ \"Increasing\",\n    p_value < 0.05 & trend < 0 ~ \"Decreasing\",\n    p_value >= 0.05 ~ \"Stable\",\n    TRUE ~ \"No sufficient data\"\n  ))\n\nwrite_rds(trend_results, \"data/rds/trend_results.rds\")\n```\n\n## Provincial Trends\n\n::: panel-tabset\n## Increasing Trends\n\n```{r}\n#| eval: false\n\nincreasing_trends <- trend_results %>%\n  filter(trend_status == \"Increasing\") %>%\n  pull(province_name)\n\nwrite_rds(increasing_trends, \"data/rds/increasing_trends.rds\")\n```\n\n```{r}\nincreasing_trends <- read_rds(\"data/rds/increasing_trends.rds\")\n\n# Check if increasing_trends is null or empty and set a default message\nif (is.null(increasing_trends) || length(increasing_trends) == 0) {\n  result <- \"NIL\"\n} else {\n  result <- paste(increasing_trends, collapse = \", \")\n}\n\ncat(result, \"\\n\")\n```\n\n## Decreasing Trends\n\n```{r}\n#| eval: false\n\ndecreasing_trends <- trend_results %>%\n  filter(trend_status == \"Decreasing\") %>%\n  pull(province_name)\n\nwrite_rds(decreasing_trends, \"data/rds/decreasing_trends.rds\")\n```\n\n```{r}\ndecreasing_trends <- read_rds(\"data/rds/decreasing_trends.rds\")\n\n# Check if decreasing_trends is null or empty and set a default message\nif (is.null(decreasing_trends) || length(decreasing_trends) == 0) {\n  result <- \"NIL\"\n} else {\n  result <- paste(decreasing_trends, collapse = \", \")\n}\n\ncat(result, \"\\n\")\n```\n\n## Stable\n\n```{r}\n#| eval: false\n\nstable_trends <- trend_results %>%\n  filter(trend_status == \"Stable\") %>%\n  pull(province_name)\n\nwrite_rds(stable_trends, \"data/rds/stable_trends.rds\")\n```\n\n```{r}\nstable_trends <- read_rds(\"data/rds/stable_trends.rds\")\n\n# Check if stable_trends is null or empty and set a default message\nif (is.null(stable_trends) || length(stable_trends) == 0) {\n  result <- \"NIL\"\n} else {\n  result <- paste(stable_trends, collapse = \", \")\n}\n\ncat(result, \"\\n\")\n```\n:::\n\n<br/><br/>\n\n# **7.0 Predicting near future trends**\n\nBy forecasting, we can enhance our strategic planning, enabling proactive policy development, targeted interventions, and more effective resource allocation. This foresight allows decision-makers to anticipate challenges and respond promptly, ultimately reducing the impact of drug abuse on communities.\n\n## Forecast Future Values\n\n```{r}\nlibrary(forecast)\n\n\narima_forecasts <- list()\n\nfor (province in unique(drug_offenses_by_province$province_name)) {\n  province_data <- drug_offenses_by_province %>%\n    filter(province_name == province) %>%\n    arrange(year)\n  \n  # Create time series object for case count\n  ts_data <- ts(province_data$case_count, start = min(province_data$year), frequency = 1)\n  \n  # Fit ARIMA model\n  fit <- auto.arima(ts_data)\n  \n  # Forecast for the next 5 years (2023 to 2027)\n  forecasted_values <- forecast(fit, h = 5)\n  \n  # Store forecast results for each year\n  arima_forecasts[[province]] <- data.frame(\n    province_name = province,\n    year = 2023:2027,\n    predicted_cases = as.numeric(forecasted_values$mean)\n  )\n}\n\n# Combine forecast results for all provinces\nfuture_predictions <- bind_rows(arima_forecasts)\n```\n\n## Hot/Cold Spot Classification\n\n```{r}\n# Set thresholds for hot and cold spots\nhot_spot_threshold <- quantile(drug_offenses_by_province$case_count, 0.75)\ncold_spot_threshold <- quantile(drug_offenses_by_province$case_count, 0.25)\n\n# Classify hot/cold spots based on predicted cases for each year\nfuture_predictions <- future_predictions %>%\n  mutate(hot_cold_label = case_when(\n    predicted_cases > hot_spot_threshold ~ \"Hot Spot\",\n    predicted_cases < cold_spot_threshold ~ \"Cold Spot\",\n    TRUE ~ \"Neutral\"\n  ))\n\nprint(future_predictions)\n```\n\n## Visualization of Predictions\n\n```{r}\nlibrary(tmap)\n\n# Merge predictions with spatial data\nfuture_spatial <- province_boundaries %>%\n  left_join(future_predictions, by = \"province_name\")\n\n\ntm_shape(future_spatial) +\n  tm_polygons(\"hot_cold_label\", palette = c(\"blue\", \"red\", \"gray\"), \n              title = \"Predicted Hot/Cold Spots (2023-2027)\") +\n  tm_borders() +\n  tm_layout(title = \"Predicted Drug Abuse Hot/Cold Spots in Thailand (2023-2027)\")\n```\n\n::: callout-note\nARIMA (AutoRegressive Integrated Moving Average) model is used for our time series forecasting.\n\nAlso it offers,\n\n-   **Flexibility**: in various time series patterns, suitable for non-stationary data.\n\n-   **Automatic Parameter Selection** (`auto.arima`): simplifies model fitting by automatically selecting optimal parameters.\n\n-   **Robustness**: in capturing fluctuations in historical data.\n:::\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"Take-home_Ex02.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.555","editor":"visual","theme":"cosmo","title":"Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level","author":"kai feng","date":"Sep 23, 2024","date-modified":"last-modified"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}